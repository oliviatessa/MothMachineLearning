{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callin Switzer\n",
    "### 30 May 2019\n",
    "\n",
    "\n",
    "# Make videos of tracking moth"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Outline:\n",
    "** show how well moth can follow trajectory with network\n",
    "** make function to predict with nnet and then evaluate immediately with ODE\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)]\n",
      "last run on 2019-06-11 15:38:16.851051\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import os\n",
    "import math\n",
    "import seaborn as sns\n",
    "from scipy.integrate import odeint\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "from matplotlib.patches import Ellipse\n",
    "from matplotlib.patches import Arc\n",
    "from collections import OrderedDict\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.image as mpimg\n",
    "import sys\n",
    "import pandas as pd\n",
    "import importlib\n",
    "print(sys.version)\n",
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'0.36.2'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numba\n",
    "numba.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import simUtils_DLVersion as simUtils\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'simUtils_DLVersion' from 'C:\\\\Users\\\\calli\\\\Documents\\\\GitRepos\\\\MothMachineLearning\\\\simUtils_DLVersion.py'>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(simUtils)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow successfully installed.\n",
      "tensorflow using CPU\n",
      "3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)] \n",
      "\n",
      "last run on 2019-06-11 15:59:40.361777\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.colors as colors\n",
    "from  mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "import subprocess\n",
    "import winsound\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "\n",
    "# make sure Keras uses CPU instead of GPU\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"   \n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow successfully installed.\")\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"The installed version of TensorFlow includes GPU support.\")\n",
    "else: \n",
    "    print(\"tensorflow using CPU\")\n",
    "print(sys.version, \"\\n\")\n",
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))\n",
    "\n",
    "# define directories\n",
    "baseDir = os.getcwd()\n",
    "dataDir = r'D:\\MothSimulations\\11c-AggressiveManeuver\\Qstore\\hws_am_con'\n",
    "figDir = r'D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019'\n",
    "dataOutput = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput'\n",
    "savedModels = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels'\n",
    "randomRawData = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\PythonGeneratedData\\TrainingData'\n",
    "if not os.path.exists(dataOutput):\n",
    "    os.mkdir(dataOutput)\n",
    "if not os.path.exists(savedModels):\n",
    "    os.mkdir(savedModels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.models import load_model\n",
    "\n",
    "# Keras callcacks\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some functions\n",
    "\n",
    "def cart2pol(x, y):\n",
    "    rho = np.sqrt(x**2 + y**2)\n",
    "    phi = np.arctan2(y, x)\n",
    "    return(rho, phi)\n",
    "\n",
    "def pol2cart(rho, phi):\n",
    "    '''\n",
    "    rho: radius\n",
    "    phi: angle (in radians)\n",
    "    '''\n",
    "    x = rho * np.cos(phi)\n",
    "    y = rho * np.sin(phi)\n",
    "    return(x, y)\n",
    "\n",
    "def midpoint(p1, p2):\n",
    "    return ((p1[0]+p2[0])/2, (p1[1]+p2[1])/2)\n",
    "\n",
    "def format_e(n):\n",
    "    a = '%E' % n\n",
    "    return a.split('E')[0].rstrip('0').rstrip('.') + 'E' + a.split('E')[1]\n",
    "\n",
    "\n",
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        plt.ylim([0.000001, 0.05])\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned_2.png\"), dpi = 120, bbox_inches='tight')\n",
    "        print(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "globalDict = OrderedDict({\"bhead\": 0.507,\n",
    "            \"ahead\": 0.908,\n",
    "            \"bbutt\": 0.1295,\n",
    "            \"abutt\": 1.7475, \n",
    "            \"rho\": 1, \n",
    "            \"rhoA\": 0.00118, \n",
    "            \"muA\": 0.000186, \n",
    "            \"L1\": 0.908, \n",
    "            \"L2\": 1.7475,  \n",
    "            \"L3\": 0.75,\n",
    "            \"K\": 29.3,\n",
    "            \"c\":  14075.8,\n",
    "            \"g\": 980.0,\n",
    "            \"betaR\":  0.0,\n",
    "            \"nstep\": 30,\n",
    "            \"nrun\" : 1  # (max) number of  trajectories.\n",
    "            })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculated variables\n",
    "globalDict['m1'] = globalDict['rho']*(4/3)*np.pi*(globalDict['bhead']**2)*globalDict['ahead']\n",
    "globalDict[\"m2\"] = globalDict[\"rho\"]*(4/3)*np.pi*(globalDict[\"bbutt\"]**2)*globalDict[\"abutt\"]\n",
    "globalDict[\"echead\"] = globalDict[\"ahead\"]/globalDict[\"bhead\"]\n",
    "globalDict['ecbutt'] = globalDict['abutt']/globalDict['bbutt']\n",
    "globalDict['I1'] = (1/5)*globalDict['m1']*(globalDict['bhead']**2)*(1 + globalDict['echead']**2)\n",
    "globalDict['I2'] = (1/5)*globalDict['m2']*(globalDict['bbutt']**2)*(1 + globalDict['ecbutt']**2)\n",
    "globalDict['S_head'] = np.pi*globalDict['bhead']**2\n",
    "globalDict['S_butt'] = np.pi*globalDict['bbutt'] **2\n",
    "t = np.linspace(0, 0.02, num = globalDict[\"nstep\"], endpoint = True)\n",
    "\n",
    "# convert dict to list, since @jit works better with lists\n",
    "globalList = [ v for v in globalDict.values() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0001, 0.0, 0.0001, 3.141592653589793, 0.0001, 0.0, 0.0001]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "state0_ICs = [0.0, 0.0001, 0.0, 0.0001, np.pi, 0.0001, 0.0, 0.0001]\n",
    "state0_ICs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "F = 0\n",
    "alpha = np.pi/2\n",
    "tau0 = 20\n",
    "tau_w = 2001\n",
    "\n",
    "FAlphaTau_list = [F, alpha, tau0, tau_w]\n",
    "x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>xd</th>\n",
       "      <th>y</th>\n",
       "      <th>yd</th>\n",
       "      <th>theta</th>\n",
       "      <th>thetad</th>\n",
       "      <th>phi</th>\n",
       "      <th>phid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>3.141593</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.895929e-08</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.000237</td>\n",
       "      <td>-0.681961</td>\n",
       "      <td>3.141588</td>\n",
       "      <td>-0.006320</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>0.005338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.379059e-07</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.000941</td>\n",
       "      <td>-1.357820</td>\n",
       "      <td>3.141584</td>\n",
       "      <td>-0.006318</td>\n",
       "      <td>0.000007</td>\n",
       "      <td>0.005340</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.068399e-07</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.002110</td>\n",
       "      <td>-2.033677</td>\n",
       "      <td>3.141580</td>\n",
       "      <td>-0.006315</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>0.005342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2.757612e-07</td>\n",
       "      <td>0.0001</td>\n",
       "      <td>-0.003746</td>\n",
       "      <td>-2.709530</td>\n",
       "      <td>3.141575</td>\n",
       "      <td>-0.006311</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.005346</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              x      xd         y        yd     theta    thetad       phi  \\\n",
       "0  0.000000e+00  0.0001  0.000000  0.000100  3.141593  0.000100  0.000000   \n",
       "1  6.895929e-08  0.0001 -0.000237 -0.681961  3.141588 -0.006320  0.000004   \n",
       "2  1.379059e-07  0.0001 -0.000941 -1.357820  3.141584 -0.006318  0.000007   \n",
       "3  2.068399e-07  0.0001 -0.002110 -2.033677  3.141580 -0.006315  0.000011   \n",
       "4  2.757612e-07  0.0001 -0.003746 -2.709530  3.141575 -0.006311  0.000015   \n",
       "\n",
       "       phid  \n",
       "0  0.000100  \n",
       "1  0.005338  \n",
       "2  0.005340  \n",
       "3  0.005342  \n",
       "4  0.005346  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tragDF = pd.DataFrame([x, xd, y, yd, theta, thetad, phi, phid]).transpose()\n",
    "tragDF.columns = \"x, xd, y, yd, theta, thetad, phi, phid\".split(\", \")\n",
    "tragDF.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x2788a811588>"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEBCAYAAACJy4k1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3Xd4VFX+x/H3TBJSIAk1tIBIO4QOoaiARMVFZLGCIooKiAi6Krpr+cladmVdsaK4qIgCYl1FrFhWUaSJBNAg4QiIICK9EwKk/P64NzrGhJAhyZ0kn9fz5Mmde8+Z+eRmZr4zt5zry83NRURE5Fj8XgcQEZHQp2IhIiJFUrEQEZEiqViIiEiRVCxERKRIKhYiIlKkcK8DHK/U1FQd4ysiUkzJycm+krifclMsAJKTk4Pql56eTlJSUgmnOXHKVTzKVTyhmgtCN1tFy5WamlpiGbQZSkREiqRiISIiRVKxEBGRIqlYiIhIkVQsRESkSEEfDWWM8QP/AToAh4FrrLVrA5aPBEYBWcD91tr3jDG1gZeBaGAzMMxam1FQ22BziYhIyTuRbxYXAFHW2lOBO4BH8hYYY+oBNwI9gL7AA8aYSOBu4GVrbS9gOTDqGG1LRG5uLhqGXUTkxJzIeRY9gQ8BrLWLjTFdApZ1AxZYaw8Dh40xa4H2bp9/uW3muNPrCmn79Qlk+9WQKV+x+IedRIRtICLMR0S4n4gwP1XC/M7tML/74yMyIoy4qAjioyOoHuP8/vUn4Hb16Aiqx1QhzF8i57qIiIS8EykWccDegNvZxphwa21WAcv2A/H55hc0L3D+H6Snpxc75J9OCicxqhr4w8jOgaM5uWTl5JKVncvRHMjOySUrJ4ujObkcyshlx54cDhzJYf/hbA5lFf6NJMwHtWLCqV01jDox4dSuGk6dquHUjnF/Vw2jelQYfl/hBSUzMzOov6m0KVfxKFfxhWo25SrciRSLfUBswG2/WygKWhYL7AmYf6iAefnb/kEwZzAmJQV/9uPR7Bz2HTrK3kNH2eP+3nfoKHsyjrJtfya/7Mlk895DbNibyaJN+zmSlfO7/lXC/NSvHkXT2lVpVqcazRKqOb/rVKVWtcgKd7ZoaVOu4gnVXBC62Y4n15upm3h96U8l+riXdGnExcmJx8z13HPPMWDAAFJSUli3bh0PPvggzz777DHvtyTP4D6RYrEAGAC8bow5BUgLWLYEGG+MiQIigSRgpdvnXGAa0A/48hhtPRcR5qdWtUhqVSt6F0pubi67Dh7hl72Z7s8hNu/JZNPuDH7YfpBFP+wk8+hvxaRGTAT1q/lp991RmiU4xaRV/TgaxEfhO8a3ERGpnAYNGsQrr7xCSkoKb7zxBgMHDizTxz+RYvEWcLYxZiHgA4YZY24B1lpr3zHGPIFTDPzAXdbaTGPM/cB09+inHcAQa+3BgtqeyB/lBZ/P92thadvwj1vRcnJy+XnPIdZtP8C67QdZt/0AaT9u49PV23ht6eFf29WsWoV2DeNpnxhPW/d3vTgVEJFQcXFy4jG/BZSW7t27M378eHbu3MmCBQu45ZZbyvTxgy4W1toc4Lp8s1cHLJ8CTMnXZytwTgH39Ye2FY3f76NRzRga1YwhxTjz8r7y7s04ytrt+1m1eR9pP+/l2017+c/nO8jOcfaZ1K7mFJB2idVp1zCeDonxJMRFefjXiEhZ8/l8DBgwgPHjx9OjRw8iIiLK9PHL1aizFVV8TATJJ9Uk+aSav87LPJrNql/2kbbJKR4rf97LF9+vwa0fnFQrhu4n16T7ybXo3rQmiTViPEovImXloosuIiUlhbfffrvMH1vFIkRFRYTRuXENOjeu8eu8jCNZrNq8jxU/7WHxD7v46LutvL50EwANq0fTvWlNTnGLR+OaMdp0JVLBZGdnk5ycTLNmzcr8sVUsypGYKuF0aVKTLk1qck2vpuTk5LJ6y36+Wr+Tr37Yxed2O7OW/QxAvbgoujetSY/mtUkxdUiI1WYrkfLso48+YtKkSYwfP96Tx1exKMf8fh+tG8TRukEcw3qcTG5uLmu2HeCr9bv46oedLFy3k7dXbAagfWI8KSaBM0wdOiRWx68TCkXKlb59+9K3b1/PHl/FogLx+Xy0rBtLy7qxDD3lJHJzc1n1yz4+t9v5bPU2Jn22hic+XUOtqlXo3bIOZ7RK4PQWdYiPKdsdZSJS/qhYVGA+n482DeJp0yCe689ozu6DR5i3xikcn9ltzFr+M2F+H8mNa3BGqwT6ta1Hk9pVvY4tIiFIxaISqVG1Cud3bMj5HRuSnZPLip92M3e1Uzwe/HA1D364mrYN4+haN5xhCRk0rqUjrETEoWJRSYX5fb8ervvXvoZNuzOYk7aF99J+4YVlu3hh2VzaJ8bTv119+revr0NzRSo5FQsBILFGDCNPb8rI05vy+dffYjOq8n7aLzwwZzUPzFlNx0bV+XP7+vRrV5+G1aO9jisiZUzFQv6gbrUIUro2Y1TvZmzcmcH7ab/wftpm7n8/nfvfT6drkxoM6tKI/u3qUzVSTyGRykCvdDmmxrViGJ3SjNEpzfhxx0HeT/uFN1M3cdsb33LvO9/Rv119BnVpRNcmNXQSoEgFpmIhx61J7apcf0ZzxqQ0Y9nG3bz+9Sbe+3Yz/03dRJNaMQzq0oiLOjekfrw2U4lUNCoWUmw+3287x+85rzUfpG3hv0t/4qGPLI98bOnVog6DuiRyduu6RIaHeR1XREqAioWckJgq4QxMTmRgciIbdh7kjdRNvJm6iRteXk71mAgu7dKIK045iUY1dTSVSHmmYiEl5qRaVbn1T4ab+7Rk4bodvLJkI8/NX8+UL3/grKS6XH1aE05rVkv7NkTKIRULKXFhfh+9WtShV4s6bN5ziJe+2sArS37ik1VbaZFQjStPa8JFnRrqSCqRcsTvdQCp2BpUj+ZvfVux8I4zeXhQB6Iiwvj77JWc8sCn/OPdVfy446DXEUXkOAT10c4YEw3MBBKA/cBV1trt+drcA/QHsoCbrbVLjDEdgSeBbOAwcKW1dqt7WdUe7n0BnG+t3RtMNglNURFhDExO5OLODVm2cQ/TF/7IjEU/8sLC9aS0rMOInk3p0VybqERCVbDfLEYDadbaXsAMYFzgQmNMZ6A30B0YDDzlLpoI/MVamwLMAm5353cG+lprU9wfFYoKyjmSqgZPXNaJhXecyY1ntmDl5n1cMfUrzpu0gA/Sfvn1crIiEjqCLRY9gQ/d6TlAnwKWf2ytzbXWbgTCjTF1gMHW2hVum3Ag0xjjB1oAzxpjFhhjhgeZScqZhLgoxp7dkvm3n8G/L2rHgcNZjHlpGWc/+gWvfb2Rw1nZXkcUEZcvN/fYn+KMMSOAsflmbwVusNamu2/2G621iQF9xgE7rbWT3dvzgOHW2rXu7dOAqcDpQCZwE/AoEAbMddt+G/iAqampuTExwR1+mZmZSVRU6F0pTrl+Lzsnl4UbD/J62h7W7jpCrZgwLmodT7+WcURH+LW+iilUc0HoZqtouTIyMkhOTi6RbbtF7rOw1k7FeWP/lTFmFhDr3owF9uTrti9g+e/aGGMuBe4C+ltrtxtjwoCJ1toMd/lnQAfgW/JJSko6jj/pj9LT04PuW5qU64/atoGR5+Qyf+0O/jN3HVOW7uT17/Zz1WlNOK12BJ20vo5bqOaC0M1W0XKlpqaWWIZgj11cAJwLLAH6AV8WsHyCMeZhIBHwW2t3GGOuAEYBKdbaXW7blsCr7n4OP84mrOlB5pIKwOf77dDb5Rt38/QX63ji0zU8E+bjsp98jElpRkJc6H36E6nIgi0Wk4Hpxpj5wBFgCIAxZgLwhnvk05fAIpwCcL37DeIJYCMwyxgD8IW19h5jzEvAYuAoMMNa+92J/FFScXRqXINnhnZh7bb9PPj2MmYu3sArSzZy5akncV3vZtSqFul1RJFKIahi4W4yGlTA/NsCpu8F7s3XpGYh9zcBmBBMFqkcmifEckvPBP5+0UlM/HQNU+ev56WvNjK8x8mM7NVU1xEXKWU6KU/Klca1Ynjkkg58PLY3Z7ZKYNLctfSc8BlPfrqGA4ezvI4nUmGpWEi51DyhGpOGdGbOTb04pWktHvnke3o9+BnPzlvHoSM65FakpKlYSLmWVD+OKVd24e3re9A+sTr/+mA1pz80l2kL1us8DZESpGIhFUKHRtWZPrwb/73uVJrWrsq9767irEe+4N1vNlPUuUQiUjQVC6lQujapyavXnsKLI7oRGxXBX15ZzkWTF5K6YbfX0UTKNRULqXDyztN47y89mXBxe37efYiLJy/k+peX8dOuDK/jiZRLKhZSYYX5fVzStRFz/5rCjWe14NP0rZz1yBc88EE6ew8d9TqeSLmiYiEVXtXIcG45uyWf//UMzuvYgGe//IGUh+YyY9GPHM3O8TqeSLmgYiGVRr34KB4e1IF3b+hJq3px3P32d/R9fB6fpm/VTnCRIqhYSKXTtmE8L4/sznNXdoFcGDF9KcOnfc2Gnbpqn0hhVCykUvL5fPRpXZePxp7OuP5JLFm/i7Mfm8fj//uezKM6P0MkPxULqdQiwvxc06spn96awp9a1+Xx/63hT4/NY+7qbV5HEwkpKhYiOPszJg3pzEvXdCcizMewaV9z7YylbNqtQ21FQMVC5Hd6NK/NnJtO57ZzDF+u2UGfR7/gqblrOZKlo6akclOxEMmnSrifMSnN+d+tvUlpmcBDH1nOmTiP+Wt2eB1NxDMqFiKFaFg9mqeHJjNtWFeyc3K5YupX3PjKcnYeOOx1NJEyp2IhUoQUk8BHN5/OTWe1YM7KXzj7sXm8veJnnZshlUpQV8ozxkQDM4EEYD9wlbV2e7429wD9gSzgZvdSq52Bd4E1brPJ1trXCmob1F8jUkqiIsIYe3ZL+revz21vfMtNr67gnRWbuf/Ctl5HEykTwX6zGA2kWWt7ATOAcYEL3aLQG+gODAaechd1Bh611qa4P68do61IyGlZN5Y3R5/GuP5JLFi3g7MfnccHdh85OfqWIRVbsMWiJ/ChOz0H6FPA8o+ttbnW2o1AuDGmDpAM9DfGzDPGTDXGxB6jrUhICvP7uKZXUz6+uTftE+N5cvEOhjy3mB936AxwqbiK3AxljBkBjM03eyuw153eD8TnWx4H7Ay4nddmCfCctTbVGHMXcA+wp5C2v9usBZCenl5U3AJlZmYG3bc0KVfxhGKucT3ieK9GFtO+2c2fHvuCoR1rcGHreML8Pq+jheT6yhOq2ZSrcEUWC2vtVGBq4DxjzCwg1r0Zi/OGH2hfwPLANm9Za/PavgU8CbxdSNs/SEpKKipugdLT04PuW5qUq3hCNZfPl86VZ3dh3OyVTE3dytKt2Tw4sD2t6sV5mitU1xeEbraKlis1NbXEMgS7GWoBcK473Q/4soDlfY0xfmNMY8Bvrd0BfGSM6ea2OQtIPUZbkXKjXnwUU65M5snLOrFp9yEGPDmfp+auJVv7MqSCCOpoKGAyMN0YMx84AgwBMMZMAN5wj3z6EliEU5Cud/uNBiYZY44AW4BrrbX7CmkrUq74fD4GdGhAj+a1+fvslTz0kWXu6m08eklHGteK8TqeyAkJqlhYazOAQQXMvy1g+l7g3nzLlwGnFdDvD21FyquaVaswaUgnzl5Rl7+/vZJ+E+dx94DWXNKlET6f9/syRIKhk/JESoHP5+OCTg358ObTaZ9YndvfTGPkjFR26OxvKadULERKUcPq0bx0TXfG9U9i3prt9H1sHp+s2up1LJFiU7EQKWV+97yM9/7Sk7pxUYycsZTb3/iWA4ezvI4mctxULETKSMu6scy+vgdjUprx39Sf6DdxHkt/3OV1LJHjomIhUoaqhPu57ZxWvD7qVHz4uOSZRTz8kSUrW9fLkNCmYiHigS5NavLBTb24uHMik+auZfCzi9m855DXsUQKpWIh4pFqkeE8NKgDEwd3JP2XfZz7xJfa+S0hS8VCxGPnd2zIezf2omH1aEbOWMp9737H4axsr2OJ/I6KhUgIOLl2VWaNOY2rT2vCCwt+ZODkRRrFVkKKioVIiIgMD+Pe89rwzNBkNuw8yJ+fnM8732z2OpYIoGIhEnL6tqnHBzf1wtSL5cZXlnPHm99y6Ig2S4m3VCxEQlBijRhevfYUxqQ049Wvf+L8p+bz/db9XseSSkzFQiRERYQ552TMGN6NXQePcN6k+by1fJPXsaSSUrEQCXGnt6zDBzf2on1idca+9g33vvMdR7J0Ep+ULRULkXIgIS6Kl67pzoieJzNt4Y9cNmUxW/dleh1LKhEVC5FyIiLMz9//3JonLuvEqs37+POT81myXmNLSdlQsRApZ87r0IC3b+hBtchwhkxZzPPz15Obq8u3SukK6kp5xphoYCaQAOwHrrLWbs/X5h6gP5AF3OxeavVVoJ7bpAmw2Fo72BjzDlALOAocstb2CyaXSGXRsm4sb9/Qg1tf/4Z/vLeKbzbt4YGL2hFTJdgrJYscW7DfLEYDadbaXsAMYFzgQmNMZ6A30B0YDDwFYK0dbK1NAS4E9gBj3S7NgZ7W2hQVCpHjExcVwTNXJPO3voZ3vtnMhU8tZL3O+pZSEmyx6Al86E7PAfoUsPxja22utXYjEG6MqROw/D7gSWvtL8aYukB14F1jzHxjzJ+DzCRS6fj9Pq4/oznTh3Vj2/5Mzps0n/9pMEIpBUV+ZzXGjOC3bwB5tgJ73en9QHy+5XHAzoDbeW22G2MSgLMC7rMK8AgwEagJLDDGLLHWbsufJT09vai4BcrMzAy6b2lSruJRrsLVAR7rV4/xn2/lmhlLubxDdS4y0Z7nKkworLOCKFfhiiwW1tqpwNTAecaYWUCsezMWZ5NSoH0By/O3GQi8bK3NG79gC/C0tTYL2GaMWQ4Y4A/FIikpqai4BUpPTw+6b2lSruJRrmNLAk7pmM242St5KXUTG/Yc5dkR7UNyP0aorLP8Klqu1NTUEssQ7GaoBcC57nQ/4MsClvc1xviNMY0Bv7V2h7usD86mKwJuvw5gjKkGtAVCr7SLlANREWE8NLA94/onsXDjQQY9vUgXVZISEWyxmAy0McbMB67F2QeBMWaCMaabtTYVp4AsAt4Erg/oa4Af8m5Ya+cAa4wxi4GPgf8LKCwiUkw+n49rejXlnjPrsXFnBudNWsDyjbu9jiXlXFDfT621GcCgAubfFjB9L3BvAW3aFDDv5mByiEjhuiXGMGvMaYyYvpRLn13Mgxe348JOiV7HknJKJ+WJVGAt6sby9vU96NzYGVfqwQ9Xk5OjE/ik+FQsRCq4GlWr8OKI7gzp3pjJn6/j2hdTOXA4y+tYUs6oWIhUAhFhfsZf0JZ/nN+GuXYbAycv5KddGV7HknJExUKkkvD5fFx5ahOmDevK5j2HOP+pBRqIUI6bioVIJdOrRR1mX9+D6tERXP7cYmYv/9nrSFIOqFiIVEJN61TjrTE9SD6pBje/toKn5q7VyLVyTCoWIpVUfEwE04d344KODXjoI8v/vZVGVrauwCcFC71xAESkzESGh/HYpR1JrBHDpLlr2bwnk6cu70y1SL01yO/pm4VIJefz+fhrX8O/L2rH/LU7uOTpRbpkq/yBioWIADC4W2OmXtWFDTsPcuFTC7Bb9nsdSUKIioWI/CrFJPD6daeSlZPLwMkLWbhWw7SJQ8VCRH6nTYN43rq+B/WrR3HVC0uYtWyT15EkBKhYiMgfNKwezX+vO42uTWpyy+vf8MSna3RobSWnYiEiBYqPjmDasG5c1Lkhj37yPf/3VhrZGoSw0tLxcSJSqCrhfh4Z1IEG8dFMmruW3QeP8vjgjkRFhHkdTcqYvlmIyDHlHVp7959b8+F3Wxg+7WuNWlsJqViIyHEZ3vNkHru0A1+t38Vlzy5mx4HDXkeSMhTUZihjTDQwE0gA9gNXWWu3F9CuOTDbWtvWvV0beBmIBjYDw6y1GcaYkcAoIAu431r7XjC5RKR0XdgpkfjoCEbPXMYlTy9ixohuJNaI8TqWlIFgv1mMBtKstb2AGcC4/A2MMUOBV4HaAbPvBl52+y0HRhlj6gE3Aj2AvsADxpjIIHOJSCk7s1VdZl7TnR0HDjNw8iK+36qT9yqDYItFT+BDd3oO0KeANruB3sfRrxuwwFp72Fq7F1gLtA8yl4iUga5NavLaqFPJzs1l0NOLWLZxt9eRpJQVuRnKGDMCGJtv9lZgrzu9H4jP3y9vU5IxJnB2XAH9AucVen8iElqS6sfx5nWnMfT5r7h8ylc8PTSZ3i3reB1LSkmRxcJaOxWYGjjPGDMLiHVvxgJ7jvPx9rntDwX0y5uXp9D7S09PP86H+b3MzMyg+5Ym5Soe5Sqessr1r7Nq8/dPtjBi2hJu7ZlAysnVQiZbcSlX4YI9z2IBcC6wBOgHfFnMftMC+i0BxhtjooBIIAlYWVDnpKSkoMKmp6cH3bc0KVfxKFfxlGWut5JaMXL6UiZ8uY2qNepw5alNQiZbcVS0XKmpqSWWIdh9FpOBNsaY+cC1wH0AxpgJxphux+h3PzDYGLMAOBWYZK3dAjyBUzg+A+6y1mp8ZJFyJD46ghkjunFWq7rc/fZ3/OfztV5HkhIW1DcLa20GMKiA+bcVMK9ewPRW4JwC2kwBpgSTRURCQ1REGJOv6Mwtr3/DhA8tmUdzGNunBT6fz+toUgI03IeIlJiIMD+PX9qRyHA/T3y6hsNHs7mjXysVjApAxUJESlSY38eEi9sTFeHnmXk/kHk0m3sGtMHvV8Eoz1QsRKTE+f0+/nl+W6LCw3hu/noOZ+Uw/sJ2hKlglFsqFiJSKnw+H3f1TyK6ShhPfraWzKPZPDyoA+FhGpKuPFKxEJFS4/P5uPVPhshwPw9//D2Hs3KYOLiT17EkCCoWIlLqbjizBVERYdz/fjpHZqZyYxcNPljeqFiISJm4pldTIiPC+PvslezaG83LLVsRXUUXUSovtPFQRMrM0FNO4qGB7flmyyGuemGJLqJUjqhYiEiZGtSlEX/rlUDqht1c/bwKRnmhYiEiZS7l5GpMuqwTy3/aw7AXlnBQBSPkqViIiCf6tavPE4M7sWzjHoa98LUKRohTsRARz/RvX5/HL+3I0g27GD7tazKOqGCEKhULEfHUgA4NeOzSjnz94y5GTFvKoSPZXkeSAqhYiIjnzu/YkEcv6chX63cyYvrXKhghSMVCRELCBZ0a8vCgDiz6YScjZywl86gKRihRsRCRkHFR50QeGtiBBet2qGCEGBULEQkpA5MTefDi9sxfu4NRL6aqYIQIFQsRCTmXdGnEvy9qxxffb+e6makczlLB8FpQY0MZY6KBmUACsB+4ylq7vYB2zYHZ1tq27u3GwPPu4/qAa6211hhzCzACyLuPUdZaG0w2EakYLu3amJxcuHNWGqNnLuPpK5KpEq7Pt14Jds2PBtKstb2AGcC4/A2MMUOBV4HaAbP/CUyy1qYA/wIecOd3Bq601qa4PyoUIsJl3Roz/sK2fLZ6Gze/tpys7ByvI1VawRaLnsCH7vQcoE8BbXYDvfPNuxV4350OBzLd6WTgTmPMfGPMnUFmEpEK6PLuJzGufxIfpG3h9jfTyMnJ9TpSpeTLzT32ijfGjADG5pu9FbjBWptujPEDG621iYX032KtrZdvngFmAxe4m6HuAZ4C9gFvAZOtte8F9klNTc2NiQluDPzMzEyioqKC6lualKt4lKt4QjUXBJftpW92M3PFbgaYOEZ3r4XPV/KXaA3VdRZsroyMDJKTk0tkRRW5z8JaOxWYGjjPGDMLiHVvxgJ7jvcBjTFnAP8BhrqFwgc8bq3d6y5/H+gEvJe/b1JS0vE+zO+kp6cH3bc0KVfxKFfxhGouCC7bP1vlEhO3mmfn/UBi/Trcfk6rkMhVFoLNlZqaWmIZgr340QLgXGAJ0A/48ng6uYViInCOtXaDOzsOWGmMSQIOAmfi7AQXEfmVz+fjzn6tOHA4i8mfr6NaZDjXn9Hc61iVRrDFYjIw3RgzHzgCDAEwxkwA3rDWLimk3+NAFbcvgLXWjjLG/B8wFzgMfGqt/SDIXCJSgfl8Pu4/vy0Zh7N46CNLTJUwhvU42etYlUJQxcJamwEMKmD+bQXMqxcw3aGQ+3sReDGYLCJSufj9Ph4e1IGMI9nc9+4qqlYJ55KujbyOVeHpoGURKXfCw/w8OaQTvVrU5vZZ3/LuN5u9jlThqViISLkUGR7Gs0O70OWkGox9bQX/W7XV60gVmoqFiJRb0VXCmHp1V5LqxzHm5WUsWLvD60gVloqFiJRrcVERzBjejSa1Yhg5YympG3Z7HalCUrEQkXKvRtUqzBzRnTqxkQyf9jVrtu73OlKFo2IhIhVCQlwULw7vTpVwP1c+v4TNew55HalCUbEQkQqjca0Ypg/rxoHMLIZO/YrdB494HanCULEQkQqldYM4plzVhZ92H2LYtK/JOJLldaQKQcVCRCqcU5rW4onBnfh20x7GvLSMoxra/ISpWIhIhXRO23qMv7Adn9vt3PbGtxra/AQFOzaUiEjIu6xbY3bsP8wjn3xPrapVuKt/UqkMbV4ZqFiISIV2w5nN2XHgMM/NX0/t2Eiu693M60jlkoqFiFRoPp+Pewa0YefBI/x7zmpqVa3CoC4aeLC4VCxEpMLz+308ckkH9mQc5Y5ZadSIqUKf1nW9jlWuaAe3iFQKkeFhPD00mTYN4rj+5WUs/XGX15HKFRULEak0qkWG88LVXWlQPZrh075m7TYNC3K8VCxEpFKpVS2SGcO7USU8jKue/5pt+zO9jlQuBLXPwhgTDcwEEoD9wFXW2u0FtGsOzLbWtnVv1wS+B1a6Td6y1k40xowERgFZwP3W2veCySUicjwa1Yzh+au7cOkzixkxbSmvjTqFmCrahXsswX6zGA2kWWt7ATOAcfkbGGOGAq8CtQNmdwZesdamuD8TjTH1gBuBHkBf4AFjTGSQuUREjkv7xOpMGtKJ7zbv5S8vLydLZ3kfU7DFoifwoTs9B+hTQJvdQO9885KBzsaYL4wx/zXG1Ae6AQustYettXuBtUD7IHOJiBy3s5Lqct/5bfl09Tbuffc7cnN1lndhivzeZYwZAYzNN3srsNd178zIAAAQM0lEQVSd3g/E5++XtynJGBM4ezWQaq39nzHmcuBJYHbAfRV6fwDp6elFxS1QZmZm0H1Lk3IVj3IVT6jmgtDK1iUeBraNZ+bijfgzYrnMFxq5AoXC+iqyWFhrpwJTA+cZY2YBse7NWGDPcT7eZ0CGO/0W8A+czVixAW0Kvb+kpKTjfJjfS09PD7pvaVKu4lGu4gnVXBB62SaYXDJfXc6Mb3+hS5vmnNehgdeRfifY9ZWamlpiGYLdDLUAONed7gd8eZz9ngMudqfPAlKBJUAvY0yUMSYeSOK3HeAiIqXO7/fx8KAOtE2I4q+vf8NXP+z0OlLICbZYTAbaGGPmA9cC9wEYYyYYY7odo98dwGhjzOfAdcBN1totwBM4Becz4C5rrY5lE5EyFRURxt1n1iWxZjTXvpjK2m0HvI4UUoI6VsxamwEMKmD+bQXMqxcwvR44o4A2U4ApwWQRESkpsZFhTB/WjQv/s4CrX1jCW2N6UCdWB2eCTsoTEfkd5xyMruw8cIQR03WlvTwqFiIi+bRPrM6Tl3Vi5c86ByOPioWISAH6tK7Lfee14dPV27j//dA7nLas6fx2EZFCDD21CRt2ZvDc/PU0q1OVoac28TqSZ1QsRESO4c5zk1i/4yD3vruKJrWr0qtFHa8jeUKboUREjiHM72PiZZ1okVCNMS8tq7TDmqtYiIgUoVpkOM9d1YXI8DCGT1vKroNHvI5U5lQsRESOQ2KNGJ69Mpkt+zK57sVUDmdlex2pTKlYiIgcp86Na/DwoA4s+XEXd721slKNUqsd3CIixXBehwas23aAiZ+uoXlCNa7r3czrSGVCxUJEpJhu7tOCddsP8OCHqzm5dlX6tqlXdKdyTpuhRESKyedzRqltn1idm19dwcqf9xbdqZxTsRARCUJURBhTrkymRkwE10xfytZ9FXuwbBULEZEgJcRG8dxVXdmXeZSRM5Zy6EjFPUJKxUJE5AS0bhDHE4M7kfbzXm7974oKe4SUioWIyAnq07oud/ZrxQdpW5j02Vqv45QKFQsRkRIwsldTLuzUkEc++Z5PVm31Ok6JC+rQWWNMNDATSAD2A1dZa7cX0K45MNta29a9/TjQ0V1cD9hjrT3FGPME0MO9L4DzrbUV//ACEakwfD4fD1zUjnXbDzD2tRW8NeY0WtSN9TpWiQn2m8VoIM1a2wuYAYzL38AYMxR4FaidN89ae7O1NgU4G9gLjHQXdQb6WmtT3B8VChEpd6IiwnhmaDJREWGMnLGUvRlHvY5UYoItFj2BD93pOUCfAtrsBnoX0v8vwMfW2jRjjB9oATxrjFlgjBkeZCYREc/Vj4/m6Ss68/OeQ9zwyjKycyrGDm9fUXvujTEjgLH5Zm8FbrDWprtv9huttYmF9N9ira0XcLsKkAZ0s9buNcbEAjcBjwJhwFxguLX228D7SU1NzY2JiSneX+fKzMwkKioqqL6lSbmKR7mKJ1RzQehmK8lcc77fxxOLdjCwTTwjutTyJFdGRgbJycm+E3pwV5H7LKy1U4GpgfOMMbOAvI1xscCeYjxmH2BewKamDGCitTbDve/PgA7At/k7JiUlFeNhfpOenh5039KkXMWjXMUTqrkgdLOVZK6kJNidu5IXF2+gZ9uTuaBTwzLPlZqaGvRj5hfsZqgFwLnudD/gy2L07YOz6SpPS2C+MSbMGBOBs4lrWZC5RERCxt0DWtPt5Jrc/ua3pG0q37tigy0Wk4E2xpj5wLXAfQDGmAnGmG5F9DXAD3k3rLXpwEvAYuALYIa19rsgc4mIhIyIMD//ubwztatFcu2LS9m+/7DXkYIW1KGz7iajQQXMv62AefXy3e5fQJsJwIRgsoiIhLLa1SJ5ZmgyA59eyOiZqbw88hSqhJe/U9zKX2IRkXKmbcN4HhrYgaUbdnPvu+Vzw4muZyEiUgYGdGjAql/2MfnzdbSuH8cVp5zkdaRi0TcLEZEy8tc/GVJMHe595zuWrN/ldZxiUbEQESkjYX4fEwd3olHNGK5/eRnbytE1MFQsRETKUHx0BE9fkcyBzCzGvLSMo9k5Xkc6LioWIiJlzNSL5cGB7Vm6YTfj30/3Os5xUbEQEfHAeR0aMLzHyUxb+CNvr/jZ6zhFUrEQEfHInee2oluTmtzxZhqrt+zzOs4xqViIiHgkIszPpMs7ERsVznUvprL3UOgOaa5iISLioYTYKJ66vDObdh/i1tdXkBOiQ5qrWIiIeKxrk5rc1T+J/6VvY/IX67yOUyAVCxGREHD1aU04v2MDHv7YMu/7P1yl2nMqFiIiISDvGt4tE2K58dXl/LQrw+tIv6NiISISImKqhPP00GSys3MZ89IyMo9mex3pVyoWIiIh5OTaVXn00o6k/byXe94OnRFqVSxERELM2a3rcsMZzXlt6U+8umSj13EAFQsRkZA09uyWpJg6zFoWGmd3B3U9C2NMNDATSAD2A1dZa7fna/MQzvW0w4FnrbVTjDG1gZeBaGAzMMxam2GMGQmMArKA+6217wX7B4mIVARhfh8vXN2VjCPZbPxhjddxgv5mMRpIs9b2AmYA4wIXGmPOAJpba0/FKRi3G2NqAHcDL7v9lgOjjDH1gBuBHkBf4AFjTGSQuUREKgyfz0fVyNC4Rl2wxaIn8KE7PQfok2/5ImC4O50LhAFHC+nXDVhgrT1srd0LrAXaB5lLRERKQZElyxgzAhibb/ZWYK87vR+ID1xorc0EMo0xEcB0nM1QB4wxcQX0C5xX4P3lSU8PbijfzMzMoPuWJuUqHuUqnlDNBaGbTbkKV2SxsNZOBaYGzjPGzAJi3ZuxwJ78/dzNTm8An1trH3Bn73PbHwrolzcvT4H3B5CUlFRU3AKlp6cH3bc0KVfxKFfxhGouCN1sFS1XampqiWUIdjPUAuBcd7of8GXgQncH+KfA89bafxbRbwnQyxgTZYyJB5KAlUHmEhGRUhDsnpPJwHRjzHzgCDAEwBgzAefbRA+gKTDSPdIJYBhwv9tvJLADGGKtPWiMeQKncPiBu9zNWCIiEiKCKhbW2gxgUAHzb3MnlwCPFdL9nAL6TQGmBJNFRERKn07KExGRIvlyc0PzQhv5paamlo+gIiIhJDk52VcS91NuioWIiHhHm6FERKRIKhYiIlIkTwcdMcb4gf8AHYDDwDXW2rUBy/8wwGBxBiM8wbb7gTZATZzDgw8GtB0L3Av4gBU4R3jFlHGuOsABd719YK29z+3/FJAJbADeAx4p41yNcE6q3OH+G8/HGfrFq/U1HJgG/Aln6BnrPt8uwDlqb4ObMxd41Vp7bWk9x9zHwRhzM1APqO5mqeY+/kGcc5OmGGPGAONxhsqxOOcn5ZZxrnic534G8C0wBhgBTHT7bwCWAn8r41x13HWRNxzrKOAsj9dXF6C5+9iHgI7AHUA2ZfeabAw8j/O+7gOutdZaY8wAnHH5svjt+VXkYLD5ebrPwhhzEXCetfZqY8wpwJ3W2vPdZfWAT3D+CVHAfHf6IWCZtXaaMeYOnDfLV0q47YuAAc5zl6cDV7jT/YFlOE+E/+I8OR4GGpdhrsHA+8D3wIU456iMA57GGVtriBfry1rbzRjzDbDZWtsv4P+40qP1dQfQEvAHPMeeBNZYa4cYYwbhnDPUsIyeY36cQ8S7A2k4oxeMBH5wb1+Ac+LqcOBj4Dl3XaUB7wA5ZZhrNLAGWGGt/bMx5hWc8dxuw3nT6e3F+nL/jx8CUdbalIDn2HIv11fgexjwb5zCdQUwl7J7TT4LvGWtnW2M6YtTTC7Fef/qivNhZAEwwM0TZ6291xgzGDjVWnsTx+D1ZqhfBxa01i7G+YPzFDbAYHEGIwy2bS5Ode4G/A/oHNB2oLv8PXfedzgv8rLM9RPQC+hirc0BInCKyEagPjAb59PXn8syl/tNsR6QYoxZYIwZ7vb3an3NAVICbqfhfOK70b3dH+eNL++N+acSeLxjtY3CGaV5PJDo9kty10kHa+0RnBf+FTifTt93+3+DM+JBWeY6DCQDndz7CAea4HxAicYp/PVw3nTKMhfASUB3Y8x8Y8ydbn+v11fge9iTOMW2C2X7mrwV50Nk3v8rE+f5tdZauzvg+dWrkPs9Jq+LRf5BBLONMeGFLCto4MGiBiMMtm2k+5M3Ly/Xfpx/eHhA271lnctae9Rau8PN9QjOp6oDwDbgAWvtGTibe/5VxuurKs4LZQfOG/EYnE1TXq2v/Tibu/Juj8DZpJI39tgunLHLeuO8mNuUZjb3BftxwDrbS8HPsVo4r828+9jttiuzXNbaHGvtVjfXTTibyn5wszyMczmB+ThvmGW5vgBeBXYCZ+O86Z3u9foKaFMFWGWttW7/MntNWmt3WGuPGmMMzv/ovmLe7zF5XSzyDyLot9ZmFbKsoIEHixqMMNi2h3Gqct68vFyxwHacT6N5beM9yIUxJgqojfMiHuO2Owi87bY9hLO/pSxzZeBsz/ZZa/cAn+EUV6/WV6ybKe/25UBGwHPsK5w3FoC3cN6kSzNboMPu/IKeYztwNqHk3UcNnBd2WebK26dYA2d/wMVu/6PATGtt3vbrXfw2MGip5zLG+IDHAay1h3A+SdcjBNaXqyrwjDtd1q/JvGsJzQaGugWrOPd7TF4Xi18HFnS396UFLCtsgMHiDEYYbFs/zqaTJTg7Rr8LaPsmzs6j89157XC+zpVZLvcF8zmw0Vo7ylqb7fa/EPir278jzifBslxfLXH256S5w9P3xHnierW++uXddtvUwPl0l2cI0N8tvANw3nBK8zkWaJPbL91dJ6uNMVVwPiW/irOp5zy3f2ecwluWucApoLuAC6wzxM8Sdz09HvC/jAC+KMNccTibwla5r4MzcTajeL6+3PcwgIXu7zJ9TbqFYiJwjrV2qdsnHWhhjKkZ8PxaVMj9HpPXO7jzjoZqj/OGMgznD1hrrX3H3eN/Lc6b0b+stW8aY+riXCMj7xNY3mCEJd12O9AaqIvz6bQ6zieqO40xtwD34Bx5sQo4A+cTflnl6onzxrwU55PKIbdfN5yvnmHAeuASnE/OZbm+GuJ8aqkGzLHWjvF4fV2O85X8NJzty6flPcdwPpzMARrgFLtbrLVTS+s5hssYczXQyn1OtXf/h0fd2+9ba68zxlwP/BNns8Z6nE0uuWWY61Q329cBz7G7cV4P43E2v2wErgHWlfH6qoPzTbYq8JW19rIQWF/tcQpnNZyd33nvYTdRdq/Jb9z/yxY3orXWjjK/HQ3lxzka6iljTIx7v/VxB4O11ub1K5DO4BYRkSJ5vRlKRETKARULEREpkoqFiIgUScVCRESKpGIhIiJFUrEQEZEiqViIiEiRVCxEgmSMud4Y87I7Pd04w4qLVEg6KU/kBBhjZuOMqxNprb3M6zwipcXTix+JVAD/xhlrJ9nrICKlSZuhRILkDsz2OM5FZia7t0UqJBULkeA9iHNRp2dxBiT8t8d5REqN9lmIiEiR9M1CRESKpGIhIiJFUrEQEZEiqViIiEiRVCxERKRIKhYiIlIkFQsRESmSioWIiBTp/wHlAi1ZA5sG2gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2788a7f7898>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tragDF.plot(x='x', y='y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot moth at certain timesteps\n",
    "# plot final positions\n",
    "def plotMoth(x,y,theta, phi, F, alpha, tau0, fig, ax):\n",
    "    # plot moth and force\n",
    "\n",
    "    thoraxLen = 0.908 * 2# cm\n",
    "    abLen = 1.747 *2 #cm\n",
    "    bodyWidth = 1.1\n",
    "\n",
    "\n",
    "    # plot trajectory\n",
    "    #fig, ax = plt.subplots( figsize = [10,10])\n",
    "    ax.set_aspect('equal', 'datalim')\n",
    "    #ax.plot(x,y, label = 'trajectory x vs y')\n",
    "\n",
    "    center = np.array([x, y])\n",
    "    head = center + np.array(pol2cart(thoraxLen, theta))\n",
    "    abTip = center + np.array(pol2cart(abLen, phi))\n",
    "\n",
    "\n",
    "\n",
    "    xx, yy = zip(*[center, head])\n",
    "    xab,yab = zip(*[center, abTip])\n",
    "\n",
    "    el = Ellipse(midpoint(center, head), width = thoraxLen, height = bodyWidth, facecolor='#907760', alpha=0.9, angle = math.degrees(theta))\n",
    "    el2 = Ellipse(midpoint(center, abTip), width = abLen, height = bodyWidth, facecolor='#DEC9B0', alpha=0.9, angle = math.degrees(phi))\n",
    "    \n",
    "#     torqueArc = Arc([x,y], 1, 1, angle=0.0, theta1= np.degrees(theta), theta2=np.degrees(phi), color = \"#B61212\")\n",
    "    \n",
    "    \n",
    "    ax.add_artist(el)\n",
    "    ax.add_artist(el2)\n",
    "#     ax.add_artist(torqueArc)\n",
    "    \n",
    "#     # add torque arrow\n",
    "#     ax.arrow(x = x + 1, y = forceCenter[1], \n",
    "#              dx = forceTip[0] - forceCenter[0],  dy =  forceTip[1] - forceCenter[1], \n",
    "#             head_width = 0.2, color = \"#B61212\")\n",
    "\n",
    "\n",
    "\n",
    "    ax.plot(xx, yy, 'k', alpha = 0.2)\n",
    "    #ax.scatter(xx, yy, s= 10, c = 'k', alpha = 0.2)\n",
    "    ax.plot(xab,yab, 'k', alpha = 0.2)\n",
    "    #ax.scatter(xab,yab, s = 10, c = 'k', alpha = 0.2)\n",
    "\n",
    "    # plot force \n",
    "    forceAlpha = alpha\n",
    "    forceCenter = midpoint(center, head)\n",
    "    forceMagnitude = F / 15000 # scale \n",
    "    forceAngle = theta + forceAlpha\n",
    "    forceTip = np.add(pol2cart(forceMagnitude, forceAngle), forceCenter)\n",
    "    ax.arrow(x = forceCenter[0], y = forceCenter[1], \n",
    "             dx = forceTip[0] - forceCenter[0],  dy =  forceTip[1] - forceCenter[1], \n",
    "            head_width = 0.2, color = \"#B61212\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make tmp dir for images\n",
    "tmpDir2 = os.path.join(r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\Figs', \"MothVid_Velocity\")\n",
    "if not os.path.exists(tmpDir2):\n",
    "    os.mkdir(tmpDir2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tau0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "# plt.figure(figsize = [10,10])\n",
    "# plt.axes().set_aspect('equal', 'datalim')\n",
    "sns.set_style(\"whitegrid\", {'axes.grid' : True})\n",
    "\n",
    "maxFrms = len(x)\n",
    "\n",
    "xlim = [np.min(x[0:maxFrms+1])-5, np.max(x[0:maxFrms+1])+5]\n",
    "ylim =[np.min(y[0:maxFrms+1])-5, np.max(y[0:maxFrms+1])+5]\n",
    "xrng = np.diff(xlim)\n",
    "yrng = np.diff(ylim)\n",
    "maxrng = np.max([xrng, yrng])\n",
    "newxlim = [np.sum(xlim)/2 - maxrng /2, np.sum(xlim)/2 + maxrng /2]\n",
    "newylim = [np.sum(ylim)/2 - maxrng /2, np.sum(ylim)/2 + maxrng /2 ]\n",
    "\n",
    "\n",
    "for ii in np.arange(1, maxFrms, 1):\n",
    "    fig, ax = plt.subplots( figsize = [10,10])\n",
    "\n",
    "    plt.plot(x[0:ii+1], y[0:ii+1], c= 'orange', label = \"Python\")\n",
    "    plotMoth(x[ii], y[ii],theta[ii], phi[ii], F, alpha, tau0, fig, ax)\n",
    "    \n",
    "\n",
    "    ax.set_ylim(newylim)\n",
    "    ax.set_xlim(newxlim)\n",
    "    ax.set_ylabel(\"vertical position (cm)\")\n",
    "    ax.set_xlabel(\"horizontal position (cm)\")\n",
    "    \n",
    "#     # add torque\n",
    "#     if tau0 < 0:\n",
    "#         marker = r'$\\circlearrowleft$'\n",
    "#     else:\n",
    "#         marker = r'$\\circlearrowright$'\n",
    "#     ax.plot(x[ii],y[ii], marker=marker,ms=tau0/100000,  color = \"#B61212\")\n",
    "    fig.savefig(os.path.join(tmpDir2, str(ii).zfill(4)+ \".png\"), dpi = 200, bbox_inches='tight')\n",
    "    # plt.legend()\n",
    "    plt.close()\n",
    "    if np.mod(ii, 10) == 0:\n",
    "        print(ii)\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make into video\n",
    "os.chdir(tmpDir2)\n",
    "\n",
    "os.system('ffmpeg -start_number 0 -r 30 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y 0000001_output_mothPath2.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import model and scaler\n",
    "modelPath = r\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels\\Opt_rmsprop__Dro_0.0__Num_512_512_512_16__Wei_0.0_velocity.h5\"\n",
    "model = load_model(modelPath)\n",
    "\n",
    "# read in scalers\n",
    "scalerX = pickle.load(open(\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput\\scalerX_veloc.pkl\", \"rb\"))\n",
    "scalerY = pickle.load(open(\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput\\scalerY_veloc.pkl\", \"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 512)               5632      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                8208      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 539,203\n",
      "Trainable params: 539,203\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # REFREF: check model loss\n",
    "\n",
    "# read in data\n",
    "trainDF = pd.read_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to be consistent with other code\n",
    "trainDF.rename(columns={\"x0\" : \"x_0\", \"y0\" : \"y_0\", \"phi0\" : \"phi_0\", \"theta0\" : \"theta_0\", \n",
    "                        \"xf\" : \"x_99\", \"yf\" : \"y_99\", \"phif\" : \"phi_99\", \"thetaf\" : \"theta_99\", \n",
    "                        \"xd0\" : \"x_dot_0\", \"yd0\" : \"y_dot_0\", \"phid0\" : \"phi_dot_0\", \"thetad0\": \"theta_dot_0\", \n",
    "                        \"xdf\" : \"x_dot_99\", \"ydf\": \"y_dot_99\", \"phidf\": \"phi_dot_99\", \"thetadf\": \"theta_dot_99\", \n",
    "                        \"tau0\" : \"tau\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to fx and fy\n",
    "trainDF[\"Fx\"] = trainDF.F * np.cos(trainDF.alpha)\n",
    "trainDF[\"Fy\"] = trainDF.F * np.sin(trainDF.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\",\n",
    "                   \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data \n",
    "scalerX = MinMaxScaler([-0.5, 0.5])  \n",
    "scalerY = MinMaxScaler([-0.5, 0.5])  \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1980102, 10)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtest_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1980102/1980102 [==============================] - 78s 39us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.00051971199936840299, 0.00051971199936840299]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(Xtest_scaled, Ytest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# calculate F and alpha from Fx and Fy\n",
    "\n",
    "# calculate alpha\n",
    "def quadrant(Fx, Fy):\n",
    "    if (Fx >= 0) & (Fy >= 0):\n",
    "        q = 1\n",
    "    elif (Fx < 0) & (Fy >= 0):\n",
    "        q = 2\n",
    "    elif (Fx < 0) & (Fy < 0):\n",
    "        q = 3\n",
    "    elif (Fx >= 0) & (Fy < 0):\n",
    "        q = 4\n",
    "    else:\n",
    "        q = 999999\n",
    "    return(q)\n",
    "\n",
    "\n",
    "def angleCalc(Fx, Fy, q):\n",
    "    fx = np.abs(Fx)\n",
    "    fy = np.abs(Fy)\n",
    "    \n",
    "    if q == 1:\n",
    "        alpha = np.arctan(fy/fx)\n",
    "    elif q == 2:\n",
    "        alpha = np.pi - np.arctan(fy/fx)\n",
    "    elif q == 3: \n",
    "        alpha = np.pi + np.arctan(fy/fx)\n",
    "    elif q == 4:\n",
    "        alpha = (2*np.pi) - np.arctan(fy/fx)\n",
    "    return(alpha)\n",
    "\n",
    "def F_alpha_calc (Fx, Fy):\n",
    "    q = quadrant(Fx, Fy)\n",
    "    alpha = angleCalc(Fx, Fy, q)\n",
    "    F = np.sqrt(Fx**2 + Fy**2)\n",
    "    return(F, alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "#inputData = # make dataset\n",
    "Xcols = [ \"phi_0\", \"theta_0\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\",\n",
    "                   \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# goalPositions = {\"phi_0\": [np.pi/2], \n",
    "#                  \"theta_0\": [3*np.pi/2],\n",
    "#                  \"x_dot_0\": [0], \n",
    "#                  \"y_dot_0\", \n",
    "#                  \"phi_dot_0\", \n",
    "#                  \"theta_dot_0\",\n",
    "#                  \"x_dot_99\", \n",
    "#                  \"y_dot_99\", \n",
    "#                  \"phi_dot_99\", \n",
    "#                  \"theta_dot_99\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'goalPositions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-75-c54313884712>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgoalDF\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgoalPositions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mgoalDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"x_99\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgoalDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"x_0\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgoalDF\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"y_99\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mgoalDF\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"y_0\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'goalPositions' is not defined"
     ]
    }
   ],
   "source": [
    "goalDF = pd.DataFrame(goalPositions)\n",
    "\n",
    "\n",
    "goalDF[\"x_99\"] = np.hstack([goalDF.loc[1:, \"x_0\"], 0])\n",
    "goalDF[\"y_99\"] = np.hstack([goalDF.loc[1:, \"y_0\"], 0])\n",
    "goalDF[\"phi_99\"] = np.hstack([goalDF.loc[1:, \"phi_0\"], 0])\n",
    "goalDF[\"theta_99\"] = np.hstack([goalDF.loc[1:, \"theta_0\"], 0])\n",
    "goalDF_ordered = goalDF.loc[ :, Xcols]\n",
    "goalDF_ordered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref calculate new x and y from error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'goalDF_ordered' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-77-f4a0baf31631>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# make video with pred\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# x,xd,y,yd,theta,thetad,phi,phid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mstate0_ICs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgoalDF_ordered\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mstate0_ICs\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'goalDF_ordered' is not defined"
     ]
    }
   ],
   "source": [
    "# make video with pred\n",
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "state0_ICs = goalDF_ordered.iloc[0, ]\n",
    "state0_ICs\n",
    "\n",
    "\n",
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "state0_ICs = [0.0, 0.0001, 0.0, 0.0001, np.pi, 0.0001, 0.0, 0.0001]\n",
    "state0_ICs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\", {'axes.grid' : True})\n",
    "\n",
    "overallCtr = 1\n",
    "\n",
    "\n",
    "# refref: maybe the derivatives should be in the input, so it doesn't go too fast\n",
    "\n",
    "# define initial position and goal position\n",
    "\n",
    "\n",
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "where_I_am = OrderedDict({\n",
    "                        \"x_0\": [0], \n",
    "                        \"x_dot_0\":[-0.0001], \n",
    "                        \"y_0\":[0], \n",
    "                        \"y_dot_0\": [0.0001]  ,\n",
    "                        \"theta_0\": [np.pi/2]  ,\n",
    "                        \"theta_dot_0\": [0.0001]  , \n",
    "                        \"phi_0\": [3*np.pi/2]   ,\n",
    "                        \"phi_dot_0\":[0.0001] })\n",
    "\n",
    "\n",
    "where_I_want2b = OrderedDict({\"x_99\": [0],\n",
    "                              \"y_99\": [0],\n",
    "                              \"phi_99\": [3*np.pi/2],\n",
    "                              \"theta_99\": [np.pi/2], \n",
    "                             \"x_dot_99\": [0.00001], \n",
    "                             \"y_dot_99\": [0.00001], \n",
    "                             \"x_dot_99\": [0.00001], \n",
    "                              \"theta_dot_99\": [0.00001], \n",
    "                             \"phi_dot_99\": [0.00001]})\n",
    "\n",
    "xList = []\n",
    "yList = []\n",
    "\n",
    "prevXY = [where_I_am[\"x_0\"][0], where_I_am[\"y_0\"][0]]\n",
    "\n",
    "goalXY = [where_I_want2b[\"x_99\"][0], where_I_want2b[\"y_99\"][0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x27890ff3128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize = [10,10])\n",
    "\n",
    "# don't pay attention to F, alpha, tau0\n",
    "plotMoth(where_I_am[\"x_0\"][0],where_I_am[\"y_0\"][0],where_I_am[\"theta_0\"][0], where_I_am[\"phi_0\"][0], F, alpha, tau0, fig, ax)\n",
    "plotMoth(where_I_want2b[\"x_99\"][0],\n",
    "         where_I_want2b[\"y_99\"][0],\n",
    "         where_I_want2b[\"theta_99\"][0],\n",
    "         where_I_want2b[\"phi_99\"][0], F, alpha, tau0, fig, ax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputData =  pd.DataFrame(OrderedDict(list(where_I_am.items()) + list(where_I_want2b.items())))\n",
    "inputData = inputData.loc[:, Xcols]\n",
    "#print(inputData)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ -567.71484375,  -783.34576416, -3044.12719727], dtype=float32)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# predict force needed to attain \n",
    "## scale data and transform\n",
    "X_scaled = scalerX.transform(inputData)\n",
    "\n",
    "\n",
    "## predict with nnet\n",
    "pred = model.predict(X_scaled[0, :].reshape(1, -1))\n",
    "\n",
    "# inverse transform\n",
    "pred_trans = scalerY.inverse_transform(pred)\n",
    "\n",
    "pred_trans[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Dropbox\\\\AcademiaDropbox\\\\mothMachineLearning_dataAndFigs\\\\Figs\\\\MothVid_Velocity'"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpDir2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 0\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 1\n",
      "0\n",
      "3\n",
      "6\n",
      "9\n",
      "12\n",
      "15\n",
      "18\n",
      "21\n",
      "24\n",
      "27\n",
      "loop 2\n"
     ]
    }
   ],
   "source": [
    "###### start of loop\n",
    "for jj in range(3):\n",
    "\n",
    "    inputData =  pd.DataFrame(OrderedDict(list(where_I_am.items()) + list(where_I_want2b.items())))\n",
    "    inputData = inputData.loc[:, Xcols]\n",
    "\n",
    "\n",
    "    # predict force needed to attain \n",
    "    ## scale data and transform\n",
    "    X_scaled = scalerX.transform(inputData)\n",
    "    \n",
    "    \n",
    "    ## predict with nnet\n",
    "    pred = model.predict(X_scaled[0, :].reshape(1, -1))\n",
    "\n",
    "    # inverse transform\n",
    "    pred_trans = scalerY.inverse_transform(pred)\n",
    "    Fx, Fy, tau0  = pred_trans[0]\n",
    "\n",
    "    # convert FX, Fy, back to F, alpha\n",
    "    # F, alpha = cart2pol(Fx, Fy)\n",
    "    F, alpha = F_alpha_calc(Fx, Fy)\n",
    "\n",
    "\n",
    "    # plug predictions into simulation\n",
    "    FAlphaTau_list = [F, alpha, tau0]\n",
    "\n",
    "    # x,xd,y,yd,theta,thetad,phi,phid\n",
    "    state0_ICs = [ v[0] for v in where_I_am.values() ]\n",
    "\n",
    "    x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)\n",
    "\n",
    "    # add previous position to x and y\n",
    "    x = x + prevXY[0]\n",
    "    y = y + prevXY[1]\n",
    "    \n",
    "    # plot actual position\n",
    "    xList.extend(x.tolist())\n",
    "    yList.extend(y.tolist())\n",
    "\n",
    "\n",
    "\n",
    "    maxFrms = len(x)\n",
    "\n",
    "\n",
    "\n",
    "    # refref: add x's to each plot\n",
    "    for ii in np.arange(0, maxFrms, 1):\n",
    "        fig, ax = plt.subplots(figsize = [10,10])\n",
    "\n",
    "        plt.plot(xList[:-(maxFrms-ii)], yList[:-(maxFrms-ii)], c= 'orange', label = \"moth trajectory\", alpha = 0.3)\n",
    "        #plt.plot(where_I_want2b[\"x_99\"], where_I_want2b[\"y_99\"], c= 'blue', label = \"Goal\", marker = \"o\", linewidth = 0)\n",
    "        plt.plot(goalXY[0], goalXY[1], c= 'blue', label = \"Goal\", marker = \"o\", linewidth = 0)\n",
    "        plotMoth(x[ii], y[ii],theta[ii], phi[ii], F, alpha, tau0, fig, ax)\n",
    "\n",
    "\n",
    "#         ax.set_ylim([-30, 30])\n",
    "#         ax.set_xlim([-30, 30])\n",
    "        ax.set_ylim([-80, 80])\n",
    "        ax.set_xlim([-80, 80])\n",
    "        ax.set_ylabel(\"vertical position (cm)\")\n",
    "        ax.set_xlabel(\"horizontal position (cm)\")\n",
    "        plt.legend()\n",
    "        fig.savefig(os.path.join(tmpDir2, str(overallCtr).zfill(4)+ \".png\"), dpi = 200, bbox_inches='tight')\n",
    "        #plt.show()\n",
    "        overallCtr += 1\n",
    "\n",
    "\n",
    "        plt.close()\n",
    "        if np.mod(ii, 3) == 0:\n",
    "            print(ii)\n",
    "\n",
    "\n",
    "\n",
    "    # calculate error and compute new initial position, but keep goal position the same\n",
    "\n",
    "    ### REFREF: may be calculating this incorrectly\n",
    "    ### where I am should always start at x_0, y_0 == (0, 0)\n",
    "    ### where I want to be should be the error....\n",
    "    \n",
    "    # update prevXY\n",
    "    prevXY = [x[-1], y[-1]]\n",
    "    \n",
    "    # x,xd,y,yd,theta,thetad,phi,phid\n",
    "    where_I_am2 = OrderedDict({\n",
    "                            \"x_0\": [0], \n",
    "                            \"x_dot_0\":[xd[-1]], \n",
    "                            \"y_0\":[0], \n",
    "                            \"y_dot_0\": [yd[-1]]  ,\n",
    "                            \"theta_0\": [theta[-1]]  ,\n",
    "                            \"theta_dot_0\": [thetad[-1]] , \n",
    "                            \"phi_0\": [phi[-1]]   ,\n",
    "                            \"phi_dot_0\":[phid[-1]] })\n",
    "\n",
    "\n",
    "    # calculate true position\n",
    "    actual_whereIam = OrderedDict({\n",
    "                            \"x\": [where_I_want2b[\"x_99\"] + x],\n",
    "                            \"y\":[where_I_want2b[\"x_99\"] + y]})\n",
    "    \n",
    "    # refref: i'm not sure this is right\n",
    "    \n",
    "    where_I_want2b2 = OrderedDict({\"x_99\": [ goalXY[0] - prevXY[0] ],\n",
    "                              \"y_99\": [goalXY[1] - prevXY[1]],\n",
    "                              \"phi_99\": [3*np.pi/2],\n",
    "                              \"theta_99\": [np.pi/2], \n",
    "                                  \"x_dot_99\": [0.00001], \n",
    "                             \"y_dot_99\": [0.00001], \n",
    "                             \"x_dot_99\": [0.00001], \n",
    "                              \"theta_dot_99\": [0.00001], \n",
    "                             \"phi_dot_99\": [0.00001]})\n",
    "    \n",
    "    # update whereIam\n",
    "    where_I_am = where_I_am2\n",
    "    where_I_want2b = where_I_want2b2\n",
    "    \n",
    "    \n",
    "\n",
    "    print(\"loop\", jj)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make video\n",
    "# make into video|\n",
    "os.chdir(tmpDir2)\n",
    "\n",
    "os.system('ffmpeg -start_number 1 -r 60 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y 0000000_output_mothPath_45deg.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_I_am"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prevXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "goalXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "where_I_want2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: do the same thing with a smaller, pruned network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make vid of multiple moth trajectoies\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "globalDict = OrderedDict({\"bhead\": 0.507,\n",
    "            \"ahead\": 0.908,\n",
    "            \"bbutt\": 0.1295,\n",
    "            \"abutt\": 1.7475, \n",
    "            \"rho\": 1, \n",
    "            \"rhoA\": 0.00118, \n",
    "            \"muA\": 0.000186, \n",
    "            \"L1\": 0.908, \n",
    "            \"L2\": 1.7475,  \n",
    "            \"L3\": 0.75,\n",
    "            \"K\": 29.3,\n",
    "            \"c\":  14075.8,\n",
    "            \"g\": 980.0,\n",
    "            \"betaR\":  0.0,\n",
    "            \"nstep\": 40,\n",
    "            \"nrun\" : 1  # (max) number of  trajectories.\n",
    "            })\n",
    "# Calculated variables\n",
    "globalDict['m1'] = globalDict['rho']*(4/3)*np.pi*(globalDict['bhead']**2)*globalDict['ahead']\n",
    "globalDict[\"m2\"] = globalDict[\"rho\"]*(4/3)*np.pi*(globalDict[\"bbutt\"]**2)*globalDict[\"abutt\"]\n",
    "globalDict[\"echead\"] = globalDict[\"ahead\"]/globalDict[\"bhead\"]\n",
    "globalDict['ecbutt'] = globalDict['abutt']/globalDict['bbutt']\n",
    "globalDict['I1'] = (1/5)*globalDict['m1']*(globalDict['bhead']**2)*(1 + globalDict['echead']**2)\n",
    "globalDict['I2'] = (1/5)*globalDict['m2']*(globalDict['bbutt']**2)*(1 + globalDict['ecbutt']**2)\n",
    "globalDict['S_head'] = np.pi*globalDict['bhead']**2\n",
    "globalDict['S_butt'] = np.pi*globalDict['bbutt'] **2\n",
    "t = np.linspace(0, 0.1, num = globalDict[\"nstep\"], endpoint = True)\n",
    "\n",
    "# convert dict to list, since @jit works better with lists\n",
    "globalList = [ v for v in globalDict.values() ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plug predictions into simulation\n",
    "FAlphaTau_list = [F, alpha, tau0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# x,xd,y,yd,theta,thetad,phi,phid\n",
    "state0_ICs = [0.0, 0.0001, 0.0, 0.0001, np.pi, 0.0001, 0.0, 0.0001]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "F, alpha, tau0 = (np.random.rand(3)* 1000).tolist()\n",
    "FAlphaTau_list = [F, alpha, tau0]\n",
    "\n",
    "\n",
    "state0_ICs = [0.0, 0.0001, 0.0, 0.0001, np.pi/2 - 0.3,0.0001, -np.pi/2 - 0.3,0.0001]\n",
    "state0_ICs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmpDir3 = os.path.join(r'D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019', \"MPC_Example\")\n",
    "if not os.path.exists(tmpDir3):\n",
    "    os.mkdir(tmpDir3)\n",
    "\n",
    "overallCtr2 = 1\n",
    "\n",
    "\n",
    "xlist = []\n",
    "ylist = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for pathNum in range(20):\n",
    "    F, alpha, tau0 = (np.random.rand(3)* 10000).tolist()\n",
    "    tau0 = tau0*10\n",
    "    FAlphaTau_list = [F, alpha, tau0]\n",
    "    x, xd, y, yd, theta, thetad, phi, phid = simUtils.flyBug_OneRun(t, state0_ICs, FAlphaTau_list, globalList)\n",
    "\n",
    "    xlist.extend(x)\n",
    "    ylist.extend(y)\n",
    "\n",
    "\n",
    "    for ii in np.arange(0, globalDict[\"nstep\"], 1):\n",
    "        fig, ax = plt.subplots(figsize = [10,10])\n",
    "\n",
    "        plt.scatter(xlist[:-(globalDict[\"nstep\"]-ii-1)], ylist[:-(globalDict[\"nstep\"]-ii-1)], c= 'orange', label = \"moth trajectory\", s = 2)\n",
    "        plotMoth(x[ii], y[ii],theta[ii], phi[ii], F, alpha, tau0, fig, ax)\n",
    "\n",
    "\n",
    "        ax.set_ylim([-30, 30])\n",
    "        ax.set_xlim([-30, 30])\n",
    "        ax.set_ylabel(\"vertical position (cm)\")\n",
    "        ax.set_xlabel(\"horizontal position (cm)\")\n",
    "        plt.legend()\n",
    "        fig.savefig(os.path.join(tmpDir3, str(overallCtr2).zfill(4)+ \".png\"), dpi = 200, bbox_inches='tight')\n",
    "        overallCtr2 += 1\n",
    "\n",
    "\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video\n",
    "# make into video|\n",
    "os.chdir(tmpDir3)\n",
    "\n",
    "os.system('ffmpeg -start_number 1 -r 30 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2, setpts=0.2*PTS\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y 0000000_MPCVID.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ii = 0\n",
    "xlist[:-(globalDict[\"nstep\"]-ii-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make training and test set"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# concatenate all files (only need to do this once)\n",
    "# it takes a few minutes\n",
    "all_files = glob.glob(os.path.join(randomRawData, \"*.csv\"))     \n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "concatenated_df   = pd.concat(df_from_each_file, ignore_index=True)\n",
    "\n",
    "# check for duplicates\n",
    "concatenated_df.drop_duplicates(inplace=True)\n",
    "concatenated_df.shape\n",
    "\n",
    "print(concatenated_df.shape)\n",
    "concatenated_df.tail()\n",
    "\n",
    "# save to hdf5\n",
    "concatenated_df.to_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "trainDF = pd.read_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: check for repeats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# double check for repeats!\n",
    "np.sum(trainDF.iloc[:, [16,17,18]].duplicated()) # 0 means no repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(trainDF.shape)\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to be consistent with other code\n",
    "trainDF.rename(columns={\"x0\" : \"x_0\", \"y0\" : \"y_0\", \"phi0\" : \"phi_0\", \"theta0\" : \"theta_0\", \n",
    "                        \"xf\" : \"x_99\", \"yf\" : \"y_99\", \"phif\" : \"phi_99\", \"thetaf\" : \"theta_99\", \n",
    "                        \"xd0\" : \"x_dot_0\", \"yd0\" : \"y_dot_0\", \"phid0\" : \"phi_dot_0\", \"thetad0\": \"theta_dot_0\", \n",
    "                        \"xdf\" : \"x_dot_99\", \"ydf\": \"y_dot_99\", \"phidf\": \"phi_dot_99\", \"thetadf\": \"theta_dot_99\", \n",
    "                        \"tau0\" : \"tau\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to fx and fy\n",
    "trainDF[\"Fx\"] = trainDF.F * np.cos(trainDF.alpha)\n",
    "trainDF[\"Fy\"] = trainDF.F * np.sin(trainDF.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data \n",
    "scalerX = MinMaxScaler([-0.5, 0.5])  \n",
    "scalerY = MinMaxScaler([-0.5, 0.5])  \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Xtrain_scaled, columns = X.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scalers, to be used on test set\n",
    "scalerfileX = 'scalerX.pkl'\n",
    "pickle.dump(scalerX, open(os.path.join(dataOutput, scalerfileX), 'wb'))\n",
    "\n",
    "scalerfileY = 'scalerY.pkl'\n",
    "pickle.dump(scalerY, open(os.path.join(dataOutput, scalerfileY), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#model.get_config()\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=150, \n",
    "                          verbose=1, mode='auto', min_delta = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: start with small network and then build up\n",
    "# refref: start with large network and prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network\n",
    "def create_network(optimizer = 'rmsprop', \n",
    "                    numUnits = [32, 32, 32, 32], \n",
    "                    weightRegularization = 0.0, \n",
    "                    dropout_rate=0.1):\n",
    "    \n",
    "    '''\n",
    "    Create a feed forward network.  Assumes Xtrain & Ytrain have been created and scaled\n",
    "    \n",
    "    Params: \n",
    "    optimizer (str): choice of optimizer\n",
    "    numUnits (list): number of units in each hidden\n",
    "    weightRegularization (float): between 0 and 1\n",
    "    dropout_rate (float): between 0 and 1\n",
    "    \n",
    "    '''\n",
    "    K.clear_session()\n",
    "    inputs = Input(shape=(Xtrain_scaled.shape[1],))    \n",
    "    \n",
    "    # add layers\n",
    "    for ii in np.arange(0, len(numUnits)):\n",
    "        if ii >= 1: \n",
    "            x = Dense(numUnits[ii], activation='tanh', \n",
    "                      kernel_regularizer=regularizers.l1(weightRegularization))(x)\n",
    "\n",
    "        else: \n",
    "            x = Dense(numUnits[ii], activation='tanh')(inputs)\n",
    "\n",
    "\n",
    "        # add dropout\n",
    "        if dropout_rate > 0: \n",
    "            x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "    # create model\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer = optimizer, metrics = ['mse'])\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "\n",
    "# model = load_model(r\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels\\Opt_rmsprop__Dro_0.0__Num_400_400_400_16__Wei_0.0.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelParams = {\"optimizer\": \"rmsprop\", \n",
    "              \"dropout_rate\" : 0, \n",
    "               \"numUnits\": [400, 400, 400, 16],\n",
    "               \"weightRegularization\": 0\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "model = create_network(**modelParams)\n",
    "\n",
    "modelName = ''.join('{}_{}__'.format(key[0:3].capitalize(), val) for  key, val in modelParams.items()).replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \"_\")[0:-2]+ \"_\" + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\")\n",
    "print(modelName)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show random weight matrices\n",
    "# show images for matrices\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2-5:256//2+5, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 200, 400])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 413])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"RandomWeightMatrices\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "historyDict = {\"mean_squared_error\": [], \n",
    "               \"val_mean_squared_error\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=15, \n",
    "                          verbose=1, mode='auto', min_delta = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit model without regularization\n",
    "stt = time.time()\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 1000, verbose = 2, \n",
    "                        batch_size=2**14, callbacks = [earlystop], validation_split = 0.3)\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)\n",
    "endd = time.time() - stt\n",
    "print(endd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historyDict[\"mean_squared_error\"].extend(history.history[\"mean_squared_error\"][0:])\n",
    "historyDict[\"val_mean_squared_error\"].extend(history.history[\"val_mean_squared_error\"][0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: save history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        plt.ylim([0.0001, 0.05])\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_NOTpruned_2.png\"), dpi = 120, bbox_inches='tight')\n",
    "        print(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "    \n",
    "plot_model_history_fromDict(historyDict, saveFig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "# if I need to remake, use this\n",
    "# wtsPath = \"D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019\\Opt_rmsprop__Dro_0__Num_400_400_400_16__Wei_0_2019_05_30__11_59_54_wts.pkl\"\n",
    "# wts =  pickle.load(open(wtsPath, 'rb'))\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2 + 1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 200, 400])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 413])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"TrainedWeightMatrices\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# refref: plot predictions on test set and make figures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "# apply same transformation to test data\n",
    "# Xtest_scaled = scalerX.transform(Xtest)\n",
    "# Ytest_scaled = scalerY.transform(Ytest)\n",
    "\n",
    "\n",
    "Ytest_pred = model.predict(Xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]\n",
    "\n",
    "\n",
    "# make data frames\n",
    "XtestDF = pd.DataFrame(scalerX.inverse_transform(Xtest_scaled), columns = X.columns)\n",
    "YtestDF = pd.DataFrame(scalerY.inverse_transform(Ytest_scaled), columns = Y.columns)\n",
    "YpredDF = pd.DataFrame(scalerY.inverse_transform(Ytest_pred), columns = Y.columns+ \"_pred\")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df_c = pd.concat([YtestDF.reset_index(drop=True), YpredDF], axis=1)\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_c = df_c[0:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array([30, 10]) / 1.3, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.2, wspace=0.7)\n",
    "#fig.suptitle('Predicted vs. acutal ', fontsize=14, fontweight='bold')\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "ylabs = [r\"g*cm/$s^2$\", r\"g*cm/$s^2$\", r\"g*$cm^2$/$s^2$\", \"cm/s\", \"cm/s\", \"rad/s\", \"rad/s\"]\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(df_c.shape[1] //2):\n",
    "    try:\n",
    "        axs[ii].hexbin(y = df_c.iloc[:,ii],x = df_c.iloc[:,ii + 7], gridsize = 50, cmap = cmap)\n",
    "        #axs[ii].set_xlabel(\"Predicted Value\\n(unscaled)\")\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\\n\" + ylabs[ii])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[ii])\n",
    "        axs[ii].set_title(df_c.columns[ii])\n",
    "        axs[ii].plot(df_c.iloc[:,ii], df_c.iloc[:,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "        \n",
    "        # annotate with R^2\n",
    "        axs[ii].text(np.max(df_c.iloc[:,ii])*0.1, np.min(df_c.iloc[:,ii])*0.9, r'$r^2$ =' + str(np.round((r2_score(df_c.iloc[:,ii ],  df_c.iloc[:,ii+7])), 3)))\n",
    "        axs[ii].set_xlim([-np.max(np.abs(df_c.iloc[:,ii+7])), np.max(np.abs(df_c.iloc[:,ii+7]))])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# # residual plots x = predicted, y = actual - predicted\n",
    "for jj in range(df_c.shape[1] //2):\n",
    "    \n",
    "    ii = jj + 7\n",
    "    try:\n",
    "        axs[ii].hexbin(x = df_c.iloc[:,jj],\n",
    "                     y = df_c.iloc[:,jj ] - df_c.iloc[:,jj+7], gridsize = (35, 50), cmap = cmap)\n",
    "        axs[ii].set_xlabel(\"Predicted Value\")\n",
    "\n",
    "        if(jj == 0):\n",
    "            axs[ii].set_ylabel(\"Actual - Predicted\\n\" + ylabs[jj])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[jj])\n",
    "        \n",
    "        axs[ii].hlines(y = 0, xmin = np.min( df_c.iloc[:,jj+7]), \n",
    "                       xmax = np.max( df_c.iloc[:,jj+7]), linestyle =  \"--\", linewidth = 1)\n",
    "        axs[ii].set_ylim([-np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7])), np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7]))])\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "fig.savefig(os.path.join(figDir, \"PredVActual_\" + modelName + \".png\"), dpi = 500, bbox_inches='tight')\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#(y_true, y_pred, sample_weight=None, multioutput=uniform_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save model\n",
    "model.save(os.path.join(figDir,  modelName + '_notPruned.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_wts.pkl'\n",
    "pickle.dump(wts, open(os.path.join(figDir, wtsFile), 'wb'))\n",
    "\n",
    "# save history\n",
    "histName = modelName + '_history.pkl'\n",
    "pickle.dump(historyDict, open(os.path.join(figDir, histName), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jj in range(7):\n",
    "    print (r2_score(df_c.iloc[:,jj ],  df_c.iloc[:,jj+7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## START NEW ITEM: train and trim weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and trim weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "#wts =  pickle.load(open(os.path.join(dataOutput, wtsFile), 'rb'))\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    print(wts[ii].shape)\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # start training\n",
    "# historyDict = {\"mean_squared_error\": [], \n",
    "#                \"val_mean_squared_error\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start pruning\n",
    "modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numCuts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: \n",
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "def prune_percent_updater(x):\n",
    "    logit = np.exp(x*8) / (np.exp(x*8) + 1)\n",
    "    return((logit - 0.5)*2*50)\n",
    "\n",
    "\n",
    "# cuts a smaller portion as the percent gets closer to 100%\n",
    "cutPercent = prune_percent_updater(np.linspace(0, 1, 26))\n",
    "\n",
    "while True:   \n",
    "   \n",
    "    for numEpocs in range(100):\n",
    "        \n",
    "        MSE_tmp = []\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                            callbacks = [earlystop])\n",
    "        \n",
    "        # refref: earlystop doesn't do anything here\n",
    "        \n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "        \n",
    "        # local MSE\n",
    "        MSE_tmp.append(history.history[\"mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 1):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent[numCuts], 50 + cutPercent[numCuts]), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        \n",
    "        # check the change in mean squared error, and if it's not changing much, then cut out more data\n",
    "        # calculate slope of loss, based on previous 5 data points\n",
    "        if numEpocs > 5:\n",
    "            inputData = historyDict[\"mean_squared_error\"][-5:]\n",
    "\n",
    "            m = np.shape(inputData)\n",
    "            X = np.matrix([np.ones(m), np.arange(0, len(inputData))]).T\n",
    "            y = np.matrix(np.log(inputData)).T\n",
    "\n",
    "            # Solve for projection matrix\n",
    "            intercept, slope = np.array(np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)).reshape(-1,)\n",
    "            print(\"change in log loss:\", slope)\n",
    "    \n",
    "            # break if slope has stopped changing or if the overall min has been surpassed\n",
    "            # in the first training, it will automatically prune after 5 epochs, because the min will be passed\n",
    "            if (np.abs(slope) < 0.0001) or (history.history[\"mean_squared_error\"][0] < np.min(historyDict[\"mean_squared_error\"][:-1])): \n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                model.save(os.path.join(figDir,  modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'))\n",
    "                break\n",
    "                       \n",
    "                    \n",
    "    ## refref: may want to save weights before each pruning, so I can go back, if I need to\n",
    "    ## refref: should I be pruning the biases too?\n",
    "    \n",
    "    ## keep running tally of min mse, and if we can't get back to the min, then break\n",
    "#     print(\"Min MSE for this prune \", np.min(MSE_tmp), \"______overall Min MSE \", np.min(historyDict[\"mean_squared_error\"]))\n",
    "#     if np.min(MSE_tmp) > np.min(historyDict[\"mean_squared_error\"]):\n",
    "#         print(\"no more gain by pruning:  STOPPING Pruning\")\n",
    "#         break\n",
    "    \n",
    "    numCuts += 1\n",
    "    if numCuts >= len(cutPercent):\n",
    "        break\n",
    "\n",
    "        \n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numCuts)\n",
    "(50 - cutPercent[numCuts]) * 2 # percent of original network size that is used the pruned version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save model\n",
    "model.save(os.path.join(figDir,  modelName + '_Pruned.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_wts_pruned.pkl'\n",
    "pickle.dump(wts, open(os.path.join(figDir, wtsFile), 'wb'))\n",
    "\n",
    "# save history\n",
    "histName = modelName + '_history_pruned.pkl'\n",
    "pickle.dump(historyDict, open(os.path.join(figDir, histName), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numCuts = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        plt.ylim([0.0001, 0.05])\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"), dpi = 120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "    \n",
    "plot_model_history_fromDict(historyDict, saveFig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(dictLen).zfill(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video of training\n",
    "tmpDir = os.path.join(figDir, \"tmpImgs\")\n",
    "if not os.path.exists(tmpDir):\n",
    "    os.mkdir(tmpDir)\n",
    "fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "#for dictLen in np.arange(1, len(historyDict[\"mean_squared_error\"])):\n",
    "for dictLen in range(300):\n",
    "\n",
    "    # save images\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(historyDict['mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "             historyDict['mean_squared_error'][dictLen-1:dictLen])\n",
    "    axs.plot(range(1,len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "             historyDict['val_mean_squared_error'][dictLen-1:dictLen])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(historyDict['val_mean_squared_error'][dictLen])))\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "#     axs.set_xticks(np.arange(1,len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "#                    len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])//10)\n",
    "    axs.legend(['train', 'val'], loc='lower left')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "\n",
    "    plt.ylim([0.0001, 0.05])\n",
    "    fig.savefig(os.path.join(tmpDir, str(dictLen).zfill(4)+ \".png\"), dpi = 120,  pad_inches = 0.5)\n",
    "    #plt.close()\n",
    "    \n",
    "    if np.mod(dictLen, 100) == 0:\n",
    "        print(dictLen)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video of training\n",
    "tmpDir = os.path.join(figDir, \"tmpImgs\")\n",
    "if not os.path.exists(tmpDir):\n",
    "    os.mkdir(tmpDir)\n",
    "fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "for dictLen in np.arange(1, len(historyDict[\"mean_squared_error\"])):\n",
    "#for dictLen in np.arange(1, 100):\n",
    "\n",
    "    # save images\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    axs.plot([dictLen -1, dictLen],\n",
    "             historyDict['mean_squared_error'][dictLen-1:dictLen+1], c= \"C0\")\n",
    "    axs.plot([dictLen -1, dictLen],\n",
    "             historyDict['val_mean_squared_error'][dictLen-1:dictLen+1], c= \"C1\")\n",
    "    axs.set_title('Model MSE = '+ str(format_e(historyDict['val_mean_squared_error'][dictLen])))\n",
    "    axs.set_ylabel('mean squared error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "#     axs.set_xticks(np.arange(1,len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "#                    len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])//10)\n",
    "    axs.legend(['train', 'val'], loc='lower left')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "\n",
    "    plt.ylim([0.0001, 0.05])\n",
    "    fig.savefig(os.path.join(tmpDir, str(dictLen).zfill(4)+ \".png\"), dpi = 120,  pad_inches = 0.5)\n",
    "    #plt.close()\n",
    "    #plt.show()\n",
    "    \n",
    "    if np.mod(dictLen, 100) == 0:\n",
    "        print(dictLen)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make into video\n",
    "os.chdir(tmpDir)\n",
    "\n",
    "os.system('ffmpeg -start_number 0   -r 50 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264 -b:v 10000k  -pix_fmt yuv420p -y  0000000_output_epochs.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest_pred = model.predict(Xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data frames\n",
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]\n",
    "\n",
    "XtestDF = pd.DataFrame(scalerX.inverse_transform(Xtest_scaled), columns = X.columns)\n",
    "YtestDF = pd.DataFrame(scalerY.inverse_transform(Ytest_scaled), columns = Y.columns)\n",
    "YpredDF = pd.DataFrame(scalerY.inverse_transform(Ytest_pred), columns = Y.columns+ \"_pred\")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df_c = pd.concat([YtestDF.reset_index(drop=True), YpredDF], axis=1)\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(historyDict[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = df_c.iloc[0:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array([30, 10]) / 1.3, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.2, wspace=0.7)\n",
    "#fig.suptitle('Predicted vs. acutal ', fontsize=14, fontweight='bold')\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "ylabs = [r\"g*cm/$s^2$\", r\"g*cm/$s^2$\", r\"g*$cm^2$/$s^2$\", \"cm/s\", \"cm/s\", \"rad/s\", \"rad/s\"]\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(df_c.shape[1] //2):\n",
    "    try:\n",
    "        axs[ii].hexbin(y = df_c.iloc[:,ii],x = df_c.iloc[:,ii + 7], gridsize = 50, cmap = cmap)\n",
    "        #axs[ii].set_xlabel(\"Predicted Value\\n(unscaled)\")\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\\n\" + ylabs[ii])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[ii])\n",
    "        axs[ii].set_title(df_c.columns[ii])\n",
    "        axs[ii].plot(df_c.iloc[:,ii], df_c.iloc[:,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "        \n",
    "        # annotate with R^2\n",
    "        axs[ii].text(np.max(df_c.iloc[:,ii])*0.1, np.min(df_c.iloc[:,ii])*0.9, r'$r^2$ =' + str(np.round((r2_score(df_c.iloc[:,ii ],  df_c.iloc[:,ii+7])), 3)))\n",
    "        axs[ii].set_xlim([-np.max(np.abs(df_c.iloc[:,ii+7])), np.max(np.abs(df_c.iloc[:,ii+7]))])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# # residual plots x = predicted, y = actual - predicted\n",
    "for jj in range(df_c.shape[1] //2):\n",
    "    \n",
    "    ii = jj + 7\n",
    "    try:\n",
    "        axs[ii].hexbin(x = df_c.iloc[:,jj],\n",
    "                     y = df_c.iloc[:,jj ] - df_c.iloc[:,jj+7], gridsize = (35, 50), cmap = cmap)\n",
    "        axs[ii].set_xlabel(\"Predicted Value\")\n",
    "\n",
    "        if(jj == 0):\n",
    "            axs[ii].set_ylabel(\"Actual - Predicted\\n\" + ylabs[jj])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[jj])\n",
    "        \n",
    "        axs[ii].hlines(y = 0, xmin = np.min( df_c.iloc[:,jj+7]), \n",
    "                       xmax = np.max( df_c.iloc[:,jj+7]), linestyle =  \"--\", linewidth = 1)\n",
    "        axs[ii].set_ylim([-np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7])), np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7]))])\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "fig.savefig(os.path.join(figDir, \"PredVActual_\" + str(len(historyDict[\"mean_squared_error\"])) +  modelName + \".png\"), dpi = 500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2+1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 200, 400])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 413])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"Pruned_WeightMatrices\" + str(len(historyDict[\"mean_squared_error\"]))  + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show example small network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelParams = {\"optimizer\": \"rmsprop\", \n",
    "              \"dropout_rate\" : 0, \n",
    "               \"numUnits\": [20, 20, 16],\n",
    "               \"weightRegularization\": 0\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "model = create_network(**modelParams)\n",
    "\n",
    "modelName = ''.join('{}_{}__'.format(key[0:3].capitalize(), val) for  key, val in modelParams.items()).replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \"_\")[0:-2]+ \"_\" + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\")\n",
    "print(modelName)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2 + 1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "\n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])   \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "        axs[jj].axes.set_ylim([-1, 21])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "              \n",
    "    if ii == 7:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"RondomWTS_small\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit model without regularization\n",
    "stt = time.time()\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 10, verbose = 2, \n",
    "                        batch_size=2**14, callbacks = [earlystop], validation_split = 0.3)\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)\n",
    "endd = time.time() - stt\n",
    "print(endd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctr = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for ii in range(100):\n",
    "    \n",
    "        # # fit model without regularization\n",
    "    stt = time.time()\n",
    "    history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 10, verbose = 2, \n",
    "                            batch_size=2**14, callbacks = [earlystop], validation_split = 0.3)\n",
    "    winsound.PlaySound(\"*\", winsound.SND_ALIAS)\n",
    "    endd = time.time() - stt\n",
    "    print(endd)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    wts = model.get_weights().copy()\n",
    "\n",
    "    # if I need to remake, use this\n",
    "    # wtsPath = \"D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019\\Opt_rmsprop__Dro_0__Num_400_400_400_16__Wei_0_2019_05_30__11_59_54_wts.pkl\"\n",
    "    # wts =  pickle.load(open(wtsPath, 'rb'))\n",
    "\n",
    "    plt.close(\"all\")\n",
    "    fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "    fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "    axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "    PRGn = cm.get_cmap('PRGn', 256)\n",
    "    newcolors = PRGn(np.linspace(0, 1, 256))\n",
    "    white = np.array([0.8, 0.8, 0.8, 1])\n",
    "    newcolors[256//2:256//2 + 1, :] = white\n",
    "    newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "\n",
    "    for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if len(wts[ii].shape) < 2: \n",
    "            wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "        else:\n",
    "            wtsTmp = wts[ii].copy()\n",
    "\n",
    "        im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                                  vmin=-3.0, vmax=3.0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if np.mod(ii+1, 2) == 0:\n",
    "            axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 1])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "\n",
    "\n",
    "\n",
    "        if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 21])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            #axs[jj].axis('off')\n",
    "\n",
    "\n",
    "        if ii == 7:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([0])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "\n",
    "        if ii == 0:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "    cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "    cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "\n",
    "    ctr += 1\n",
    "\n",
    "    plt.savefig(os.path.join(figDir, \"TrainedWts_small_\"+ str(ctr) + modelName  + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveWeightImages(model):\n",
    "    \n",
    "     wts = model.get_weights().copy()\n",
    "\n",
    "    # if I need to remake, use this\n",
    "    # wtsPath = \"D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019\\Opt_rmsprop__Dro_0__Num_400_400_400_16__Wei_0_2019_05_30__11_59_54_wts.pkl\"\n",
    "    # wts =  pickle.load(open(wtsPath, 'rb'))\n",
    "\n",
    "    plt.close(\"all\")\n",
    "    fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "    fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "    axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "    PRGn = cm.get_cmap('PRGn', 256)\n",
    "    newcolors = PRGn(np.linspace(0, 1, 256))\n",
    "    white = np.array([0.8, 0.8, 0.8, 1])\n",
    "    newcolors[256//2:256//2 + 1, :] = white\n",
    "    newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "\n",
    "    for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if len(wts[ii].shape) < 2: \n",
    "            wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "        else:\n",
    "            wtsTmp = wts[ii].copy()\n",
    "\n",
    "        im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                                  vmin=-3.0, vmax=3.0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        if np.mod(ii+1, 2) == 0:\n",
    "            axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 1])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "\n",
    "\n",
    "\n",
    "        if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 21])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            #axs[jj].axis('off')\n",
    "\n",
    "\n",
    "        if ii == 7:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([0])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "\n",
    "        if ii == 0:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "    cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "    cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "\n",
    "\n",
    "    plt.savefig(os.path.join(figDir, \"TrainedWts_small_\"+ str(ctr) + modelName  + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    print(wts[ii].shape)\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "numCuts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: \n",
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "def prune_percent_updater(x):\n",
    "    logit = np.exp(x*8) / (np.exp(x*8) + 1)\n",
    "    return((logit - 0.5)*2*50)\n",
    "\n",
    "\n",
    "# cuts a smaller portion as the percent gets closer to 100%\n",
    "cutPercent = prune_percent_updater(np.linspace(0, 1, 26))\n",
    "\n",
    "while True:   \n",
    "   \n",
    "    for numEpocs in range(100):\n",
    "        \n",
    "        MSE_tmp = []\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                            callbacks = [earlystop])\n",
    "        \n",
    "        # refref: earlystop doesn't do anything here\n",
    "        \n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "        \n",
    "        # local MSE\n",
    "        MSE_tmp.append(history.history[\"mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 1):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent[numCuts], 50 + cutPercent[numCuts]), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        \n",
    "        # check the change in mean squared error, and if it's not changing much, then cut out more data\n",
    "        # calculate slope of loss, based on previous 5 data points\n",
    "        if numEpocs > 5:\n",
    "            inputData = historyDict[\"mean_squared_error\"][-5:]\n",
    "\n",
    "            m = np.shape(inputData)\n",
    "            X = np.matrix([np.ones(m), np.arange(0, len(inputData))]).T\n",
    "            y = np.matrix(np.log(inputData)).T\n",
    "\n",
    "            # Solve for projection matrix\n",
    "            intercept, slope = np.array(np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)).reshape(-1,)\n",
    "            print(\"change in log loss:\", slope)\n",
    "    \n",
    "            # break if slope has stopped changing or if the overall min has been surpassed\n",
    "            # in the first training, it will automatically prune after 5 epochs, because the min will be passed\n",
    "            if (np.abs(slope) < 0.0001) or (history.history[\"mean_squared_error\"][0] < np.min(historyDict[\"mean_squared_error\"][:-1])): \n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                model.save(os.path.join(figDir,  modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'))\n",
    "                break\n",
    "                       \n",
    "                    \n",
    "    ## refref: may want to save weights before each pruning, so I can go back, if I need to\n",
    "    ## refref: should I be pruning the biases too?\n",
    "    \n",
    "    ## keep running tally of min mse, and if we can't get back to the min, then break\n",
    "#     print(\"Min MSE for this prune \", np.min(MSE_tmp), \"______overall Min MSE \", np.min(historyDict[\"mean_squared_error\"]))\n",
    "#     if np.min(MSE_tmp) > np.min(historyDict[\"mean_squared_error\"]):\n",
    "#         print(\"no more gain by pruning:  STOPPING Pruning\")\n",
    "#         break\n",
    "    \n",
    "    numCuts += 1\n",
    "    if numCuts >= len(cutPercent):\n",
    "        break\n",
    "\n",
    "        \n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('viridis', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2 + 1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 21])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 7:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"PrunedWts_small\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how good can I get without trimming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot matrices\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "for ii in np.arange(0, len(wts), 2):\n",
    "    plt.matshow(wts[ii], cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot biases\n",
    "\n",
    "for ii in np.arange(1, len(wts), 2):\n",
    "    plt.matshow(wts[ii].reshape(1, -1), cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: save weights and model\n",
    "model.save(os.path.join(savedModels,  modelName + '_pruned_bias.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_pruned_wts_bias.pkl'\n",
    "pickle.dump(wts, open(os.path.join(dataOutput, wtsFile), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(1,5, figsize=(20, 5), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.2)\n",
    "\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 2)):\n",
    "    im = axs[jj].matshow(wts[ii], cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "    \n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"vertical\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(5,1, figsize=(30, 10), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "for jj, ii in enumerate(np.arange(1, len(wts), 2)):\n",
    "    im = axs[jj].matshow(wts[ii].reshape(1, -1), cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    axs[jj].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"horizontal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=(30, 10), facecolor='w', edgecolor='k', )\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.1)\n",
    "\n",
    "\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"horizontal\")\n",
    "plt.savefig(os.path.join(figDir, \"PrunedWeightMatrices.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(dataOutput, wtsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: if whole node is basically 0, then remove the node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(wts[2].reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_network(**modelParams)\n",
    "\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                        verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                        callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if model saved: \n",
    "K.clear_session()\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels, 'my_model_400Units_newData.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wts[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((20,3)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 100)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 100)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(Xtest_scaled, Ytest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (5, 95), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this is the original model\n",
    "inputs = Input(shape=(Xtrain_scaled.shape[1],))\n",
    "x = Dense(400, activation='tanh')(inputs)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(16, activation='tanh')(x)\n",
    "predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics = ['mse'])\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=50, \n",
    "                          verbose=1, mode='auto', min_delta = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "\n",
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (2, 98), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "model.set_weights(wts)\n",
    "\n",
    "\n",
    "# start training\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                    verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                    callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (2.5, 97.5), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "model.set_weights(wts)\n",
    "\n",
    "model.evaluate(Xtest_scaled, Ytest_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history.history['mean_squared_error'])+1),\n",
    "             model_history.history['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "             model_history.history['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE')\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "                   len(model_history.history['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    if saveFig:\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining.png\"), dpi = 120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "plot_model_history(history)\n",
    "print(history.history[\"loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model that was trained for much longer\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels, 'my_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "nzwts = [np.nonzero(wts[ii].reshape(-1))[0] for ii in range(len(wts))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((20,5)) , facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(nzwts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(nzwts[jj].shape))\n",
    "    axs[jj+1].hist(nzwts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(nzwts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((10,10)) , facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n",
    "#fig.savefig(os.path.join(figDir, \"SmallModelResids.png\"), dpi = 120, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim distribution of weights -- cut out middle 20%\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (40, 60), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show new histogram of weights (excluding the 0's)\n",
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array((15, 6)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    \n",
    "    d1 = wts[jj].reshape(-1)\n",
    "    axs[jj].hist(d1[d1!=0], bins = 30, facecolor = '#d6bddb' )\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "\n",
    "    d2 = wts[jj+1]\n",
    "    axs[jj+1].hist(d2[d2!=0], bins = 30, facecolor = '#d6bddb')\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the validation.split is the last X% of the data\n",
    "int(0.3*Xtrain_scaled.shape[0])\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict of hyperparameters\n",
    "\n",
    "\n",
    "# regularization, num layers, num nodes, learning rate, optimizer, activation function, batch size\n",
    "\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Create hyperparameter space\n",
    "NumHiddenLayers = randint(low = 2, high = 20)#[4, 2, 8]\n",
    "numUnits  = [2**4, 2**5, 2**6, 2**7, 2**8, 2**9, 2**10]\n",
    "epochs = [200]\n",
    "batches1 = [2**12, 2**10, 2**8, 2**14] \n",
    "optimizers = ['rmsprop', 'adam']\n",
    "dropout_rate =  uniform(loc = 0, scale = 0.5) #[0.0, 0.2, 0.5]\n",
    "weightRegularization = uniform(loc = 0, scale = 0.001) #[0, 0.0001, 0.001, 0.01]\n",
    "secondToLastUnits = [8, 16, 32, 64]\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(optimizer=optimizers, \n",
    "                        epochs=epochs, \n",
    "                        batch_size=batches1,\n",
    "                        dropout_rate = dropout_rate, \n",
    "                        numUnits = numUnits, \n",
    "                        NumHiddenLayers = NumHiddenLayers, \n",
    "                        weightRegularization = weightRegularization, \n",
    "                        secondToLastUnits = secondToLastUnits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: \n",
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "cutPercent = 49.7\n",
    "for numCuts in range(3):\n",
    "    for numEpocs in range(100):\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                            callbacks = [earlystop])\n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 2):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent, 50 + cutPercent), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DL_and_ODE",
   "language": "python",
   "name": "dl_and_ode"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
