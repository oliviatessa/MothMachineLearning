{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callin Switzer\n",
    "___\n",
    "\n",
    "### 16 Jan 2020\n",
    "### - Train without pruning\n",
    "### - Then prune a Dense, Feedforward Neural Network with Keras\n",
    "### - Use data that was generated in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow successfully installed.\n",
      "The installed version of TensorFlow includes GPU support.\n",
      "3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)] \n",
      "\n",
      "last run on 2020-01-27 08:46:08.247174\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "plt.rc('font',family='Times New Roman')\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "import subprocess\n",
    "import winsound\n",
    "import pickle\n",
    "import glob\n",
    "import sqlite3\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow successfully installed.\")\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"The installed version of TensorFlow includes GPU support.\")\n",
    "print(sys.version, \"\\n\")\n",
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))\n",
    "\n",
    "# define directories\n",
    "baseDir = os.getcwd()\n",
    "dataDir = r'D:\\MothSimulations\\11c-AggressiveManeuver\\Qstore\\hws_am_con'\n",
    "figDir = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\Figs'\n",
    "dataOutput = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput'\n",
    "savedModels = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels'\n",
    "dataDir = r'D:/Dropbox/AcademiaDropbox/mothMachineLearning_dataAndFigs/PythonGeneratedData_oneTorque/'\n",
    "if not os.path.exists(figDir):\n",
    "    os.mkdir(figDir)\n",
    "\n",
    "if not os.path.exists(dataOutput):\n",
    "    os.mkdir(dataOutput)\n",
    "if not os.path.exists(savedModels):\n",
    "    os.mkdir(savedModels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "# Keras callcacks\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['test', 'train']\n"
     ]
    }
   ],
   "source": [
    "# get table names in database\n",
    "con1 = sqlite3.connect(os.path.join(dataDir, \"oneTorqueData.db\"))\n",
    "cursorObj = con1.cursor()\n",
    "res = cursorObj.execute(\"SELECT name FROM sqlite_master WHERE type='table';\")\n",
    "tableNames = [name[0] for name in res]\n",
    "con1.close()\n",
    "print(tableNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "con1 = sqlite3.connect(os.path.join(dataDir, \"oneTorqueData.db\"))\n",
    "trainDF = pd.read_sql_query(\"SELECT * FROM train\", con1)\n",
    "testDF = pd.read_sql_query(\"SELECT * FROM test\", con1)\n",
    "con1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check for repeats!\n",
    "np.sum(trainDF.iloc[:, [16,17,18]].duplicated()) # 0 means no repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000000, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x_0</th>\n",
       "      <th>xd_0</th>\n",
       "      <th>y_0</th>\n",
       "      <th>yd_0</th>\n",
       "      <th>theta_0</th>\n",
       "      <th>thetad_0</th>\n",
       "      <th>phi_0</th>\n",
       "      <th>phid_0</th>\n",
       "      <th>x_f</th>\n",
       "      <th>xd_f</th>\n",
       "      <th>y_f</th>\n",
       "      <th>yd_f</th>\n",
       "      <th>theta_f</th>\n",
       "      <th>thetad_f</th>\n",
       "      <th>phi_f</th>\n",
       "      <th>phid_f</th>\n",
       "      <th>F</th>\n",
       "      <th>alpha</th>\n",
       "      <th>tau0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1127.569064</td>\n",
       "      <td>0.0</td>\n",
       "      <td>765.895323</td>\n",
       "      <td>1.075898</td>\n",
       "      <td>11.962440</td>\n",
       "      <td>3.427385</td>\n",
       "      <td>18.462602</td>\n",
       "      <td>18.395120</td>\n",
       "      <td>720.596469</td>\n",
       "      <td>14.991199</td>\n",
       "      <td>564.440206</td>\n",
       "      <td>2.620463</td>\n",
       "      <td>143.757506</td>\n",
       "      <td>5.082561</td>\n",
       "      <td>149.863616</td>\n",
       "      <td>41181.992912</td>\n",
       "      <td>1.987846</td>\n",
       "      <td>-63216.237665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>979.651081</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-625.561275</td>\n",
       "      <td>0.306688</td>\n",
       "      <td>-5.637037</td>\n",
       "      <td>2.576453</td>\n",
       "      <td>19.788635</td>\n",
       "      <td>18.621532</td>\n",
       "      <td>880.434302</td>\n",
       "      <td>-13.742423</td>\n",
       "      <td>-731.060427</td>\n",
       "      <td>0.112672</td>\n",
       "      <td>-33.187823</td>\n",
       "      <td>2.382966</td>\n",
       "      <td>-33.150583</td>\n",
       "      <td>9062.020340</td>\n",
       "      <td>3.567122</td>\n",
       "      <td>19108.940596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1111.257777</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1406.672066</td>\n",
       "      <td>5.094943</td>\n",
       "      <td>16.102668</td>\n",
       "      <td>1.775724</td>\n",
       "      <td>-9.188076</td>\n",
       "      <td>19.014489</td>\n",
       "      <td>1042.106161</td>\n",
       "      <td>-25.204363</td>\n",
       "      <td>-1013.381330</td>\n",
       "      <td>2.863959</td>\n",
       "      <td>-213.548177</td>\n",
       "      <td>-0.317910</td>\n",
       "      <td>-206.678168</td>\n",
       "      <td>42727.993224</td>\n",
       "      <td>4.104033</td>\n",
       "      <td>49781.327507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-1438.730397</td>\n",
       "      <td>0.0</td>\n",
       "      <td>690.882986</td>\n",
       "      <td>5.034187</td>\n",
       "      <td>-3.375327</td>\n",
       "      <td>5.534301</td>\n",
       "      <td>-9.669100</td>\n",
       "      <td>-31.106570</td>\n",
       "      <td>-1508.832101</td>\n",
       "      <td>10.684741</td>\n",
       "      <td>335.455964</td>\n",
       "      <td>6.295325</td>\n",
       "      <td>138.687265</td>\n",
       "      <td>6.771356</td>\n",
       "      <td>137.904931</td>\n",
       "      <td>28953.145279</td>\n",
       "      <td>4.698031</td>\n",
       "      <td>92261.347215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1370.322727</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-216.459775</td>\n",
       "      <td>4.186927</td>\n",
       "      <td>-16.500337</td>\n",
       "      <td>3.194818</td>\n",
       "      <td>-0.385905</td>\n",
       "      <td>27.275396</td>\n",
       "      <td>1358.731404</td>\n",
       "      <td>-4.542652</td>\n",
       "      <td>-238.481028</td>\n",
       "      <td>3.985371</td>\n",
       "      <td>-9.972093</td>\n",
       "      <td>3.182170</td>\n",
       "      <td>-0.693456</td>\n",
       "      <td>371.601599</td>\n",
       "      <td>0.668810</td>\n",
       "      <td>-40259.257246</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x_0         xd_0  y_0         yd_0   theta_0   thetad_0     phi_0  \\\n",
       "0  0.0  1127.569064  0.0   765.895323  1.075898  11.962440  3.427385   \n",
       "1  0.0   979.651081  0.0  -625.561275  0.306688  -5.637037  2.576453   \n",
       "2  0.0  1111.257777  0.0 -1406.672066  5.094943  16.102668  1.775724   \n",
       "3  0.0 -1438.730397  0.0   690.882986  5.034187  -3.375327  5.534301   \n",
       "4  0.0  1370.322727  0.0  -216.459775  4.186927 -16.500337  3.194818   \n",
       "\n",
       "      phid_0        x_f         xd_f        y_f         yd_f   theta_f  \\\n",
       "0  18.462602  18.395120   720.596469  14.991199   564.440206  2.620463   \n",
       "1  19.788635  18.621532   880.434302 -13.742423  -731.060427  0.112672   \n",
       "2  -9.188076  19.014489  1042.106161 -25.204363 -1013.381330  2.863959   \n",
       "3  -9.669100 -31.106570 -1508.832101  10.684741   335.455964  6.295325   \n",
       "4  -0.385905  27.275396  1358.731404  -4.542652  -238.481028  3.985371   \n",
       "\n",
       "     thetad_f     phi_f      phid_f             F     alpha          tau0  \n",
       "0  143.757506  5.082561  149.863616  41181.992912  1.987846 -63216.237665  \n",
       "1  -33.187823  2.382966  -33.150583   9062.020340  3.567122  19108.940596  \n",
       "2 -213.548177 -0.317910 -206.678168  42727.993224  4.104033  49781.327507  \n",
       "3  138.687265  6.771356  137.904931  28953.145279  4.698031  92261.347215  \n",
       "4   -9.972093  3.182170   -0.693456    371.601599  0.668810 -40259.257246  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trainDF.shape)\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to be consistent with other code\n",
    "trainDF.rename(columns={\"x0\" : \"x_0\", \"y0\" : \"y_0\", \"phi0\" : \"phi_0\", \"theta0\" : \"theta_0\", \n",
    "                        \"x_f\" : \"x_99\", \"y_f\" : \"y_99\", \"phi_f\" : \"phi_99\", \"theta_f\" : \"theta_99\", \n",
    "                        \"xd_0\" : \"x_dot_0\", \"yd_0\" : \"y_dot_0\", \"phid_0\" : \"phi_dot_0\", \"thetad_0\": \"theta_dot_0\", \n",
    "                        \"xd_f\" : \"x_dot_99\", \"yd_f\": \"y_dot_99\", \"phid_f\": \"phi_dot_99\", \"thetad_f\": \"theta_dot_99\", \n",
    "                        \"tau0\" : \"tau\"}, inplace=True)\n",
    "\n",
    "# rename columns to be consistent with other code\n",
    "testDF.rename(columns={\"x0\" : \"x_0\", \"y0\" : \"y_0\", \"phi0\" : \"phi_0\", \"theta0\" : \"theta_0\", \n",
    "                        \"x_f\" : \"x_99\", \"y_f\" : \"y_99\", \"phi_f\" : \"phi_99\", \"theta_f\" : \"theta_99\", \n",
    "                        \"xd_0\" : \"x_dot_0\", \"yd_0\" : \"y_dot_0\", \"phid_0\" : \"phi_dot_0\", \"thetad_0\": \"theta_dot_0\", \n",
    "                        \"xd_f\" : \"x_dot_99\", \"yd_f\": \"y_dot_99\", \"phid_f\": \"phi_dot_99\", \"thetad_f\": \"theta_dot_99\", \n",
    "                        \"tau0\" : \"tau\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to fx and fy\n",
    "trainDF[\"Fx\"] = trainDF.F * np.cos(trainDF.alpha)\n",
    "trainDF[\"Fy\"] = trainDF.F * np.sin(trainDF.alpha)\n",
    "\n",
    "testDF[\"Fx\"] = testDF.F * np.cos(testDF.alpha)\n",
    "testDF[\"Fy\"] = testDF.F * np.sin(testDF.alpha)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]\n",
    "\n",
    "# make test dataset\n",
    "Xtest = testDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Ytest = testDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phi_0</th>\n",
       "      <th>theta_0</th>\n",
       "      <th>x_99</th>\n",
       "      <th>y_99</th>\n",
       "      <th>phi_99</th>\n",
       "      <th>theta_99</th>\n",
       "      <th>x_dot_0</th>\n",
       "      <th>y_dot_0</th>\n",
       "      <th>phi_dot_0</th>\n",
       "      <th>theta_dot_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.427385</td>\n",
       "      <td>1.075898</td>\n",
       "      <td>18.395120</td>\n",
       "      <td>14.991199</td>\n",
       "      <td>5.082561</td>\n",
       "      <td>2.620463</td>\n",
       "      <td>1127.569064</td>\n",
       "      <td>765.895323</td>\n",
       "      <td>18.462602</td>\n",
       "      <td>11.962440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.576453</td>\n",
       "      <td>0.306688</td>\n",
       "      <td>18.621532</td>\n",
       "      <td>-13.742423</td>\n",
       "      <td>2.382966</td>\n",
       "      <td>0.112672</td>\n",
       "      <td>979.651081</td>\n",
       "      <td>-625.561275</td>\n",
       "      <td>19.788635</td>\n",
       "      <td>-5.637037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.775724</td>\n",
       "      <td>5.094943</td>\n",
       "      <td>19.014489</td>\n",
       "      <td>-25.204363</td>\n",
       "      <td>-0.317910</td>\n",
       "      <td>2.863959</td>\n",
       "      <td>1111.257777</td>\n",
       "      <td>-1406.672066</td>\n",
       "      <td>-9.188076</td>\n",
       "      <td>16.102668</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.534301</td>\n",
       "      <td>5.034187</td>\n",
       "      <td>-31.106570</td>\n",
       "      <td>10.684741</td>\n",
       "      <td>6.771356</td>\n",
       "      <td>6.295325</td>\n",
       "      <td>-1438.730397</td>\n",
       "      <td>690.882986</td>\n",
       "      <td>-9.669100</td>\n",
       "      <td>-3.375327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3.194818</td>\n",
       "      <td>4.186927</td>\n",
       "      <td>27.275396</td>\n",
       "      <td>-4.542652</td>\n",
       "      <td>3.182170</td>\n",
       "      <td>3.985371</td>\n",
       "      <td>1370.322727</td>\n",
       "      <td>-216.459775</td>\n",
       "      <td>-0.385905</td>\n",
       "      <td>-16.500337</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phi_0   theta_0       x_99       y_99    phi_99  theta_99      x_dot_0  \\\n",
       "0  3.427385  1.075898  18.395120  14.991199  5.082561  2.620463  1127.569064   \n",
       "1  2.576453  0.306688  18.621532 -13.742423  2.382966  0.112672   979.651081   \n",
       "2  1.775724  5.094943  19.014489 -25.204363 -0.317910  2.863959  1111.257777   \n",
       "3  5.534301  5.034187 -31.106570  10.684741  6.771356  6.295325 -1438.730397   \n",
       "4  3.194818  4.186927  27.275396  -4.542652  3.182170  3.985371  1370.322727   \n",
       "\n",
       "       y_dot_0  phi_dot_0  theta_dot_0  \n",
       "0   765.895323  18.462602    11.962440  \n",
       "1  -625.561275  19.788635    -5.637037  \n",
       "2 -1406.672066  -9.188076    16.102668  \n",
       "3   690.882986  -9.669100    -3.375327  \n",
       "4  -216.459775  -0.385905   -16.500337  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fx</th>\n",
       "      <th>Fy</th>\n",
       "      <th>tau</th>\n",
       "      <th>x_dot_99</th>\n",
       "      <th>y_dot_99</th>\n",
       "      <th>phi_dot_99</th>\n",
       "      <th>theta_dot_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-16681.383440</td>\n",
       "      <td>37652.197635</td>\n",
       "      <td>-63216.237665</td>\n",
       "      <td>720.596469</td>\n",
       "      <td>564.440206</td>\n",
       "      <td>149.863616</td>\n",
       "      <td>143.757506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-8253.874132</td>\n",
       "      <td>-3740.825371</td>\n",
       "      <td>19108.940596</td>\n",
       "      <td>880.434302</td>\n",
       "      <td>-731.060427</td>\n",
       "      <td>-33.150583</td>\n",
       "      <td>-33.187823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-24419.876370</td>\n",
       "      <td>-35062.102662</td>\n",
       "      <td>49781.327507</td>\n",
       "      <td>1042.106161</td>\n",
       "      <td>-1013.381330</td>\n",
       "      <td>-206.678168</td>\n",
       "      <td>-213.548177</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-415.702991</td>\n",
       "      <td>-28950.160838</td>\n",
       "      <td>92261.347215</td>\n",
       "      <td>-1508.832101</td>\n",
       "      <td>335.455964</td>\n",
       "      <td>137.904931</td>\n",
       "      <td>138.687265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>291.543841</td>\n",
       "      <td>230.412537</td>\n",
       "      <td>-40259.257246</td>\n",
       "      <td>1358.731404</td>\n",
       "      <td>-238.481028</td>\n",
       "      <td>-0.693456</td>\n",
       "      <td>-9.972093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Fx            Fy           tau     x_dot_99     y_dot_99  \\\n",
       "0 -16681.383440  37652.197635 -63216.237665   720.596469   564.440206   \n",
       "1  -8253.874132  -3740.825371  19108.940596   880.434302  -731.060427   \n",
       "2 -24419.876370 -35062.102662  49781.327507  1042.106161 -1013.381330   \n",
       "3   -415.702991 -28950.160838  92261.347215 -1508.832101   335.455964   \n",
       "4    291.543841    230.412537 -40259.257246  1358.731404  -238.481028   \n",
       "\n",
       "   phi_dot_99  theta_dot_99  \n",
       "0  149.863616    143.757506  \n",
       "1  -33.150583    -33.187823  \n",
       "2 -206.678168   -213.548177  \n",
       "3  137.904931    138.687265  \n",
       "4   -0.693456     -9.972093  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# val train split\n",
    "Xtrain, Xval, Ytrain, Yval = train_test_split(X, Y, test_size=0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data \n",
    "scalerX = MinMaxScaler([-0.5, 0.5])  \n",
    "scalerY = MinMaxScaler([-0.5, 0.5])  \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xval_scaled = scalerX.transform(Xval)\n",
    "Yval_scaled = scalerY.transform(Yval)\n",
    "\n",
    "\n",
    "# final test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phi_0</th>\n",
       "      <th>theta_0</th>\n",
       "      <th>x_99</th>\n",
       "      <th>y_99</th>\n",
       "      <th>phi_99</th>\n",
       "      <th>theta_99</th>\n",
       "      <th>x_dot_0</th>\n",
       "      <th>y_dot_0</th>\n",
       "      <th>phi_dot_0</th>\n",
       "      <th>theta_dot_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.440808</td>\n",
       "      <td>-0.497541</td>\n",
       "      <td>-0.377559</td>\n",
       "      <td>-0.093133</td>\n",
       "      <td>0.279853</td>\n",
       "      <td>-0.127880</td>\n",
       "      <td>-0.413733</td>\n",
       "      <td>-0.087276</td>\n",
       "      <td>0.151751</td>\n",
       "      <td>-0.419563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.002656</td>\n",
       "      <td>0.450960</td>\n",
       "      <td>0.232459</td>\n",
       "      <td>0.301555</td>\n",
       "      <td>-0.029443</td>\n",
       "      <td>0.182687</td>\n",
       "      <td>0.276074</td>\n",
       "      <td>0.383212</td>\n",
       "      <td>0.227138</td>\n",
       "      <td>0.094672</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.302116</td>\n",
       "      <td>0.217276</td>\n",
       "      <td>0.364897</td>\n",
       "      <td>-0.175870</td>\n",
       "      <td>-0.005774</td>\n",
       "      <td>-0.045649</td>\n",
       "      <td>0.385703</td>\n",
       "      <td>-0.188919</td>\n",
       "      <td>-0.266187</td>\n",
       "      <td>-0.202705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.471247</td>\n",
       "      <td>0.121804</td>\n",
       "      <td>0.069457</td>\n",
       "      <td>0.309980</td>\n",
       "      <td>-0.318901</td>\n",
       "      <td>-0.060641</td>\n",
       "      <td>0.103501</td>\n",
       "      <td>0.332100</td>\n",
       "      <td>-0.227711</td>\n",
       "      <td>0.447327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.350056</td>\n",
       "      <td>-0.349031</td>\n",
       "      <td>0.313385</td>\n",
       "      <td>0.159446</td>\n",
       "      <td>-0.094834</td>\n",
       "      <td>-0.093747</td>\n",
       "      <td>0.350805</td>\n",
       "      <td>0.216431</td>\n",
       "      <td>0.136925</td>\n",
       "      <td>0.270457</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phi_0   theta_0      x_99      y_99    phi_99  theta_99   x_dot_0  \\\n",
       "0  0.440808 -0.497541 -0.377559 -0.093133  0.279853 -0.127880 -0.413733   \n",
       "1  0.002656  0.450960  0.232459  0.301555 -0.029443  0.182687  0.276074   \n",
       "2  0.302116  0.217276  0.364897 -0.175870 -0.005774 -0.045649  0.385703   \n",
       "3 -0.471247  0.121804  0.069457  0.309980 -0.318901 -0.060641  0.103501   \n",
       "4 -0.350056 -0.349031  0.313385  0.159446 -0.094834 -0.093747  0.350805   \n",
       "\n",
       "    y_dot_0  phi_dot_0  theta_dot_0  \n",
       "0 -0.087276   0.151751    -0.419563  \n",
       "1  0.383212   0.227138     0.094672  \n",
       "2 -0.188919  -0.266187    -0.202705  \n",
       "3  0.332100  -0.227711     0.447327  \n",
       "4  0.216431   0.136925     0.270457  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Xtrain_scaled, columns = X.columns).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "\n",
    "# Keras callcacks\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import keras.backend as K\n",
    "\n",
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network\n",
    "def create_network(optimizer = 'rmsprop', \n",
    "                    numUnits = [400, 16], \n",
    "                    weightRegularization = 0.0, \n",
    "                    dropout_rate=0.1):\n",
    "    \n",
    "    '''\n",
    "    Create a feed forward network.  Assumes Xtrain & Ytrain have been created and scaled\n",
    "    \n",
    "    Params: \n",
    "    optimizer (str): choice of optimizer\n",
    "    numUnits (list): number of units in each hidden\n",
    "    weightRegularization (float): between 0 and 1\n",
    "    dropout_rate (float): between 0 and 1\n",
    "    \n",
    "    '''\n",
    "    K.clear_session()\n",
    "    inputs = Input(shape=(Xtrain_scaled.shape[1],))    \n",
    "    \n",
    "    # add layers\n",
    "    for ii in np.arange(0, len(numUnits)):\n",
    "        if ii >= 1: \n",
    "            x = Dense(numUnits[ii], activation='tanh', \n",
    "                      kernel_regularizer=regularizers.l1(weightRegularization))(x)\n",
    "\n",
    "        else: \n",
    "            x = Dense(numUnits[ii], activation='tanh')(inputs)\n",
    "\n",
    "\n",
    "        # add dropout\n",
    "        if dropout_rate > 0: \n",
    "            x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "    # create model\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer = optimizer, metrics = ['mse'])\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_e(n):\n",
    "    a = '%E' % n\n",
    "    return a.split('E')[0].rstrip('0').rstrip('.') + 'E' + a.split('E')[1]\n",
    "\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=150, \n",
    "                          verbose=1, mode='auto', min_delta = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history.history['mean_squared_error'])+1),\n",
    "             model_history.history['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "             model_history.history['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history.history['val_mean_squared_error'][-1])))\n",
    "    axs.set_ylabel('Mean squared error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(0,len(model_history.history['val_mean_squared_error']), 50), 50)\n",
    "    axs.legend(['train', 'validation'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \".pdf\"), dpi = 500, bbox_inches='tight')\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'validation'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"), dpi = 120, bbox_inches='tight')\n",
    "        print(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"))\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and trim weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt_rmsprop__Dro_0__Num_400_400_400_16__Wei_0_2020_01_24__04_40_30\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 400)               4400      \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 400)               160400    \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 16)                6416      \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 7)                 119       \n",
      "=================================================================\n",
      "Total params: 331,735\n",
      "Trainable params: 331,735\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "\n",
    "K.clear_session()\n",
    "\n",
    "modelParams = {\"optimizer\": \"rmsprop\", \n",
    "              \"dropout_rate\" : 0, \n",
    "               \"numUnits\": [400, 400, 400, 16],\n",
    "               \"weightRegularization\": 0\n",
    "              }\n",
    "\n",
    "\n",
    "model = create_network(**modelParams)\n",
    "\n",
    "modeltimestamp = datetime.now().strftime(\"%Y_%m_%d__%I_%M_%S\")\n",
    "modelName = ''.join('{}_{}__'.format(key[0:3].capitalize(), val) for  key, val in modelParams.items()).\\\n",
    "                            replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \"_\")[0:-2] + \"_\" + modeltimestamp\n",
    "print(modelName)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save scalers, to be used on test set\n",
    "scalerfileX = 'scalerX_fullact_' + modeltimestamp + '.pkl'\n",
    "pickle.dump(scalerX, open(os.path.join(dataOutput, scalerfileX), 'wb'))\n",
    "\n",
    "scalerfileY = 'scalerY_fullact_' + modeltimestamp + '.pkl'\n",
    "pickle.dump(scalerY, open(os.path.join(dataOutput, scalerfileY), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "historyDict = {\"mean_squared_error\": [], \n",
    "               \"val_mean_squared_error\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 8000000 samples, validate on 2000000 samples\n",
      "Epoch 1/1000\n",
      " - 17s - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0074 - val_mean_squared_error: 0.0074\n",
      "Epoch 2/1000\n",
      " - 15s - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0065 - val_mean_squared_error: 0.0065\n",
      "Epoch 3/1000\n",
      " - 15s - loss: 0.0045 - mean_squared_error: 0.0045 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
      "Epoch 4/1000\n",
      " - 15s - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Epoch 5/1000\n",
      " - 15s - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
      "Epoch 6/1000\n",
      " - 15s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "Epoch 7/1000\n",
      " - 15s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "Epoch 8/1000\n",
      " - 15s - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Epoch 9/1000\n",
      " - 15s - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 10/1000\n",
      " - 15s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0020 - val_mean_squared_error: 0.0020\n",
      "Epoch 11/1000\n",
      " - 15s - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 12/1000\n",
      " - 15s - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Epoch 13/1000\n",
      " - 15s - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 14/1000\n",
      " - 15s - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 15/1000\n",
      " - 15s - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Epoch 16/1000\n",
      " - 15s - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 17/1000\n",
      " - 15s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 18/1000\n",
      " - 15s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 19/1000\n",
      " - 15s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Epoch 20/1000\n",
      " - 15s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 21/1000\n",
      " - 15s - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 22/1000\n",
      " - 15s - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Epoch 23/1000\n",
      " - 15s - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 24/1000\n",
      " - 15s - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 9.1163e-04 - val_mean_squared_error: 9.1163e-04\n",
      "Epoch 25/1000\n",
      " - 15s - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 26/1000\n",
      " - 15s - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Epoch 27/1000\n",
      " - 15s - loss: 9.9052e-04 - mean_squared_error: 9.9052e-04 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 28/1000\n",
      " - 15s - loss: 9.7081e-04 - mean_squared_error: 9.7081e-04 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Epoch 29/1000\n",
      " - 15s - loss: 9.5155e-04 - mean_squared_error: 9.5155e-04 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 30/1000\n",
      " - 15s - loss: 9.3460e-04 - mean_squared_error: 9.3460e-04 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Epoch 31/1000\n",
      " - 15s - loss: 9.1835e-04 - mean_squared_error: 9.1835e-04 - val_loss: 8.5490e-04 - val_mean_squared_error: 8.5490e-04\n",
      "Epoch 32/1000\n",
      " - 15s - loss: 9.0289e-04 - mean_squared_error: 9.0289e-04 - val_loss: 9.2246e-04 - val_mean_squared_error: 9.2246e-04\n",
      "Epoch 33/1000\n",
      " - 15s - loss: 8.8801e-04 - mean_squared_error: 8.8801e-04 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Epoch 34/1000\n",
      " - 15s - loss: 8.7518e-04 - mean_squared_error: 8.7518e-04 - val_loss: 6.9226e-04 - val_mean_squared_error: 6.9226e-04\n",
      "Epoch 35/1000\n",
      " - 15s - loss: 8.6149e-04 - mean_squared_error: 8.6149e-04 - val_loss: 8.7141e-04 - val_mean_squared_error: 8.7141e-04\n",
      "Epoch 36/1000\n",
      " - 15s - loss: 8.5075e-04 - mean_squared_error: 8.5075e-04 - val_loss: 9.2652e-04 - val_mean_squared_error: 9.2652e-04\n",
      "Epoch 37/1000\n",
      " - 15s - loss: 8.3907e-04 - mean_squared_error: 8.3907e-04 - val_loss: 8.3356e-04 - val_mean_squared_error: 8.3356e-04\n",
      "Epoch 38/1000\n",
      " - 15s - loss: 8.2744e-04 - mean_squared_error: 8.2744e-04 - val_loss: 7.9697e-04 - val_mean_squared_error: 7.9697e-04\n",
      "Epoch 39/1000\n",
      " - 15s - loss: 8.1785e-04 - mean_squared_error: 8.1785e-04 - val_loss: 9.4284e-04 - val_mean_squared_error: 9.4284e-04\n",
      "Epoch 40/1000\n",
      " - 15s - loss: 8.0617e-04 - mean_squared_error: 8.0617e-04 - val_loss: 8.5560e-04 - val_mean_squared_error: 8.5560e-04\n",
      "Epoch 41/1000\n",
      " - 15s - loss: 7.9819e-04 - mean_squared_error: 7.9819e-04 - val_loss: 8.0753e-04 - val_mean_squared_error: 8.0753e-04\n",
      "Epoch 42/1000\n",
      " - 15s - loss: 7.8858e-04 - mean_squared_error: 7.8858e-04 - val_loss: 8.1428e-04 - val_mean_squared_error: 8.1428e-04\n",
      "Epoch 43/1000\n",
      " - 15s - loss: 7.8004e-04 - mean_squared_error: 7.8004e-04 - val_loss: 9.0573e-04 - val_mean_squared_error: 9.0573e-04\n",
      "Epoch 44/1000\n",
      " - 15s - loss: 7.7075e-04 - mean_squared_error: 7.7075e-04 - val_loss: 8.9783e-04 - val_mean_squared_error: 8.9783e-04\n",
      "Epoch 45/1000\n",
      " - 15s - loss: 7.6304e-04 - mean_squared_error: 7.6304e-04 - val_loss: 6.9374e-04 - val_mean_squared_error: 6.9374e-04\n",
      "Epoch 46/1000\n",
      " - 15s - loss: 7.5535e-04 - mean_squared_error: 7.5535e-04 - val_loss: 7.8576e-04 - val_mean_squared_error: 7.8576e-04\n",
      "Epoch 47/1000\n",
      " - 15s - loss: 7.4756e-04 - mean_squared_error: 7.4756e-04 - val_loss: 7.7375e-04 - val_mean_squared_error: 7.7375e-04\n",
      "Epoch 48/1000\n",
      " - 15s - loss: 7.4117e-04 - mean_squared_error: 7.4117e-04 - val_loss: 6.3124e-04 - val_mean_squared_error: 6.3124e-04\n",
      "Epoch 49/1000\n",
      " - 15s - loss: 7.3302e-04 - mean_squared_error: 7.3302e-04 - val_loss: 7.7431e-04 - val_mean_squared_error: 7.7431e-04\n",
      "Epoch 50/1000\n",
      " - 15s - loss: 7.2643e-04 - mean_squared_error: 7.2643e-04 - val_loss: 9.3351e-04 - val_mean_squared_error: 9.3351e-04\n",
      "Epoch 51/1000\n",
      " - 15s - loss: 7.1932e-04 - mean_squared_error: 7.1932e-04 - val_loss: 8.1082e-04 - val_mean_squared_error: 8.1082e-04\n",
      "Epoch 52/1000\n",
      " - 15s - loss: 7.1321e-04 - mean_squared_error: 7.1321e-04 - val_loss: 8.3913e-04 - val_mean_squared_error: 8.3913e-04\n",
      "Epoch 53/1000\n",
      " - 15s - loss: 7.0763e-04 - mean_squared_error: 7.0763e-04 - val_loss: 8.0227e-04 - val_mean_squared_error: 8.0227e-04\n",
      "Epoch 54/1000\n",
      " - 15s - loss: 7.0022e-04 - mean_squared_error: 7.0022e-04 - val_loss: 8.0968e-04 - val_mean_squared_error: 8.0968e-04\n",
      "Epoch 55/1000\n",
      " - 15s - loss: 6.9558e-04 - mean_squared_error: 6.9558e-04 - val_loss: 7.1263e-04 - val_mean_squared_error: 7.1263e-04\n",
      "Epoch 56/1000\n",
      " - 15s - loss: 6.9009e-04 - mean_squared_error: 6.9009e-04 - val_loss: 6.2508e-04 - val_mean_squared_error: 6.2508e-04\n",
      "Epoch 57/1000\n",
      " - 15s - loss: 6.8397e-04 - mean_squared_error: 6.8397e-04 - val_loss: 6.3757e-04 - val_mean_squared_error: 6.3757e-04\n",
      "Epoch 58/1000\n",
      " - 15s - loss: 6.7916e-04 - mean_squared_error: 6.7916e-04 - val_loss: 8.2759e-04 - val_mean_squared_error: 8.2759e-04\n",
      "Epoch 59/1000\n",
      " - 15s - loss: 6.7322e-04 - mean_squared_error: 6.7322e-04 - val_loss: 6.6445e-04 - val_mean_squared_error: 6.6445e-04\n",
      "Epoch 60/1000\n",
      " - 15s - loss: 6.6816e-04 - mean_squared_error: 6.6816e-04 - val_loss: 7.0324e-04 - val_mean_squared_error: 7.0324e-04\n",
      "Epoch 61/1000\n",
      " - 15s - loss: 6.6334e-04 - mean_squared_error: 6.6334e-04 - val_loss: 8.8223e-04 - val_mean_squared_error: 8.8223e-04\n",
      "Epoch 62/1000\n",
      " - 15s - loss: 6.5892e-04 - mean_squared_error: 6.5892e-04 - val_loss: 6.4020e-04 - val_mean_squared_error: 6.4020e-04\n",
      "Epoch 63/1000\n",
      " - 15s - loss: 6.5446e-04 - mean_squared_error: 6.5446e-04 - val_loss: 6.6547e-04 - val_mean_squared_error: 6.6547e-04\n",
      "Epoch 64/1000\n",
      " - 15s - loss: 6.4976e-04 - mean_squared_error: 6.4976e-04 - val_loss: 5.3905e-04 - val_mean_squared_error: 5.3905e-04\n",
      "Epoch 65/1000\n",
      " - 15s - loss: 6.4502e-04 - mean_squared_error: 6.4502e-04 - val_loss: 6.7906e-04 - val_mean_squared_error: 6.7906e-04\n",
      "Epoch 66/1000\n",
      " - 15s - loss: 6.4164e-04 - mean_squared_error: 6.4164e-04 - val_loss: 7.3911e-04 - val_mean_squared_error: 7.3911e-04\n",
      "Epoch 67/1000\n",
      " - 15s - loss: 6.3709e-04 - mean_squared_error: 6.3709e-04 - val_loss: 8.3160e-04 - val_mean_squared_error: 8.3160e-04\n",
      "Epoch 68/1000\n",
      " - 15s - loss: 6.3303e-04 - mean_squared_error: 6.3303e-04 - val_loss: 7.3089e-04 - val_mean_squared_error: 7.3089e-04\n",
      "Epoch 69/1000\n",
      " - 15s - loss: 6.2865e-04 - mean_squared_error: 6.2865e-04 - val_loss: 7.5309e-04 - val_mean_squared_error: 7.5309e-04\n",
      "Epoch 70/1000\n",
      " - 15s - loss: 6.2516e-04 - mean_squared_error: 6.2516e-04 - val_loss: 7.0618e-04 - val_mean_squared_error: 7.0618e-04\n",
      "Epoch 71/1000\n",
      " - 15s - loss: 6.2089e-04 - mean_squared_error: 6.2089e-04 - val_loss: 8.9743e-04 - val_mean_squared_error: 8.9743e-04\n",
      "Epoch 72/1000\n",
      " - 15s - loss: 6.1818e-04 - mean_squared_error: 6.1818e-04 - val_loss: 6.6810e-04 - val_mean_squared_error: 6.6810e-04\n",
      "Epoch 73/1000\n",
      " - 15s - loss: 6.1449e-04 - mean_squared_error: 6.1449e-04 - val_loss: 5.5571e-04 - val_mean_squared_error: 5.5571e-04\n",
      "Epoch 74/1000\n",
      " - 15s - loss: 6.1043e-04 - mean_squared_error: 6.1043e-04 - val_loss: 5.7455e-04 - val_mean_squared_error: 5.7455e-04\n",
      "Epoch 75/1000\n",
      " - 15s - loss: 6.0738e-04 - mean_squared_error: 6.0738e-04 - val_loss: 6.1822e-04 - val_mean_squared_error: 6.1822e-04\n",
      "Epoch 76/1000\n",
      " - 15s - loss: 6.0429e-04 - mean_squared_error: 6.0429e-04 - val_loss: 6.8374e-04 - val_mean_squared_error: 6.8374e-04\n",
      "Epoch 77/1000\n",
      " - 15s - loss: 6.0109e-04 - mean_squared_error: 6.0109e-04 - val_loss: 6.0909e-04 - val_mean_squared_error: 6.0909e-04\n",
      "Epoch 78/1000\n",
      " - 15s - loss: 5.9751e-04 - mean_squared_error: 5.9751e-04 - val_loss: 6.2491e-04 - val_mean_squared_error: 6.2491e-04\n",
      "Epoch 79/1000\n",
      " - 15s - loss: 5.9465e-04 - mean_squared_error: 5.9465e-04 - val_loss: 6.2800e-04 - val_mean_squared_error: 6.2800e-04\n",
      "Epoch 80/1000\n",
      " - 15s - loss: 5.9058e-04 - mean_squared_error: 5.9058e-04 - val_loss: 7.1337e-04 - val_mean_squared_error: 7.1337e-04\n",
      "Epoch 81/1000\n",
      " - 15s - loss: 5.8867e-04 - mean_squared_error: 5.8867e-04 - val_loss: 5.4619e-04 - val_mean_squared_error: 5.4619e-04\n",
      "Epoch 82/1000\n",
      " - 15s - loss: 5.8508e-04 - mean_squared_error: 5.8508e-04 - val_loss: 4.9061e-04 - val_mean_squared_error: 4.9061e-04\n",
      "Epoch 83/1000\n",
      " - 15s - loss: 5.8170e-04 - mean_squared_error: 5.8170e-04 - val_loss: 6.8446e-04 - val_mean_squared_error: 6.8446e-04\n",
      "Epoch 84/1000\n",
      " - 15s - loss: 5.7985e-04 - mean_squared_error: 5.7985e-04 - val_loss: 5.9262e-04 - val_mean_squared_error: 5.9262e-04\n",
      "Epoch 85/1000\n",
      " - 15s - loss: 5.7748e-04 - mean_squared_error: 5.7748e-04 - val_loss: 5.6787e-04 - val_mean_squared_error: 5.6787e-04\n",
      "Epoch 86/1000\n",
      " - 15s - loss: 5.7344e-04 - mean_squared_error: 5.7344e-04 - val_loss: 4.7646e-04 - val_mean_squared_error: 4.7646e-04\n",
      "Epoch 87/1000\n",
      " - 15s - loss: 5.7145e-04 - mean_squared_error: 5.7145e-04 - val_loss: 5.3318e-04 - val_mean_squared_error: 5.3318e-04\n",
      "Epoch 88/1000\n",
      " - 15s - loss: 5.6769e-04 - mean_squared_error: 5.6769e-04 - val_loss: 6.6021e-04 - val_mean_squared_error: 6.6021e-04\n",
      "Epoch 89/1000\n",
      " - 15s - loss: 5.6553e-04 - mean_squared_error: 5.6553e-04 - val_loss: 5.4351e-04 - val_mean_squared_error: 5.4351e-04\n",
      "Epoch 90/1000\n",
      " - 15s - loss: 5.6356e-04 - mean_squared_error: 5.6356e-04 - val_loss: 7.2767e-04 - val_mean_squared_error: 7.2767e-04\n",
      "Epoch 91/1000\n",
      " - 15s - loss: 5.6000e-04 - mean_squared_error: 5.6000e-04 - val_loss: 7.2799e-04 - val_mean_squared_error: 7.2799e-04\n",
      "Epoch 92/1000\n",
      " - 15s - loss: 5.5804e-04 - mean_squared_error: 5.5804e-04 - val_loss: 5.0323e-04 - val_mean_squared_error: 5.0323e-04\n",
      "Epoch 93/1000\n",
      " - 15s - loss: 5.5465e-04 - mean_squared_error: 5.5465e-04 - val_loss: 5.7063e-04 - val_mean_squared_error: 5.7063e-04\n",
      "Epoch 94/1000\n",
      " - 15s - loss: 5.5304e-04 - mean_squared_error: 5.5304e-04 - val_loss: 4.6244e-04 - val_mean_squared_error: 4.6244e-04\n",
      "Epoch 95/1000\n",
      " - 15s - loss: 5.5070e-04 - mean_squared_error: 5.5070e-04 - val_loss: 4.4638e-04 - val_mean_squared_error: 4.4638e-04\n",
      "Epoch 96/1000\n",
      " - 15s - loss: 5.4778e-04 - mean_squared_error: 5.4778e-04 - val_loss: 5.8050e-04 - val_mean_squared_error: 5.8050e-04\n",
      "Epoch 97/1000\n",
      " - 15s - loss: 5.4616e-04 - mean_squared_error: 5.4616e-04 - val_loss: 6.1064e-04 - val_mean_squared_error: 6.1064e-04\n",
      "Epoch 98/1000\n",
      " - 15s - loss: 5.4329e-04 - mean_squared_error: 5.4329e-04 - val_loss: 6.1192e-04 - val_mean_squared_error: 6.1192e-04\n",
      "Epoch 99/1000\n",
      " - 15s - loss: 5.4075e-04 - mean_squared_error: 5.4075e-04 - val_loss: 7.2772e-04 - val_mean_squared_error: 7.2772e-04\n",
      "Epoch 100/1000\n",
      " - 15s - loss: 5.3871e-04 - mean_squared_error: 5.3871e-04 - val_loss: 4.8618e-04 - val_mean_squared_error: 4.8618e-04\n",
      "Epoch 101/1000\n",
      " - 15s - loss: 5.3723e-04 - mean_squared_error: 5.3723e-04 - val_loss: 6.9191e-04 - val_mean_squared_error: 6.9191e-04\n",
      "Epoch 102/1000\n",
      " - 15s - loss: 5.3504e-04 - mean_squared_error: 5.3504e-04 - val_loss: 6.0562e-04 - val_mean_squared_error: 6.0562e-04\n",
      "Epoch 103/1000\n",
      " - 15s - loss: 5.3284e-04 - mean_squared_error: 5.3284e-04 - val_loss: 5.5303e-04 - val_mean_squared_error: 5.5303e-04\n",
      "Epoch 104/1000\n",
      " - 15s - loss: 5.3050e-04 - mean_squared_error: 5.3050e-04 - val_loss: 7.1854e-04 - val_mean_squared_error: 7.1854e-04\n",
      "Epoch 105/1000\n",
      " - 15s - loss: 5.2886e-04 - mean_squared_error: 5.2886e-04 - val_loss: 6.5690e-04 - val_mean_squared_error: 6.5690e-04\n",
      "Epoch 106/1000\n",
      " - 15s - loss: 5.2622e-04 - mean_squared_error: 5.2622e-04 - val_loss: 7.3531e-04 - val_mean_squared_error: 7.3531e-04\n",
      "Epoch 107/1000\n",
      " - 15s - loss: 5.2529e-04 - mean_squared_error: 5.2529e-04 - val_loss: 5.2088e-04 - val_mean_squared_error: 5.2088e-04\n",
      "Epoch 108/1000\n",
      " - 15s - loss: 5.2355e-04 - mean_squared_error: 5.2355e-04 - val_loss: 5.4386e-04 - val_mean_squared_error: 5.4386e-04\n",
      "Epoch 109/1000\n",
      " - 15s - loss: 5.2161e-04 - mean_squared_error: 5.2161e-04 - val_loss: 5.2952e-04 - val_mean_squared_error: 5.2952e-04\n",
      "Epoch 110/1000\n",
      " - 15s - loss: 5.1908e-04 - mean_squared_error: 5.1908e-04 - val_loss: 8.3794e-04 - val_mean_squared_error: 8.3794e-04\n",
      "Epoch 111/1000\n",
      " - 15s - loss: 5.1727e-04 - mean_squared_error: 5.1727e-04 - val_loss: 4.9403e-04 - val_mean_squared_error: 4.9403e-04\n",
      "Epoch 112/1000\n",
      " - 15s - loss: 5.1668e-04 - mean_squared_error: 5.1668e-04 - val_loss: 5.5017e-04 - val_mean_squared_error: 5.5017e-04\n",
      "Epoch 113/1000\n",
      " - 15s - loss: 5.1515e-04 - mean_squared_error: 5.1515e-04 - val_loss: 6.9970e-04 - val_mean_squared_error: 6.9970e-04\n",
      "Epoch 114/1000\n",
      " - 15s - loss: 5.1347e-04 - mean_squared_error: 5.1347e-04 - val_loss: 5.9051e-04 - val_mean_squared_error: 5.9051e-04\n",
      "Epoch 115/1000\n",
      " - 15s - loss: 5.1150e-04 - mean_squared_error: 5.1150e-04 - val_loss: 4.5565e-04 - val_mean_squared_error: 4.5565e-04\n",
      "Epoch 116/1000\n",
      " - 15s - loss: 5.0984e-04 - mean_squared_error: 5.0984e-04 - val_loss: 4.6125e-04 - val_mean_squared_error: 4.6125e-04\n",
      "Epoch 117/1000\n",
      " - 15s - loss: 5.0739e-04 - mean_squared_error: 5.0739e-04 - val_loss: 4.7273e-04 - val_mean_squared_error: 4.7273e-04\n",
      "Epoch 118/1000\n",
      " - 15s - loss: 5.0624e-04 - mean_squared_error: 5.0624e-04 - val_loss: 4.9037e-04 - val_mean_squared_error: 4.9037e-04\n",
      "Epoch 119/1000\n",
      " - 15s - loss: 5.0560e-04 - mean_squared_error: 5.0560e-04 - val_loss: 4.0320e-04 - val_mean_squared_error: 4.0320e-04\n",
      "Epoch 120/1000\n",
      " - 15s - loss: 5.0350e-04 - mean_squared_error: 5.0350e-04 - val_loss: 8.1870e-04 - val_mean_squared_error: 8.1870e-04\n",
      "Epoch 121/1000\n",
      " - 15s - loss: 5.0178e-04 - mean_squared_error: 5.0178e-04 - val_loss: 5.8495e-04 - val_mean_squared_error: 5.8495e-04\n",
      "Epoch 122/1000\n",
      " - 15s - loss: 5.0056e-04 - mean_squared_error: 5.0056e-04 - val_loss: 7.3502e-04 - val_mean_squared_error: 7.3502e-04\n",
      "Epoch 123/1000\n",
      " - 15s - loss: 4.9892e-04 - mean_squared_error: 4.9892e-04 - val_loss: 5.1407e-04 - val_mean_squared_error: 5.1407e-04\n",
      "Epoch 124/1000\n",
      " - 15s - loss: 4.9776e-04 - mean_squared_error: 4.9776e-04 - val_loss: 4.0124e-04 - val_mean_squared_error: 4.0124e-04\n",
      "Epoch 125/1000\n",
      " - 15s - loss: 4.9713e-04 - mean_squared_error: 4.9713e-04 - val_loss: 4.5659e-04 - val_mean_squared_error: 4.5659e-04\n",
      "Epoch 126/1000\n",
      " - 15s - loss: 4.9535e-04 - mean_squared_error: 4.9535e-04 - val_loss: 4.0989e-04 - val_mean_squared_error: 4.0989e-04\n",
      "Epoch 127/1000\n",
      " - 15s - loss: 4.9366e-04 - mean_squared_error: 4.9366e-04 - val_loss: 5.5350e-04 - val_mean_squared_error: 5.5350e-04\n",
      "Epoch 128/1000\n",
      " - 15s - loss: 4.9301e-04 - mean_squared_error: 4.9301e-04 - val_loss: 7.6548e-04 - val_mean_squared_error: 7.6548e-04\n",
      "Epoch 129/1000\n",
      " - 15s - loss: 4.9125e-04 - mean_squared_error: 4.9125e-04 - val_loss: 4.2625e-04 - val_mean_squared_error: 4.2625e-04\n",
      "Epoch 130/1000\n",
      " - 15s - loss: 4.9014e-04 - mean_squared_error: 4.9014e-04 - val_loss: 4.5831e-04 - val_mean_squared_error: 4.5831e-04\n",
      "Epoch 131/1000\n",
      " - 15s - loss: 4.8876e-04 - mean_squared_error: 4.8876e-04 - val_loss: 4.0013e-04 - val_mean_squared_error: 4.0013e-04\n",
      "Epoch 132/1000\n",
      " - 15s - loss: 4.8748e-04 - mean_squared_error: 4.8748e-04 - val_loss: 5.5609e-04 - val_mean_squared_error: 5.5609e-04\n",
      "Epoch 133/1000\n",
      " - 15s - loss: 4.8537e-04 - mean_squared_error: 4.8537e-04 - val_loss: 4.9398e-04 - val_mean_squared_error: 4.9398e-04\n",
      "Epoch 134/1000\n",
      " - 15s - loss: 4.8513e-04 - mean_squared_error: 4.8513e-04 - val_loss: 5.3908e-04 - val_mean_squared_error: 5.3908e-04\n",
      "Epoch 135/1000\n",
      " - 15s - loss: 4.8344e-04 - mean_squared_error: 4.8344e-04 - val_loss: 4.7398e-04 - val_mean_squared_error: 4.7398e-04\n",
      "Epoch 136/1000\n",
      " - 15s - loss: 4.8219e-04 - mean_squared_error: 4.8219e-04 - val_loss: 5.1410e-04 - val_mean_squared_error: 5.1410e-04\n",
      "Epoch 137/1000\n",
      " - 15s - loss: 4.8081e-04 - mean_squared_error: 4.8081e-04 - val_loss: 5.3939e-04 - val_mean_squared_error: 5.3939e-04\n",
      "Epoch 138/1000\n",
      " - 15s - loss: 4.8037e-04 - mean_squared_error: 4.8037e-04 - val_loss: 4.4086e-04 - val_mean_squared_error: 4.4086e-04\n",
      "Epoch 139/1000\n",
      " - 15s - loss: 4.7945e-04 - mean_squared_error: 4.7945e-04 - val_loss: 7.1517e-04 - val_mean_squared_error: 7.1517e-04\n",
      "Epoch 140/1000\n",
      " - 15s - loss: 4.7822e-04 - mean_squared_error: 4.7822e-04 - val_loss: 4.0413e-04 - val_mean_squared_error: 4.0413e-04\n",
      "Epoch 141/1000\n",
      " - 15s - loss: 4.7717e-04 - mean_squared_error: 4.7717e-04 - val_loss: 4.3993e-04 - val_mean_squared_error: 4.3993e-04\n",
      "Epoch 142/1000\n",
      " - 15s - loss: 4.7525e-04 - mean_squared_error: 4.7525e-04 - val_loss: 5.0837e-04 - val_mean_squared_error: 5.0837e-04\n",
      "Epoch 143/1000\n",
      " - 15s - loss: 4.7434e-04 - mean_squared_error: 4.7434e-04 - val_loss: 4.6860e-04 - val_mean_squared_error: 4.6860e-04\n",
      "Epoch 144/1000\n",
      " - 15s - loss: 4.7374e-04 - mean_squared_error: 4.7374e-04 - val_loss: 3.7236e-04 - val_mean_squared_error: 3.7236e-04\n",
      "Epoch 145/1000\n",
      " - 15s - loss: 4.7213e-04 - mean_squared_error: 4.7213e-04 - val_loss: 4.1284e-04 - val_mean_squared_error: 4.1284e-04\n",
      "Epoch 146/1000\n",
      " - 15s - loss: 4.7174e-04 - mean_squared_error: 4.7174e-04 - val_loss: 5.7265e-04 - val_mean_squared_error: 5.7265e-04\n",
      "Epoch 147/1000\n",
      " - 15s - loss: 4.6977e-04 - mean_squared_error: 4.6977e-04 - val_loss: 4.8747e-04 - val_mean_squared_error: 4.8747e-04\n",
      "Epoch 148/1000\n",
      " - 15s - loss: 4.7050e-04 - mean_squared_error: 4.7050e-04 - val_loss: 4.2363e-04 - val_mean_squared_error: 4.2363e-04\n",
      "Epoch 149/1000\n",
      " - 15s - loss: 4.6837e-04 - mean_squared_error: 4.6837e-04 - val_loss: 3.8316e-04 - val_mean_squared_error: 3.8316e-04\n",
      "Epoch 150/1000\n",
      " - 15s - loss: 4.6722e-04 - mean_squared_error: 4.6722e-04 - val_loss: 5.3801e-04 - val_mean_squared_error: 5.3801e-04\n",
      "Epoch 151/1000\n",
      " - 15s - loss: 4.6644e-04 - mean_squared_error: 4.6644e-04 - val_loss: 5.0593e-04 - val_mean_squared_error: 5.0593e-04\n",
      "Epoch 152/1000\n",
      " - 15s - loss: 4.6598e-04 - mean_squared_error: 4.6598e-04 - val_loss: 4.4756e-04 - val_mean_squared_error: 4.4756e-04\n",
      "Epoch 153/1000\n",
      " - 15s - loss: 4.6428e-04 - mean_squared_error: 4.6428e-04 - val_loss: 6.5718e-04 - val_mean_squared_error: 6.5718e-04\n",
      "Epoch 154/1000\n",
      " - 15s - loss: 4.6405e-04 - mean_squared_error: 4.6405e-04 - val_loss: 5.4570e-04 - val_mean_squared_error: 5.4570e-04\n",
      "Epoch 155/1000\n",
      " - 15s - loss: 4.6247e-04 - mean_squared_error: 4.6247e-04 - val_loss: 6.0501e-04 - val_mean_squared_error: 6.0501e-04\n",
      "Epoch 156/1000\n",
      " - 15s - loss: 4.6180e-04 - mean_squared_error: 4.6180e-04 - val_loss: 4.6106e-04 - val_mean_squared_error: 4.6106e-04\n",
      "Epoch 157/1000\n",
      " - 15s - loss: 4.6042e-04 - mean_squared_error: 4.6042e-04 - val_loss: 5.2211e-04 - val_mean_squared_error: 5.2211e-04\n",
      "Epoch 158/1000\n",
      " - 15s - loss: 4.5967e-04 - mean_squared_error: 4.5967e-04 - val_loss: 3.5816e-04 - val_mean_squared_error: 3.5816e-04\n",
      "Epoch 159/1000\n",
      " - 15s - loss: 4.5906e-04 - mean_squared_error: 4.5906e-04 - val_loss: 4.4596e-04 - val_mean_squared_error: 4.4596e-04\n",
      "Epoch 160/1000\n",
      " - 15s - loss: 4.5776e-04 - mean_squared_error: 4.5776e-04 - val_loss: 4.2360e-04 - val_mean_squared_error: 4.2360e-04\n",
      "Epoch 161/1000\n",
      " - 15s - loss: 4.5748e-04 - mean_squared_error: 4.5748e-04 - val_loss: 3.9281e-04 - val_mean_squared_error: 3.9281e-04\n",
      "Epoch 162/1000\n",
      " - 15s - loss: 4.5573e-04 - mean_squared_error: 4.5573e-04 - val_loss: 5.3200e-04 - val_mean_squared_error: 5.3200e-04\n",
      "Epoch 163/1000\n",
      " - 15s - loss: 4.5545e-04 - mean_squared_error: 4.5545e-04 - val_loss: 4.8523e-04 - val_mean_squared_error: 4.8523e-04\n",
      "Epoch 164/1000\n",
      " - 15s - loss: 4.5431e-04 - mean_squared_error: 4.5431e-04 - val_loss: 5.4647e-04 - val_mean_squared_error: 5.4647e-04\n",
      "Epoch 165/1000\n",
      " - 15s - loss: 4.5349e-04 - mean_squared_error: 4.5349e-04 - val_loss: 5.2449e-04 - val_mean_squared_error: 5.2449e-04\n",
      "Epoch 166/1000\n",
      " - 15s - loss: 4.5287e-04 - mean_squared_error: 4.5287e-04 - val_loss: 4.0674e-04 - val_mean_squared_error: 4.0674e-04\n",
      "Epoch 167/1000\n",
      " - 15s - loss: 4.5209e-04 - mean_squared_error: 4.5209e-04 - val_loss: 4.3880e-04 - val_mean_squared_error: 4.3880e-04\n",
      "Epoch 168/1000\n",
      " - 15s - loss: 4.5111e-04 - mean_squared_error: 4.5111e-04 - val_loss: 4.6081e-04 - val_mean_squared_error: 4.6081e-04\n",
      "Epoch 169/1000\n",
      " - 15s - loss: 4.5094e-04 - mean_squared_error: 4.5094e-04 - val_loss: 4.4783e-04 - val_mean_squared_error: 4.4783e-04\n",
      "Epoch 170/1000\n",
      " - 15s - loss: 4.5006e-04 - mean_squared_error: 4.5006e-04 - val_loss: 5.0468e-04 - val_mean_squared_error: 5.0468e-04\n",
      "Epoch 171/1000\n",
      " - 15s - loss: 4.4853e-04 - mean_squared_error: 4.4853e-04 - val_loss: 6.1467e-04 - val_mean_squared_error: 6.1467e-04\n",
      "Epoch 172/1000\n",
      " - 15s - loss: 4.4818e-04 - mean_squared_error: 4.4818e-04 - val_loss: 3.9043e-04 - val_mean_squared_error: 3.9043e-04\n",
      "Epoch 173/1000\n",
      " - 15s - loss: 4.4686e-04 - mean_squared_error: 4.4686e-04 - val_loss: 4.1470e-04 - val_mean_squared_error: 4.1470e-04\n",
      "Epoch 174/1000\n",
      " - 15s - loss: 4.4712e-04 - mean_squared_error: 4.4712e-04 - val_loss: 5.7746e-04 - val_mean_squared_error: 5.7746e-04\n",
      "Epoch 175/1000\n",
      " - 15s - loss: 4.4551e-04 - mean_squared_error: 4.4551e-04 - val_loss: 5.1332e-04 - val_mean_squared_error: 5.1332e-04\n",
      "Epoch 176/1000\n",
      " - 15s - loss: 4.4542e-04 - mean_squared_error: 4.4542e-04 - val_loss: 6.1225e-04 - val_mean_squared_error: 6.1225e-04\n",
      "Epoch 177/1000\n",
      " - 15s - loss: 4.4411e-04 - mean_squared_error: 4.4411e-04 - val_loss: 5.2227e-04 - val_mean_squared_error: 5.2227e-04\n",
      "Epoch 178/1000\n",
      " - 15s - loss: 4.4311e-04 - mean_squared_error: 4.4311e-04 - val_loss: 4.8004e-04 - val_mean_squared_error: 4.8004e-04\n",
      "Epoch 179/1000\n",
      " - 15s - loss: 4.4262e-04 - mean_squared_error: 4.4262e-04 - val_loss: 4.5720e-04 - val_mean_squared_error: 4.5720e-04\n",
      "Epoch 180/1000\n",
      " - 15s - loss: 4.4226e-04 - mean_squared_error: 4.4226e-04 - val_loss: 4.5816e-04 - val_mean_squared_error: 4.5816e-04\n",
      "Epoch 181/1000\n",
      " - 15s - loss: 4.4074e-04 - mean_squared_error: 4.4074e-04 - val_loss: 5.0229e-04 - val_mean_squared_error: 5.0229e-04\n",
      "Epoch 182/1000\n",
      " - 15s - loss: 4.4007e-04 - mean_squared_error: 4.4007e-04 - val_loss: 5.6765e-04 - val_mean_squared_error: 5.6765e-04\n",
      "Epoch 183/1000\n",
      " - 15s - loss: 4.3947e-04 - mean_squared_error: 4.3947e-04 - val_loss: 4.8220e-04 - val_mean_squared_error: 4.8220e-04\n",
      "Epoch 184/1000\n",
      " - 15s - loss: 4.3960e-04 - mean_squared_error: 4.3960e-04 - val_loss: 4.5047e-04 - val_mean_squared_error: 4.5047e-04\n",
      "Epoch 185/1000\n",
      " - 15s - loss: 4.3861e-04 - mean_squared_error: 4.3861e-04 - val_loss: 3.4298e-04 - val_mean_squared_error: 3.4298e-04\n",
      "Epoch 186/1000\n",
      " - 15s - loss: 4.3722e-04 - mean_squared_error: 4.3722e-04 - val_loss: 4.8381e-04 - val_mean_squared_error: 4.8381e-04\n",
      "Epoch 187/1000\n",
      " - 15s - loss: 4.3638e-04 - mean_squared_error: 4.3638e-04 - val_loss: 5.0636e-04 - val_mean_squared_error: 5.0636e-04\n",
      "Epoch 188/1000\n",
      " - 15s - loss: 4.3668e-04 - mean_squared_error: 4.3668e-04 - val_loss: 3.6262e-04 - val_mean_squared_error: 3.6262e-04\n",
      "Epoch 189/1000\n",
      " - 15s - loss: 4.3546e-04 - mean_squared_error: 4.3546e-04 - val_loss: 4.1047e-04 - val_mean_squared_error: 4.1047e-04\n",
      "Epoch 190/1000\n",
      " - 15s - loss: 4.3421e-04 - mean_squared_error: 4.3421e-04 - val_loss: 4.7826e-04 - val_mean_squared_error: 4.7826e-04\n",
      "Epoch 191/1000\n",
      " - 15s - loss: 4.3407e-04 - mean_squared_error: 4.3407e-04 - val_loss: 5.9768e-04 - val_mean_squared_error: 5.9768e-04\n",
      "Epoch 192/1000\n",
      " - 15s - loss: 4.3388e-04 - mean_squared_error: 4.3388e-04 - val_loss: 4.0180e-04 - val_mean_squared_error: 4.0180e-04\n",
      "Epoch 193/1000\n",
      " - 15s - loss: 4.3275e-04 - mean_squared_error: 4.3275e-04 - val_loss: 3.7775e-04 - val_mean_squared_error: 3.7775e-04\n",
      "Epoch 194/1000\n",
      " - 15s - loss: 4.3199e-04 - mean_squared_error: 4.3199e-04 - val_loss: 6.6582e-04 - val_mean_squared_error: 6.6582e-04\n",
      "Epoch 195/1000\n",
      " - 15s - loss: 4.3191e-04 - mean_squared_error: 4.3191e-04 - val_loss: 3.4039e-04 - val_mean_squared_error: 3.4039e-04\n",
      "Epoch 196/1000\n",
      " - 15s - loss: 4.3138e-04 - mean_squared_error: 4.3138e-04 - val_loss: 3.9725e-04 - val_mean_squared_error: 3.9725e-04\n",
      "Epoch 197/1000\n",
      " - 15s - loss: 4.3031e-04 - mean_squared_error: 4.3031e-04 - val_loss: 4.4815e-04 - val_mean_squared_error: 4.4815e-04\n",
      "Epoch 198/1000\n",
      " - 15s - loss: 4.3063e-04 - mean_squared_error: 4.3063e-04 - val_loss: 5.1791e-04 - val_mean_squared_error: 5.1791e-04\n",
      "Epoch 199/1000\n",
      " - 15s - loss: 4.2904e-04 - mean_squared_error: 4.2904e-04 - val_loss: 3.4324e-04 - val_mean_squared_error: 3.4324e-04\n",
      "Epoch 200/1000\n",
      " - 15s - loss: 4.2873e-04 - mean_squared_error: 4.2873e-04 - val_loss: 4.7801e-04 - val_mean_squared_error: 4.7801e-04\n",
      "Epoch 201/1000\n",
      " - 15s - loss: 4.2859e-04 - mean_squared_error: 4.2859e-04 - val_loss: 4.3640e-04 - val_mean_squared_error: 4.3640e-04\n",
      "Epoch 202/1000\n",
      " - 15s - loss: 4.2696e-04 - mean_squared_error: 4.2696e-04 - val_loss: 4.3731e-04 - val_mean_squared_error: 4.3731e-04\n",
      "Epoch 203/1000\n",
      " - 15s - loss: 4.2671e-04 - mean_squared_error: 4.2671e-04 - val_loss: 5.3773e-04 - val_mean_squared_error: 5.3773e-04\n",
      "Epoch 204/1000\n",
      " - 15s - loss: 4.2705e-04 - mean_squared_error: 4.2705e-04 - val_loss: 4.3596e-04 - val_mean_squared_error: 4.3596e-04\n",
      "Epoch 205/1000\n",
      " - 15s - loss: 4.2556e-04 - mean_squared_error: 4.2556e-04 - val_loss: 5.0128e-04 - val_mean_squared_error: 5.0128e-04\n",
      "Epoch 206/1000\n",
      " - 15s - loss: 4.2584e-04 - mean_squared_error: 4.2584e-04 - val_loss: 4.4545e-04 - val_mean_squared_error: 4.4545e-04\n",
      "Epoch 207/1000\n",
      " - 15s - loss: 4.2437e-04 - mean_squared_error: 4.2437e-04 - val_loss: 3.9683e-04 - val_mean_squared_error: 3.9683e-04\n",
      "Epoch 208/1000\n",
      " - 15s - loss: 4.2441e-04 - mean_squared_error: 4.2441e-04 - val_loss: 5.4786e-04 - val_mean_squared_error: 5.4786e-04\n",
      "Epoch 209/1000\n",
      " - 15s - loss: 4.2343e-04 - mean_squared_error: 4.2343e-04 - val_loss: 5.0708e-04 - val_mean_squared_error: 5.0708e-04\n",
      "Epoch 210/1000\n",
      " - 15s - loss: 4.2324e-04 - mean_squared_error: 4.2324e-04 - val_loss: 4.1277e-04 - val_mean_squared_error: 4.1277e-04\n",
      "Epoch 211/1000\n",
      " - 15s - loss: 4.2273e-04 - mean_squared_error: 4.2273e-04 - val_loss: 4.5363e-04 - val_mean_squared_error: 4.5363e-04\n",
      "Epoch 212/1000\n",
      " - 15s - loss: 4.2224e-04 - mean_squared_error: 4.2224e-04 - val_loss: 3.8016e-04 - val_mean_squared_error: 3.8016e-04\n",
      "Epoch 213/1000\n",
      " - 15s - loss: 4.2131e-04 - mean_squared_error: 4.2131e-04 - val_loss: 3.5275e-04 - val_mean_squared_error: 3.5275e-04\n",
      "Epoch 214/1000\n",
      " - 15s - loss: 4.2095e-04 - mean_squared_error: 4.2095e-04 - val_loss: 4.6656e-04 - val_mean_squared_error: 4.6656e-04\n",
      "Epoch 215/1000\n",
      " - 15s - loss: 4.2063e-04 - mean_squared_error: 4.2063e-04 - val_loss: 6.1048e-04 - val_mean_squared_error: 6.1048e-04\n",
      "Epoch 216/1000\n",
      " - 15s - loss: 4.2042e-04 - mean_squared_error: 4.2042e-04 - val_loss: 3.9405e-04 - val_mean_squared_error: 3.9405e-04\n",
      "Epoch 217/1000\n",
      " - 15s - loss: 4.1948e-04 - mean_squared_error: 4.1948e-04 - val_loss: 4.7296e-04 - val_mean_squared_error: 4.7296e-04\n",
      "Epoch 218/1000\n",
      " - 15s - loss: 4.1922e-04 - mean_squared_error: 4.1922e-04 - val_loss: 4.1012e-04 - val_mean_squared_error: 4.1012e-04\n",
      "Epoch 219/1000\n",
      " - 15s - loss: 4.1866e-04 - mean_squared_error: 4.1866e-04 - val_loss: 3.5725e-04 - val_mean_squared_error: 3.5725e-04\n",
      "Epoch 220/1000\n",
      " - 15s - loss: 4.1771e-04 - mean_squared_error: 4.1771e-04 - val_loss: 5.3989e-04 - val_mean_squared_error: 5.3989e-04\n",
      "Epoch 221/1000\n",
      " - 15s - loss: 4.1781e-04 - mean_squared_error: 4.1781e-04 - val_loss: 3.7193e-04 - val_mean_squared_error: 3.7193e-04\n",
      "Epoch 222/1000\n",
      " - 15s - loss: 4.1653e-04 - mean_squared_error: 4.1653e-04 - val_loss: 4.5379e-04 - val_mean_squared_error: 4.5379e-04\n",
      "Epoch 223/1000\n",
      " - 15s - loss: 4.1654e-04 - mean_squared_error: 4.1654e-04 - val_loss: 5.6645e-04 - val_mean_squared_error: 5.6645e-04\n",
      "Epoch 224/1000\n",
      " - 15s - loss: 4.1577e-04 - mean_squared_error: 4.1577e-04 - val_loss: 3.7838e-04 - val_mean_squared_error: 3.7838e-04\n",
      "Epoch 225/1000\n",
      " - 15s - loss: 4.1546e-04 - mean_squared_error: 4.1546e-04 - val_loss: 5.5159e-04 - val_mean_squared_error: 5.5159e-04\n",
      "Epoch 226/1000\n",
      " - 15s - loss: 4.1529e-04 - mean_squared_error: 4.1529e-04 - val_loss: 5.0684e-04 - val_mean_squared_error: 5.0684e-04\n",
      "Epoch 227/1000\n",
      " - 15s - loss: 4.1446e-04 - mean_squared_error: 4.1446e-04 - val_loss: 6.3671e-04 - val_mean_squared_error: 6.3671e-04\n",
      "Epoch 228/1000\n",
      " - 15s - loss: 4.1442e-04 - mean_squared_error: 4.1442e-04 - val_loss: 4.5859e-04 - val_mean_squared_error: 4.5859e-04\n",
      "Epoch 229/1000\n",
      " - 15s - loss: 4.1413e-04 - mean_squared_error: 4.1413e-04 - val_loss: 3.8188e-04 - val_mean_squared_error: 3.8188e-04\n",
      "Epoch 230/1000\n",
      " - 15s - loss: 4.1322e-04 - mean_squared_error: 4.1322e-04 - val_loss: 3.7388e-04 - val_mean_squared_error: 3.7388e-04\n",
      "Epoch 231/1000\n",
      " - 15s - loss: 4.1249e-04 - mean_squared_error: 4.1249e-04 - val_loss: 3.7210e-04 - val_mean_squared_error: 3.7210e-04\n",
      "Epoch 232/1000\n",
      " - 15s - loss: 4.1244e-04 - mean_squared_error: 4.1244e-04 - val_loss: 4.4039e-04 - val_mean_squared_error: 4.4039e-04\n",
      "Epoch 233/1000\n",
      " - 15s - loss: 4.1208e-04 - mean_squared_error: 4.1208e-04 - val_loss: 3.3982e-04 - val_mean_squared_error: 3.3982e-04\n",
      "Epoch 234/1000\n",
      " - 15s - loss: 4.1136e-04 - mean_squared_error: 4.1136e-04 - val_loss: 3.5551e-04 - val_mean_squared_error: 3.5551e-04\n",
      "Epoch 235/1000\n",
      " - 15s - loss: 4.1144e-04 - mean_squared_error: 4.1144e-04 - val_loss: 4.8057e-04 - val_mean_squared_error: 4.8057e-04\n",
      "Epoch 236/1000\n",
      " - 15s - loss: 4.1137e-04 - mean_squared_error: 4.1137e-04 - val_loss: 3.6218e-04 - val_mean_squared_error: 3.6218e-04\n",
      "Epoch 237/1000\n",
      " - 15s - loss: 4.0971e-04 - mean_squared_error: 4.0971e-04 - val_loss: 4.4634e-04 - val_mean_squared_error: 4.4634e-04\n",
      "Epoch 238/1000\n",
      " - 15s - loss: 4.1001e-04 - mean_squared_error: 4.1001e-04 - val_loss: 4.9313e-04 - val_mean_squared_error: 4.9313e-04\n",
      "Epoch 239/1000\n",
      " - 15s - loss: 4.0883e-04 - mean_squared_error: 4.0883e-04 - val_loss: 4.9256e-04 - val_mean_squared_error: 4.9256e-04\n",
      "Epoch 240/1000\n",
      " - 15s - loss: 4.0894e-04 - mean_squared_error: 4.0894e-04 - val_loss: 3.1616e-04 - val_mean_squared_error: 3.1616e-04\n",
      "Epoch 241/1000\n",
      " - 15s - loss: 4.0774e-04 - mean_squared_error: 4.0774e-04 - val_loss: 5.1095e-04 - val_mean_squared_error: 5.1095e-04\n",
      "Epoch 242/1000\n",
      " - 15s - loss: 4.0824e-04 - mean_squared_error: 4.0824e-04 - val_loss: 4.8706e-04 - val_mean_squared_error: 4.8706e-04\n",
      "Epoch 243/1000\n",
      " - 15s - loss: 4.0714e-04 - mean_squared_error: 4.0714e-04 - val_loss: 3.2777e-04 - val_mean_squared_error: 3.2777e-04\n",
      "Epoch 244/1000\n",
      " - 15s - loss: 4.0687e-04 - mean_squared_error: 4.0687e-04 - val_loss: 4.1273e-04 - val_mean_squared_error: 4.1273e-04\n",
      "Epoch 245/1000\n",
      " - 15s - loss: 4.0683e-04 - mean_squared_error: 4.0683e-04 - val_loss: 4.1708e-04 - val_mean_squared_error: 4.1708e-04\n",
      "Epoch 246/1000\n",
      " - 15s - loss: 4.0637e-04 - mean_squared_error: 4.0637e-04 - val_loss: 5.4221e-04 - val_mean_squared_error: 5.4221e-04\n",
      "Epoch 247/1000\n",
      " - 15s - loss: 4.0611e-04 - mean_squared_error: 4.0611e-04 - val_loss: 3.7757e-04 - val_mean_squared_error: 3.7757e-04\n",
      "Epoch 248/1000\n",
      " - 15s - loss: 4.0509e-04 - mean_squared_error: 4.0509e-04 - val_loss: 3.2138e-04 - val_mean_squared_error: 3.2138e-04\n",
      "Epoch 249/1000\n",
      " - 15s - loss: 4.0546e-04 - mean_squared_error: 4.0546e-04 - val_loss: 3.6346e-04 - val_mean_squared_error: 3.6346e-04\n",
      "Epoch 250/1000\n",
      " - 15s - loss: 4.0467e-04 - mean_squared_error: 4.0467e-04 - val_loss: 4.8938e-04 - val_mean_squared_error: 4.8938e-04\n",
      "Epoch 251/1000\n",
      " - 15s - loss: 4.0439e-04 - mean_squared_error: 4.0439e-04 - val_loss: 3.5616e-04 - val_mean_squared_error: 3.5616e-04\n",
      "Epoch 252/1000\n",
      " - 15s - loss: 4.0372e-04 - mean_squared_error: 4.0372e-04 - val_loss: 5.3901e-04 - val_mean_squared_error: 5.3901e-04\n",
      "Epoch 253/1000\n",
      " - 15s - loss: 4.0302e-04 - mean_squared_error: 4.0302e-04 - val_loss: 4.7596e-04 - val_mean_squared_error: 4.7596e-04\n",
      "Epoch 254/1000\n",
      " - 15s - loss: 4.0290e-04 - mean_squared_error: 4.0290e-04 - val_loss: 4.7480e-04 - val_mean_squared_error: 4.7480e-04\n",
      "Epoch 255/1000\n",
      " - 15s - loss: 4.0311e-04 - mean_squared_error: 4.0311e-04 - val_loss: 3.5922e-04 - val_mean_squared_error: 3.5922e-04\n",
      "Epoch 256/1000\n",
      " - 15s - loss: 4.0208e-04 - mean_squared_error: 4.0208e-04 - val_loss: 4.4469e-04 - val_mean_squared_error: 4.4469e-04\n",
      "Epoch 257/1000\n",
      " - 15s - loss: 4.0190e-04 - mean_squared_error: 4.0190e-04 - val_loss: 4.5832e-04 - val_mean_squared_error: 4.5832e-04\n",
      "Epoch 258/1000\n",
      " - 15s - loss: 4.0142e-04 - mean_squared_error: 4.0142e-04 - val_loss: 4.7530e-04 - val_mean_squared_error: 4.7530e-04\n",
      "Epoch 259/1000\n",
      " - 15s - loss: 4.0126e-04 - mean_squared_error: 4.0126e-04 - val_loss: 4.2047e-04 - val_mean_squared_error: 4.2047e-04\n",
      "Epoch 260/1000\n",
      " - 15s - loss: 4.0103e-04 - mean_squared_error: 4.0103e-04 - val_loss: 4.6073e-04 - val_mean_squared_error: 4.6073e-04\n",
      "Epoch 261/1000\n",
      " - 15s - loss: 4.0000e-04 - mean_squared_error: 4.0000e-04 - val_loss: 3.9047e-04 - val_mean_squared_error: 3.9047e-04\n",
      "Epoch 262/1000\n",
      " - 15s - loss: 3.9960e-04 - mean_squared_error: 3.9960e-04 - val_loss: 4.8910e-04 - val_mean_squared_error: 4.8910e-04\n",
      "Epoch 263/1000\n",
      " - 15s - loss: 3.9946e-04 - mean_squared_error: 3.9946e-04 - val_loss: 3.5171e-04 - val_mean_squared_error: 3.5171e-04\n",
      "Epoch 264/1000\n",
      " - 15s - loss: 3.9914e-04 - mean_squared_error: 3.9914e-04 - val_loss: 3.2436e-04 - val_mean_squared_error: 3.2436e-04\n",
      "Epoch 265/1000\n",
      " - 15s - loss: 3.9903e-04 - mean_squared_error: 3.9903e-04 - val_loss: 3.5812e-04 - val_mean_squared_error: 3.5812e-04\n",
      "Epoch 266/1000\n",
      " - 15s - loss: 3.9816e-04 - mean_squared_error: 3.9816e-04 - val_loss: 3.1641e-04 - val_mean_squared_error: 3.1641e-04\n",
      "Epoch 267/1000\n",
      " - 15s - loss: 3.9850e-04 - mean_squared_error: 3.9850e-04 - val_loss: 4.5672e-04 - val_mean_squared_error: 4.5672e-04\n",
      "Epoch 268/1000\n",
      " - 15s - loss: 3.9772e-04 - mean_squared_error: 3.9772e-04 - val_loss: 5.5218e-04 - val_mean_squared_error: 5.5218e-04\n",
      "Epoch 269/1000\n",
      " - 15s - loss: 3.9717e-04 - mean_squared_error: 3.9717e-04 - val_loss: 5.1943e-04 - val_mean_squared_error: 5.1943e-04\n",
      "Epoch 270/1000\n",
      " - 15s - loss: 3.9778e-04 - mean_squared_error: 3.9778e-04 - val_loss: 3.5958e-04 - val_mean_squared_error: 3.5958e-04\n",
      "Epoch 271/1000\n",
      " - 15s - loss: 3.9677e-04 - mean_squared_error: 3.9677e-04 - val_loss: 4.1855e-04 - val_mean_squared_error: 4.1855e-04\n",
      "Epoch 272/1000\n",
      " - 15s - loss: 3.9655e-04 - mean_squared_error: 3.9655e-04 - val_loss: 3.9752e-04 - val_mean_squared_error: 3.9752e-04\n",
      "Epoch 273/1000\n",
      " - 15s - loss: 3.9602e-04 - mean_squared_error: 3.9602e-04 - val_loss: 5.2879e-04 - val_mean_squared_error: 5.2879e-04\n",
      "Epoch 274/1000\n",
      " - 15s - loss: 3.9585e-04 - mean_squared_error: 3.9585e-04 - val_loss: 3.4298e-04 - val_mean_squared_error: 3.4298e-04\n",
      "Epoch 275/1000\n",
      " - 15s - loss: 3.9537e-04 - mean_squared_error: 3.9537e-04 - val_loss: 3.5003e-04 - val_mean_squared_error: 3.5003e-04\n",
      "Epoch 276/1000\n",
      " - 15s - loss: 3.9437e-04 - mean_squared_error: 3.9437e-04 - val_loss: 4.1628e-04 - val_mean_squared_error: 4.1628e-04\n",
      "Epoch 277/1000\n",
      " - 15s - loss: 3.9462e-04 - mean_squared_error: 3.9462e-04 - val_loss: 4.1743e-04 - val_mean_squared_error: 4.1743e-04\n",
      "Epoch 278/1000\n",
      " - 15s - loss: 3.9489e-04 - mean_squared_error: 3.9489e-04 - val_loss: 3.5997e-04 - val_mean_squared_error: 3.5997e-04\n",
      "Epoch 279/1000\n",
      " - 15s - loss: 3.9395e-04 - mean_squared_error: 3.9395e-04 - val_loss: 4.1098e-04 - val_mean_squared_error: 4.1098e-04\n",
      "Epoch 280/1000\n",
      " - 15s - loss: 3.9359e-04 - mean_squared_error: 3.9359e-04 - val_loss: 3.9485e-04 - val_mean_squared_error: 3.9485e-04\n",
      "Epoch 281/1000\n",
      " - 15s - loss: 3.9415e-04 - mean_squared_error: 3.9415e-04 - val_loss: 3.1419e-04 - val_mean_squared_error: 3.1419e-04\n",
      "Epoch 282/1000\n",
      " - 15s - loss: 3.9259e-04 - mean_squared_error: 3.9259e-04 - val_loss: 3.5093e-04 - val_mean_squared_error: 3.5093e-04\n",
      "Epoch 283/1000\n",
      " - 15s - loss: 3.9265e-04 - mean_squared_error: 3.9265e-04 - val_loss: 3.9479e-04 - val_mean_squared_error: 3.9479e-04\n",
      "Epoch 284/1000\n",
      " - 15s - loss: 3.9264e-04 - mean_squared_error: 3.9264e-04 - val_loss: 4.6138e-04 - val_mean_squared_error: 4.6138e-04\n",
      "Epoch 285/1000\n",
      " - 15s - loss: 3.9176e-04 - mean_squared_error: 3.9176e-04 - val_loss: 3.5592e-04 - val_mean_squared_error: 3.5592e-04\n",
      "Epoch 286/1000\n",
      " - 15s - loss: 3.9139e-04 - mean_squared_error: 3.9139e-04 - val_loss: 4.1184e-04 - val_mean_squared_error: 4.1184e-04\n",
      "Epoch 287/1000\n",
      " - 15s - loss: 3.9143e-04 - mean_squared_error: 3.9143e-04 - val_loss: 3.6818e-04 - val_mean_squared_error: 3.6818e-04\n",
      "Epoch 288/1000\n",
      " - 15s - loss: 3.9111e-04 - mean_squared_error: 3.9111e-04 - val_loss: 3.1251e-04 - val_mean_squared_error: 3.1251e-04\n",
      "Epoch 289/1000\n",
      " - 15s - loss: 3.9067e-04 - mean_squared_error: 3.9067e-04 - val_loss: 5.0885e-04 - val_mean_squared_error: 5.0885e-04\n",
      "Epoch 290/1000\n",
      " - 15s - loss: 3.9041e-04 - mean_squared_error: 3.9041e-04 - val_loss: 3.0856e-04 - val_mean_squared_error: 3.0856e-04\n",
      "Epoch 291/1000\n",
      " - 15s - loss: 3.9010e-04 - mean_squared_error: 3.9010e-04 - val_loss: 4.5266e-04 - val_mean_squared_error: 4.5266e-04\n",
      "Epoch 292/1000\n",
      " - 15s - loss: 3.8977e-04 - mean_squared_error: 3.8977e-04 - val_loss: 4.1596e-04 - val_mean_squared_error: 4.1596e-04\n",
      "Epoch 293/1000\n",
      " - 15s - loss: 3.8926e-04 - mean_squared_error: 3.8926e-04 - val_loss: 5.3449e-04 - val_mean_squared_error: 5.3449e-04\n",
      "Epoch 294/1000\n",
      " - 15s - loss: 3.8918e-04 - mean_squared_error: 3.8918e-04 - val_loss: 4.0488e-04 - val_mean_squared_error: 4.0488e-04\n",
      "Epoch 295/1000\n",
      " - 15s - loss: 3.8892e-04 - mean_squared_error: 3.8892e-04 - val_loss: 4.5749e-04 - val_mean_squared_error: 4.5749e-04\n",
      "Epoch 296/1000\n",
      " - 15s - loss: 3.8880e-04 - mean_squared_error: 3.8880e-04 - val_loss: 3.3875e-04 - val_mean_squared_error: 3.3875e-04\n",
      "Epoch 297/1000\n",
      " - 15s - loss: 3.8821e-04 - mean_squared_error: 3.8821e-04 - val_loss: 3.9988e-04 - val_mean_squared_error: 3.9988e-04\n",
      "Epoch 298/1000\n",
      " - 15s - loss: 3.8783e-04 - mean_squared_error: 3.8783e-04 - val_loss: 4.2394e-04 - val_mean_squared_error: 4.2394e-04\n",
      "Epoch 299/1000\n",
      " - 15s - loss: 3.8760e-04 - mean_squared_error: 3.8760e-04 - val_loss: 3.2590e-04 - val_mean_squared_error: 3.2590e-04\n",
      "Epoch 300/1000\n",
      " - 15s - loss: 3.8684e-04 - mean_squared_error: 3.8684e-04 - val_loss: 3.3020e-04 - val_mean_squared_error: 3.3020e-04\n",
      "Epoch 301/1000\n",
      " - 15s - loss: 3.8746e-04 - mean_squared_error: 3.8746e-04 - val_loss: 3.1820e-04 - val_mean_squared_error: 3.1820e-04\n",
      "Epoch 302/1000\n",
      " - 15s - loss: 3.8677e-04 - mean_squared_error: 3.8677e-04 - val_loss: 3.4030e-04 - val_mean_squared_error: 3.4030e-04\n",
      "Epoch 303/1000\n",
      " - 15s - loss: 3.8598e-04 - mean_squared_error: 3.8598e-04 - val_loss: 4.3482e-04 - val_mean_squared_error: 4.3482e-04\n",
      "Epoch 304/1000\n",
      " - 15s - loss: 3.8623e-04 - mean_squared_error: 3.8623e-04 - val_loss: 3.8538e-04 - val_mean_squared_error: 3.8538e-04\n",
      "Epoch 305/1000\n",
      " - 15s - loss: 3.8623e-04 - mean_squared_error: 3.8623e-04 - val_loss: 3.3074e-04 - val_mean_squared_error: 3.3074e-04\n",
      "Epoch 306/1000\n",
      " - 15s - loss: 3.8512e-04 - mean_squared_error: 3.8512e-04 - val_loss: 3.4125e-04 - val_mean_squared_error: 3.4125e-04\n",
      "Epoch 307/1000\n",
      " - 15s - loss: 3.8455e-04 - mean_squared_error: 3.8455e-04 - val_loss: 3.5002e-04 - val_mean_squared_error: 3.5002e-04\n",
      "Epoch 308/1000\n",
      " - 15s - loss: 3.8523e-04 - mean_squared_error: 3.8523e-04 - val_loss: 4.2803e-04 - val_mean_squared_error: 4.2803e-04\n",
      "Epoch 309/1000\n",
      " - 15s - loss: 3.8463e-04 - mean_squared_error: 3.8463e-04 - val_loss: 3.2043e-04 - val_mean_squared_error: 3.2043e-04\n",
      "Epoch 310/1000\n",
      " - 15s - loss: 3.8383e-04 - mean_squared_error: 3.8383e-04 - val_loss: 3.8213e-04 - val_mean_squared_error: 3.8213e-04\n",
      "Epoch 311/1000\n",
      " - 15s - loss: 3.8400e-04 - mean_squared_error: 3.8400e-04 - val_loss: 3.1776e-04 - val_mean_squared_error: 3.1776e-04\n",
      "Epoch 312/1000\n",
      " - 15s - loss: 3.8356e-04 - mean_squared_error: 3.8356e-04 - val_loss: 3.5831e-04 - val_mean_squared_error: 3.5831e-04\n",
      "Epoch 313/1000\n",
      " - 15s - loss: 3.8349e-04 - mean_squared_error: 3.8349e-04 - val_loss: 3.9760e-04 - val_mean_squared_error: 3.9760e-04\n",
      "Epoch 314/1000\n",
      " - 15s - loss: 3.8305e-04 - mean_squared_error: 3.8305e-04 - val_loss: 5.9975e-04 - val_mean_squared_error: 5.9975e-04\n",
      "Epoch 315/1000\n",
      " - 15s - loss: 3.8313e-04 - mean_squared_error: 3.8313e-04 - val_loss: 4.9458e-04 - val_mean_squared_error: 4.9458e-04\n",
      "Epoch 316/1000\n",
      " - 15s - loss: 3.8228e-04 - mean_squared_error: 3.8228e-04 - val_loss: 4.4769e-04 - val_mean_squared_error: 4.4769e-04\n",
      "Epoch 317/1000\n",
      " - 15s - loss: 3.8223e-04 - mean_squared_error: 3.8223e-04 - val_loss: 3.5895e-04 - val_mean_squared_error: 3.5895e-04\n",
      "Epoch 318/1000\n",
      " - 15s - loss: 3.8236e-04 - mean_squared_error: 3.8236e-04 - val_loss: 3.8068e-04 - val_mean_squared_error: 3.8068e-04\n",
      "Epoch 319/1000\n",
      " - 15s - loss: 3.8202e-04 - mean_squared_error: 3.8202e-04 - val_loss: 5.1277e-04 - val_mean_squared_error: 5.1277e-04\n",
      "Epoch 320/1000\n",
      " - 15s - loss: 3.8120e-04 - mean_squared_error: 3.8120e-04 - val_loss: 3.4157e-04 - val_mean_squared_error: 3.4157e-04\n",
      "Epoch 321/1000\n",
      " - 15s - loss: 3.8159e-04 - mean_squared_error: 3.8159e-04 - val_loss: 4.3985e-04 - val_mean_squared_error: 4.3985e-04\n",
      "Epoch 322/1000\n",
      " - 15s - loss: 3.8110e-04 - mean_squared_error: 3.8110e-04 - val_loss: 3.8091e-04 - val_mean_squared_error: 3.8091e-04\n",
      "Epoch 323/1000\n",
      " - 15s - loss: 3.8039e-04 - mean_squared_error: 3.8039e-04 - val_loss: 5.2766e-04 - val_mean_squared_error: 5.2766e-04\n",
      "Epoch 324/1000\n",
      " - 15s - loss: 3.8067e-04 - mean_squared_error: 3.8067e-04 - val_loss: 4.3415e-04 - val_mean_squared_error: 4.3415e-04\n",
      "Epoch 325/1000\n",
      " - 15s - loss: 3.7965e-04 - mean_squared_error: 3.7965e-04 - val_loss: 4.0668e-04 - val_mean_squared_error: 4.0668e-04\n",
      "Epoch 326/1000\n",
      " - 15s - loss: 3.7984e-04 - mean_squared_error: 3.7984e-04 - val_loss: 3.3657e-04 - val_mean_squared_error: 3.3657e-04\n",
      "Epoch 327/1000\n",
      " - 15s - loss: 3.7952e-04 - mean_squared_error: 3.7952e-04 - val_loss: 3.4077e-04 - val_mean_squared_error: 3.4077e-04\n",
      "Epoch 328/1000\n",
      " - 15s - loss: 3.7968e-04 - mean_squared_error: 3.7968e-04 - val_loss: 4.3861e-04 - val_mean_squared_error: 4.3861e-04\n",
      "Epoch 329/1000\n",
      " - 15s - loss: 3.7898e-04 - mean_squared_error: 3.7898e-04 - val_loss: 3.9145e-04 - val_mean_squared_error: 3.9145e-04\n",
      "Epoch 330/1000\n",
      " - 15s - loss: 3.7920e-04 - mean_squared_error: 3.7920e-04 - val_loss: 3.2642e-04 - val_mean_squared_error: 3.2642e-04\n",
      "Epoch 331/1000\n",
      " - 15s - loss: 3.7874e-04 - mean_squared_error: 3.7874e-04 - val_loss: 3.4077e-04 - val_mean_squared_error: 3.4077e-04\n",
      "Epoch 332/1000\n",
      " - 15s - loss: 3.7844e-04 - mean_squared_error: 3.7844e-04 - val_loss: 4.8090e-04 - val_mean_squared_error: 4.8090e-04\n",
      "Epoch 333/1000\n",
      " - 15s - loss: 3.7767e-04 - mean_squared_error: 3.7767e-04 - val_loss: 4.0804e-04 - val_mean_squared_error: 4.0804e-04\n",
      "Epoch 334/1000\n",
      " - 15s - loss: 3.7807e-04 - mean_squared_error: 3.7807e-04 - val_loss: 4.3686e-04 - val_mean_squared_error: 4.3686e-04\n",
      "Epoch 335/1000\n",
      " - 15s - loss: 3.7788e-04 - mean_squared_error: 3.7788e-04 - val_loss: 3.0821e-04 - val_mean_squared_error: 3.0821e-04\n",
      "Epoch 336/1000\n",
      " - 15s - loss: 3.7795e-04 - mean_squared_error: 3.7795e-04 - val_loss: 2.8330e-04 - val_mean_squared_error: 2.8330e-04\n",
      "Epoch 337/1000\n",
      " - 15s - loss: 3.7731e-04 - mean_squared_error: 3.7731e-04 - val_loss: 3.0865e-04 - val_mean_squared_error: 3.0865e-04\n",
      "Epoch 338/1000\n",
      " - 15s - loss: 3.7729e-04 - mean_squared_error: 3.7729e-04 - val_loss: 4.6937e-04 - val_mean_squared_error: 4.6937e-04\n",
      "Epoch 339/1000\n",
      " - 15s - loss: 3.7716e-04 - mean_squared_error: 3.7716e-04 - val_loss: 3.0962e-04 - val_mean_squared_error: 3.0962e-04\n",
      "Epoch 340/1000\n",
      " - 15s - loss: 3.7679e-04 - mean_squared_error: 3.7679e-04 - val_loss: 2.7217e-04 - val_mean_squared_error: 2.7217e-04\n",
      "Epoch 341/1000\n",
      " - 15s - loss: 3.7674e-04 - mean_squared_error: 3.7674e-04 - val_loss: 3.7885e-04 - val_mean_squared_error: 3.7885e-04\n",
      "Epoch 342/1000\n",
      " - 15s - loss: 3.7607e-04 - mean_squared_error: 3.7607e-04 - val_loss: 2.9356e-04 - val_mean_squared_error: 2.9356e-04\n",
      "Epoch 343/1000\n",
      " - 15s - loss: 3.7624e-04 - mean_squared_error: 3.7624e-04 - val_loss: 2.9022e-04 - val_mean_squared_error: 2.9022e-04\n",
      "Epoch 344/1000\n",
      " - 15s - loss: 3.7533e-04 - mean_squared_error: 3.7533e-04 - val_loss: 3.0132e-04 - val_mean_squared_error: 3.0132e-04\n",
      "Epoch 345/1000\n",
      " - 15s - loss: 3.7494e-04 - mean_squared_error: 3.7494e-04 - val_loss: 3.9765e-04 - val_mean_squared_error: 3.9765e-04\n",
      "Epoch 346/1000\n",
      " - 15s - loss: 3.7532e-04 - mean_squared_error: 3.7532e-04 - val_loss: 5.3541e-04 - val_mean_squared_error: 5.3541e-04\n",
      "Epoch 347/1000\n",
      " - 15s - loss: 3.7525e-04 - mean_squared_error: 3.7525e-04 - val_loss: 3.0601e-04 - val_mean_squared_error: 3.0601e-04\n",
      "Epoch 348/1000\n",
      " - 15s - loss: 3.7484e-04 - mean_squared_error: 3.7484e-04 - val_loss: 2.8864e-04 - val_mean_squared_error: 2.8864e-04\n",
      "Epoch 349/1000\n",
      " - 15s - loss: 3.7460e-04 - mean_squared_error: 3.7460e-04 - val_loss: 4.1165e-04 - val_mean_squared_error: 4.1165e-04\n",
      "Epoch 350/1000\n",
      " - 15s - loss: 3.7473e-04 - mean_squared_error: 3.7473e-04 - val_loss: 2.6371e-04 - val_mean_squared_error: 2.6371e-04\n",
      "Epoch 351/1000\n",
      " - 15s - loss: 3.7380e-04 - mean_squared_error: 3.7380e-04 - val_loss: 4.4921e-04 - val_mean_squared_error: 4.4921e-04\n",
      "Epoch 352/1000\n",
      " - 15s - loss: 3.7379e-04 - mean_squared_error: 3.7379e-04 - val_loss: 3.9740e-04 - val_mean_squared_error: 3.9740e-04\n",
      "Epoch 353/1000\n",
      " - 15s - loss: 3.7368e-04 - mean_squared_error: 3.7368e-04 - val_loss: 3.8676e-04 - val_mean_squared_error: 3.8676e-04\n",
      "Epoch 354/1000\n",
      " - 15s - loss: 3.7346e-04 - mean_squared_error: 3.7346e-04 - val_loss: 3.1957e-04 - val_mean_squared_error: 3.1957e-04\n",
      "Epoch 355/1000\n",
      " - 15s - loss: 3.7313e-04 - mean_squared_error: 3.7313e-04 - val_loss: 4.8467e-04 - val_mean_squared_error: 4.8467e-04\n",
      "Epoch 356/1000\n",
      " - 15s - loss: 3.7321e-04 - mean_squared_error: 3.7321e-04 - val_loss: 3.0101e-04 - val_mean_squared_error: 3.0101e-04\n",
      "Epoch 357/1000\n",
      " - 15s - loss: 3.7285e-04 - mean_squared_error: 3.7285e-04 - val_loss: 6.6959e-04 - val_mean_squared_error: 6.6959e-04\n",
      "Epoch 358/1000\n",
      " - 15s - loss: 3.7303e-04 - mean_squared_error: 3.7303e-04 - val_loss: 3.0923e-04 - val_mean_squared_error: 3.0923e-04\n",
      "Epoch 359/1000\n",
      " - 15s - loss: 3.7214e-04 - mean_squared_error: 3.7214e-04 - val_loss: 2.7520e-04 - val_mean_squared_error: 2.7520e-04\n",
      "Epoch 360/1000\n",
      " - 15s - loss: 3.7211e-04 - mean_squared_error: 3.7211e-04 - val_loss: 4.4516e-04 - val_mean_squared_error: 4.4516e-04\n",
      "Epoch 361/1000\n",
      " - 15s - loss: 3.7231e-04 - mean_squared_error: 3.7231e-04 - val_loss: 3.7335e-04 - val_mean_squared_error: 3.7335e-04\n",
      "Epoch 362/1000\n",
      " - 15s - loss: 3.7169e-04 - mean_squared_error: 3.7169e-04 - val_loss: 4.7000e-04 - val_mean_squared_error: 4.7000e-04\n",
      "Epoch 363/1000\n",
      " - 15s - loss: 3.7173e-04 - mean_squared_error: 3.7173e-04 - val_loss: 4.6809e-04 - val_mean_squared_error: 4.6809e-04\n",
      "Epoch 364/1000\n",
      " - 15s - loss: 3.7136e-04 - mean_squared_error: 3.7136e-04 - val_loss: 3.7587e-04 - val_mean_squared_error: 3.7587e-04\n",
      "Epoch 365/1000\n",
      " - 15s - loss: 3.7155e-04 - mean_squared_error: 3.7155e-04 - val_loss: 3.8032e-04 - val_mean_squared_error: 3.8032e-04\n",
      "Epoch 366/1000\n",
      " - 15s - loss: 3.7095e-04 - mean_squared_error: 3.7095e-04 - val_loss: 3.9394e-04 - val_mean_squared_error: 3.9394e-04\n",
      "Epoch 367/1000\n",
      " - 15s - loss: 3.7078e-04 - mean_squared_error: 3.7078e-04 - val_loss: 3.8201e-04 - val_mean_squared_error: 3.8201e-04\n",
      "Epoch 368/1000\n",
      " - 15s - loss: 3.7045e-04 - mean_squared_error: 3.7045e-04 - val_loss: 3.2485e-04 - val_mean_squared_error: 3.2485e-04\n",
      "Epoch 369/1000\n",
      " - 15s - loss: 3.7052e-04 - mean_squared_error: 3.7052e-04 - val_loss: 5.1618e-04 - val_mean_squared_error: 5.1618e-04\n",
      "Epoch 370/1000\n",
      " - 15s - loss: 3.7033e-04 - mean_squared_error: 3.7033e-04 - val_loss: 3.5249e-04 - val_mean_squared_error: 3.5249e-04\n",
      "Epoch 371/1000\n",
      " - 15s - loss: 3.7054e-04 - mean_squared_error: 3.7054e-04 - val_loss: 3.0523e-04 - val_mean_squared_error: 3.0523e-04\n",
      "Epoch 372/1000\n",
      " - 15s - loss: 3.6951e-04 - mean_squared_error: 3.6951e-04 - val_loss: 4.3155e-04 - val_mean_squared_error: 4.3155e-04\n",
      "Epoch 373/1000\n",
      " - 15s - loss: 3.6996e-04 - mean_squared_error: 3.6996e-04 - val_loss: 3.7776e-04 - val_mean_squared_error: 3.7776e-04\n",
      "Epoch 374/1000\n",
      " - 15s - loss: 3.6913e-04 - mean_squared_error: 3.6913e-04 - val_loss: 4.7808e-04 - val_mean_squared_error: 4.7808e-04\n",
      "Epoch 375/1000\n",
      " - 15s - loss: 3.6899e-04 - mean_squared_error: 3.6899e-04 - val_loss: 4.7372e-04 - val_mean_squared_error: 4.7372e-04\n",
      "Epoch 376/1000\n",
      " - 15s - loss: 3.6853e-04 - mean_squared_error: 3.6853e-04 - val_loss: 3.5098e-04 - val_mean_squared_error: 3.5098e-04\n",
      "Epoch 377/1000\n",
      " - 15s - loss: 3.6879e-04 - mean_squared_error: 3.6879e-04 - val_loss: 3.9235e-04 - val_mean_squared_error: 3.9235e-04\n",
      "Epoch 378/1000\n",
      " - 15s - loss: 3.6866e-04 - mean_squared_error: 3.6866e-04 - val_loss: 4.3933e-04 - val_mean_squared_error: 4.3933e-04\n",
      "Epoch 379/1000\n",
      " - 15s - loss: 3.6825e-04 - mean_squared_error: 3.6825e-04 - val_loss: 4.7363e-04 - val_mean_squared_error: 4.7363e-04\n",
      "Epoch 380/1000\n",
      " - 15s - loss: 3.6858e-04 - mean_squared_error: 3.6858e-04 - val_loss: 4.6476e-04 - val_mean_squared_error: 4.6476e-04\n",
      "Epoch 381/1000\n",
      " - 15s - loss: 3.6849e-04 - mean_squared_error: 3.6849e-04 - val_loss: 4.6615e-04 - val_mean_squared_error: 4.6615e-04\n",
      "Epoch 382/1000\n",
      " - 15s - loss: 3.6785e-04 - mean_squared_error: 3.6785e-04 - val_loss: 3.3141e-04 - val_mean_squared_error: 3.3141e-04\n",
      "Epoch 383/1000\n",
      " - 15s - loss: 3.6815e-04 - mean_squared_error: 3.6815e-04 - val_loss: 2.9312e-04 - val_mean_squared_error: 2.9312e-04\n",
      "Epoch 384/1000\n",
      " - 15s - loss: 3.6775e-04 - mean_squared_error: 3.6775e-04 - val_loss: 5.1198e-04 - val_mean_squared_error: 5.1198e-04\n",
      "Epoch 385/1000\n",
      " - 15s - loss: 3.6734e-04 - mean_squared_error: 3.6734e-04 - val_loss: 3.3362e-04 - val_mean_squared_error: 3.3362e-04\n",
      "Epoch 386/1000\n",
      " - 15s - loss: 3.6684e-04 - mean_squared_error: 3.6684e-04 - val_loss: 3.7250e-04 - val_mean_squared_error: 3.7250e-04\n",
      "Epoch 387/1000\n",
      " - 15s - loss: 3.6684e-04 - mean_squared_error: 3.6684e-04 - val_loss: 4.8676e-04 - val_mean_squared_error: 4.8676e-04\n",
      "Epoch 388/1000\n",
      " - 15s - loss: 3.6736e-04 - mean_squared_error: 3.6736e-04 - val_loss: 2.9390e-04 - val_mean_squared_error: 2.9390e-04\n",
      "Epoch 389/1000\n",
      " - 15s - loss: 3.6670e-04 - mean_squared_error: 3.6670e-04 - val_loss: 4.6686e-04 - val_mean_squared_error: 4.6686e-04\n",
      "Epoch 390/1000\n",
      " - 15s - loss: 3.6625e-04 - mean_squared_error: 3.6625e-04 - val_loss: 3.5157e-04 - val_mean_squared_error: 3.5157e-04\n",
      "Epoch 391/1000\n",
      " - 15s - loss: 3.6636e-04 - mean_squared_error: 3.6636e-04 - val_loss: 4.3443e-04 - val_mean_squared_error: 4.3443e-04\n",
      "Epoch 392/1000\n",
      " - 15s - loss: 3.6638e-04 - mean_squared_error: 3.6638e-04 - val_loss: 2.8844e-04 - val_mean_squared_error: 2.8844e-04\n",
      "Epoch 393/1000\n",
      " - 15s - loss: 3.6552e-04 - mean_squared_error: 3.6552e-04 - val_loss: 3.4630e-04 - val_mean_squared_error: 3.4630e-04\n",
      "Epoch 394/1000\n",
      " - 15s - loss: 3.6572e-04 - mean_squared_error: 3.6572e-04 - val_loss: 3.2268e-04 - val_mean_squared_error: 3.2268e-04\n",
      "Epoch 395/1000\n",
      " - 15s - loss: 3.6516e-04 - mean_squared_error: 3.6516e-04 - val_loss: 4.2740e-04 - val_mean_squared_error: 4.2740e-04\n",
      "Epoch 396/1000\n",
      " - 15s - loss: 3.6561e-04 - mean_squared_error: 3.6561e-04 - val_loss: 5.5768e-04 - val_mean_squared_error: 5.5768e-04\n",
      "Epoch 397/1000\n",
      " - 15s - loss: 3.6485e-04 - mean_squared_error: 3.6485e-04 - val_loss: 3.3409e-04 - val_mean_squared_error: 3.3409e-04\n",
      "Epoch 398/1000\n",
      " - 15s - loss: 3.6543e-04 - mean_squared_error: 3.6543e-04 - val_loss: 2.9441e-04 - val_mean_squared_error: 2.9441e-04\n",
      "Epoch 399/1000\n",
      " - 15s - loss: 3.6471e-04 - mean_squared_error: 3.6471e-04 - val_loss: 3.5308e-04 - val_mean_squared_error: 3.5308e-04\n",
      "Epoch 400/1000\n",
      " - 15s - loss: 3.6476e-04 - mean_squared_error: 3.6476e-04 - val_loss: 3.4843e-04 - val_mean_squared_error: 3.4843e-04\n",
      "Epoch 401/1000\n",
      " - 15s - loss: 3.6481e-04 - mean_squared_error: 3.6481e-04 - val_loss: 3.7642e-04 - val_mean_squared_error: 3.7642e-04\n",
      "Epoch 402/1000\n",
      " - 15s - loss: 3.6417e-04 - mean_squared_error: 3.6417e-04 - val_loss: 4.8158e-04 - val_mean_squared_error: 4.8158e-04\n",
      "Epoch 403/1000\n",
      " - 15s - loss: 3.6395e-04 - mean_squared_error: 3.6395e-04 - val_loss: 5.0320e-04 - val_mean_squared_error: 5.0320e-04\n",
      "Epoch 404/1000\n",
      " - 15s - loss: 3.6386e-04 - mean_squared_error: 3.6386e-04 - val_loss: 3.5024e-04 - val_mean_squared_error: 3.5024e-04\n",
      "Epoch 405/1000\n",
      " - 15s - loss: 3.6409e-04 - mean_squared_error: 3.6409e-04 - val_loss: 3.2123e-04 - val_mean_squared_error: 3.2123e-04\n",
      "Epoch 406/1000\n",
      " - 15s - loss: 3.6344e-04 - mean_squared_error: 3.6344e-04 - val_loss: 4.1270e-04 - val_mean_squared_error: 4.1270e-04\n",
      "Epoch 407/1000\n",
      " - 15s - loss: 3.6340e-04 - mean_squared_error: 3.6340e-04 - val_loss: 3.1072e-04 - val_mean_squared_error: 3.1072e-04\n",
      "Epoch 408/1000\n",
      " - 15s - loss: 3.6341e-04 - mean_squared_error: 3.6341e-04 - val_loss: 5.0221e-04 - val_mean_squared_error: 5.0221e-04\n",
      "Epoch 409/1000\n",
      " - 15s - loss: 3.6302e-04 - mean_squared_error: 3.6302e-04 - val_loss: 3.2961e-04 - val_mean_squared_error: 3.2961e-04\n",
      "Epoch 410/1000\n",
      " - 15s - loss: 3.6339e-04 - mean_squared_error: 3.6339e-04 - val_loss: 3.6032e-04 - val_mean_squared_error: 3.6032e-04\n",
      "Epoch 411/1000\n",
      " - 15s - loss: 3.6293e-04 - mean_squared_error: 3.6293e-04 - val_loss: 4.0886e-04 - val_mean_squared_error: 4.0886e-04\n",
      "Epoch 412/1000\n",
      " - 15s - loss: 3.6236e-04 - mean_squared_error: 3.6236e-04 - val_loss: 3.0671e-04 - val_mean_squared_error: 3.0671e-04\n",
      "Epoch 413/1000\n",
      " - 15s - loss: 3.6235e-04 - mean_squared_error: 3.6235e-04 - val_loss: 3.1791e-04 - val_mean_squared_error: 3.1791e-04\n",
      "Epoch 414/1000\n",
      " - 15s - loss: 3.6206e-04 - mean_squared_error: 3.6206e-04 - val_loss: 5.6477e-04 - val_mean_squared_error: 5.6477e-04\n",
      "Epoch 415/1000\n",
      " - 15s - loss: 3.6242e-04 - mean_squared_error: 3.6242e-04 - val_loss: 5.4420e-04 - val_mean_squared_error: 5.4420e-04\n",
      "Epoch 416/1000\n",
      " - 15s - loss: 3.6198e-04 - mean_squared_error: 3.6198e-04 - val_loss: 3.2365e-04 - val_mean_squared_error: 3.2365e-04\n",
      "Epoch 417/1000\n",
      " - 15s - loss: 3.6155e-04 - mean_squared_error: 3.6155e-04 - val_loss: 3.0457e-04 - val_mean_squared_error: 3.0457e-04\n",
      "Epoch 418/1000\n",
      " - 15s - loss: 3.6171e-04 - mean_squared_error: 3.6171e-04 - val_loss: 4.5621e-04 - val_mean_squared_error: 4.5621e-04\n",
      "Epoch 419/1000\n",
      " - 15s - loss: 3.6215e-04 - mean_squared_error: 3.6215e-04 - val_loss: 3.3171e-04 - val_mean_squared_error: 3.3171e-04\n",
      "Epoch 420/1000\n",
      " - 15s - loss: 3.6105e-04 - mean_squared_error: 3.6105e-04 - val_loss: 4.3837e-04 - val_mean_squared_error: 4.3837e-04\n",
      "Epoch 421/1000\n",
      " - 15s - loss: 3.6148e-04 - mean_squared_error: 3.6148e-04 - val_loss: 3.9882e-04 - val_mean_squared_error: 3.9882e-04\n",
      "Epoch 422/1000\n",
      " - 15s - loss: 3.6083e-04 - mean_squared_error: 3.6083e-04 - val_loss: 3.7512e-04 - val_mean_squared_error: 3.7512e-04\n",
      "Epoch 423/1000\n",
      " - 15s - loss: 3.6140e-04 - mean_squared_error: 3.6140e-04 - val_loss: 3.3350e-04 - val_mean_squared_error: 3.3350e-04\n",
      "Epoch 424/1000\n",
      " - 15s - loss: 3.6090e-04 - mean_squared_error: 3.6090e-04 - val_loss: 3.3993e-04 - val_mean_squared_error: 3.3993e-04\n",
      "Epoch 425/1000\n",
      " - 15s - loss: 3.6101e-04 - mean_squared_error: 3.6101e-04 - val_loss: 4.1713e-04 - val_mean_squared_error: 4.1713e-04\n",
      "Epoch 426/1000\n",
      " - 15s - loss: 3.6039e-04 - mean_squared_error: 3.6039e-04 - val_loss: 4.9919e-04 - val_mean_squared_error: 4.9919e-04\n",
      "Epoch 427/1000\n",
      " - 15s - loss: 3.6053e-04 - mean_squared_error: 3.6053e-04 - val_loss: 4.5023e-04 - val_mean_squared_error: 4.5023e-04\n",
      "Epoch 428/1000\n",
      " - 15s - loss: 3.6032e-04 - mean_squared_error: 3.6032e-04 - val_loss: 4.2045e-04 - val_mean_squared_error: 4.2045e-04\n",
      "Epoch 429/1000\n",
      " - 15s - loss: 3.5926e-04 - mean_squared_error: 3.5926e-04 - val_loss: 3.5706e-04 - val_mean_squared_error: 3.5706e-04\n",
      "Epoch 430/1000\n",
      " - 15s - loss: 3.5954e-04 - mean_squared_error: 3.5954e-04 - val_loss: 4.9862e-04 - val_mean_squared_error: 4.9862e-04\n",
      "Epoch 431/1000\n",
      " - 15s - loss: 3.5959e-04 - mean_squared_error: 3.5959e-04 - val_loss: 2.9786e-04 - val_mean_squared_error: 2.9786e-04\n",
      "Epoch 432/1000\n",
      " - 15s - loss: 3.5909e-04 - mean_squared_error: 3.5909e-04 - val_loss: 3.3597e-04 - val_mean_squared_error: 3.3597e-04\n",
      "Epoch 433/1000\n",
      " - 15s - loss: 3.5934e-04 - mean_squared_error: 3.5934e-04 - val_loss: 5.0751e-04 - val_mean_squared_error: 5.0751e-04\n",
      "Epoch 434/1000\n",
      " - 15s - loss: 3.5924e-04 - mean_squared_error: 3.5924e-04 - val_loss: 3.8836e-04 - val_mean_squared_error: 3.8836e-04\n",
      "Epoch 435/1000\n",
      " - 15s - loss: 3.5926e-04 - mean_squared_error: 3.5926e-04 - val_loss: 4.2040e-04 - val_mean_squared_error: 4.2040e-04\n",
      "Epoch 436/1000\n",
      " - 15s - loss: 3.5887e-04 - mean_squared_error: 3.5887e-04 - val_loss: 3.9686e-04 - val_mean_squared_error: 3.9686e-04\n",
      "Epoch 437/1000\n",
      " - 15s - loss: 3.5897e-04 - mean_squared_error: 3.5897e-04 - val_loss: 3.9322e-04 - val_mean_squared_error: 3.9322e-04\n",
      "Epoch 438/1000\n",
      " - 15s - loss: 3.5917e-04 - mean_squared_error: 3.5917e-04 - val_loss: 3.3097e-04 - val_mean_squared_error: 3.3097e-04\n",
      "Epoch 439/1000\n",
      " - 15s - loss: 3.5838e-04 - mean_squared_error: 3.5838e-04 - val_loss: 5.6703e-04 - val_mean_squared_error: 5.6703e-04\n",
      "Epoch 440/1000\n",
      " - 15s - loss: 3.5846e-04 - mean_squared_error: 3.5846e-04 - val_loss: 2.9365e-04 - val_mean_squared_error: 2.9365e-04\n",
      "Epoch 441/1000\n",
      " - 15s - loss: 3.5839e-04 - mean_squared_error: 3.5839e-04 - val_loss: 4.4183e-04 - val_mean_squared_error: 4.4183e-04\n",
      "Epoch 442/1000\n",
      " - 15s - loss: 3.5820e-04 - mean_squared_error: 3.5820e-04 - val_loss: 3.9284e-04 - val_mean_squared_error: 3.9284e-04\n",
      "Epoch 443/1000\n",
      " - 15s - loss: 3.5805e-04 - mean_squared_error: 3.5805e-04 - val_loss: 3.2654e-04 - val_mean_squared_error: 3.2654e-04\n",
      "Epoch 444/1000\n",
      " - 15s - loss: 3.5744e-04 - mean_squared_error: 3.5744e-04 - val_loss: 2.7479e-04 - val_mean_squared_error: 2.7479e-04\n",
      "Epoch 445/1000\n",
      " - 15s - loss: 3.5779e-04 - mean_squared_error: 3.5779e-04 - val_loss: 4.8518e-04 - val_mean_squared_error: 4.8518e-04\n",
      "Epoch 446/1000\n",
      " - 15s - loss: 3.5767e-04 - mean_squared_error: 3.5767e-04 - val_loss: 2.7244e-04 - val_mean_squared_error: 2.7244e-04\n",
      "Epoch 447/1000\n",
      " - 15s - loss: 3.5736e-04 - mean_squared_error: 3.5736e-04 - val_loss: 3.7823e-04 - val_mean_squared_error: 3.7823e-04\n",
      "Epoch 448/1000\n",
      " - 15s - loss: 3.5748e-04 - mean_squared_error: 3.5748e-04 - val_loss: 4.6109e-04 - val_mean_squared_error: 4.6109e-04\n",
      "Epoch 449/1000\n",
      " - 15s - loss: 3.5749e-04 - mean_squared_error: 3.5749e-04 - val_loss: 3.0771e-04 - val_mean_squared_error: 3.0771e-04\n",
      "Epoch 450/1000\n",
      " - 15s - loss: 3.5698e-04 - mean_squared_error: 3.5698e-04 - val_loss: 6.6569e-04 - val_mean_squared_error: 6.6569e-04\n",
      "Epoch 451/1000\n",
      " - 15s - loss: 3.5694e-04 - mean_squared_error: 3.5694e-04 - val_loss: 2.9526e-04 - val_mean_squared_error: 2.9526e-04\n",
      "Epoch 452/1000\n",
      " - 15s - loss: 3.5629e-04 - mean_squared_error: 3.5629e-04 - val_loss: 3.7154e-04 - val_mean_squared_error: 3.7154e-04\n",
      "Epoch 453/1000\n",
      " - 15s - loss: 3.5638e-04 - mean_squared_error: 3.5638e-04 - val_loss: 3.5918e-04 - val_mean_squared_error: 3.5918e-04\n",
      "Epoch 454/1000\n",
      " - 15s - loss: 3.5596e-04 - mean_squared_error: 3.5596e-04 - val_loss: 2.9570e-04 - val_mean_squared_error: 2.9570e-04\n",
      "Epoch 455/1000\n",
      " - 15s - loss: 3.5574e-04 - mean_squared_error: 3.5574e-04 - val_loss: 3.4274e-04 - val_mean_squared_error: 3.4274e-04\n",
      "Epoch 456/1000\n",
      " - 15s - loss: 3.5646e-04 - mean_squared_error: 3.5646e-04 - val_loss: 3.6681e-04 - val_mean_squared_error: 3.6681e-04\n",
      "Epoch 457/1000\n",
      " - 15s - loss: 3.5559e-04 - mean_squared_error: 3.5559e-04 - val_loss: 4.2339e-04 - val_mean_squared_error: 4.2339e-04\n",
      "Epoch 458/1000\n",
      " - 15s - loss: 3.5572e-04 - mean_squared_error: 3.5572e-04 - val_loss: 3.3600e-04 - val_mean_squared_error: 3.3600e-04\n",
      "Epoch 459/1000\n",
      " - 15s - loss: 3.5564e-04 - mean_squared_error: 3.5564e-04 - val_loss: 3.3522e-04 - val_mean_squared_error: 3.3522e-04\n",
      "Epoch 460/1000\n",
      " - 15s - loss: 3.5524e-04 - mean_squared_error: 3.5524e-04 - val_loss: 3.7012e-04 - val_mean_squared_error: 3.7012e-04\n",
      "Epoch 461/1000\n",
      " - 15s - loss: 3.5547e-04 - mean_squared_error: 3.5547e-04 - val_loss: 3.0553e-04 - val_mean_squared_error: 3.0553e-04\n",
      "Epoch 462/1000\n",
      " - 15s - loss: 3.5546e-04 - mean_squared_error: 3.5546e-04 - val_loss: 3.4851e-04 - val_mean_squared_error: 3.4851e-04\n",
      "Epoch 463/1000\n",
      " - 15s - loss: 3.5504e-04 - mean_squared_error: 3.5504e-04 - val_loss: 3.8572e-04 - val_mean_squared_error: 3.8572e-04\n",
      "Epoch 464/1000\n",
      " - 15s - loss: 3.5506e-04 - mean_squared_error: 3.5506e-04 - val_loss: 4.4093e-04 - val_mean_squared_error: 4.4093e-04\n",
      "Epoch 465/1000\n",
      " - 15s - loss: 3.5517e-04 - mean_squared_error: 3.5517e-04 - val_loss: 3.2451e-04 - val_mean_squared_error: 3.2451e-04\n",
      "Epoch 466/1000\n",
      " - 15s - loss: 3.5494e-04 - mean_squared_error: 3.5494e-04 - val_loss: 3.8354e-04 - val_mean_squared_error: 3.8354e-04\n",
      "Epoch 467/1000\n",
      " - 15s - loss: 3.5425e-04 - mean_squared_error: 3.5425e-04 - val_loss: 3.3613e-04 - val_mean_squared_error: 3.3613e-04\n",
      "Epoch 468/1000\n",
      " - 15s - loss: 3.5497e-04 - mean_squared_error: 3.5497e-04 - val_loss: 2.9288e-04 - val_mean_squared_error: 2.9288e-04\n",
      "Epoch 469/1000\n",
      " - 15s - loss: 3.5433e-04 - mean_squared_error: 3.5433e-04 - val_loss: 3.9103e-04 - val_mean_squared_error: 3.9103e-04\n",
      "Epoch 470/1000\n",
      " - 15s - loss: 3.5391e-04 - mean_squared_error: 3.5391e-04 - val_loss: 3.3984e-04 - val_mean_squared_error: 3.3984e-04\n",
      "Epoch 471/1000\n",
      " - 15s - loss: 3.5413e-04 - mean_squared_error: 3.5413e-04 - val_loss: 4.0354e-04 - val_mean_squared_error: 4.0354e-04\n",
      "Epoch 472/1000\n",
      " - 15s - loss: 3.5411e-04 - mean_squared_error: 3.5411e-04 - val_loss: 3.6427e-04 - val_mean_squared_error: 3.6427e-04\n",
      "Epoch 473/1000\n",
      " - 15s - loss: 3.5357e-04 - mean_squared_error: 3.5357e-04 - val_loss: 5.5972e-04 - val_mean_squared_error: 5.5972e-04\n",
      "Epoch 474/1000\n",
      " - 15s - loss: 3.5392e-04 - mean_squared_error: 3.5392e-04 - val_loss: 3.4067e-04 - val_mean_squared_error: 3.4067e-04\n",
      "Epoch 475/1000\n",
      " - 15s - loss: 3.5394e-04 - mean_squared_error: 3.5394e-04 - val_loss: 2.9560e-04 - val_mean_squared_error: 2.9560e-04\n",
      "Epoch 476/1000\n",
      " - 15s - loss: 3.5361e-04 - mean_squared_error: 3.5361e-04 - val_loss: 2.6666e-04 - val_mean_squared_error: 2.6666e-04\n",
      "Epoch 477/1000\n",
      " - 15s - loss: 3.5341e-04 - mean_squared_error: 3.5341e-04 - val_loss: 4.2515e-04 - val_mean_squared_error: 4.2515e-04\n",
      "Epoch 478/1000\n",
      " - 15s - loss: 3.5310e-04 - mean_squared_error: 3.5310e-04 - val_loss: 3.8333e-04 - val_mean_squared_error: 3.8333e-04\n",
      "Epoch 479/1000\n",
      " - 15s - loss: 3.5350e-04 - mean_squared_error: 3.5350e-04 - val_loss: 2.8845e-04 - val_mean_squared_error: 2.8845e-04\n",
      "Epoch 480/1000\n",
      " - 15s - loss: 3.5270e-04 - mean_squared_error: 3.5270e-04 - val_loss: 3.5079e-04 - val_mean_squared_error: 3.5079e-04\n",
      "Epoch 481/1000\n",
      " - 15s - loss: 3.5238e-04 - mean_squared_error: 3.5238e-04 - val_loss: 2.6436e-04 - val_mean_squared_error: 2.6436e-04\n",
      "Epoch 482/1000\n",
      " - 15s - loss: 3.5242e-04 - mean_squared_error: 3.5242e-04 - val_loss: 5.9025e-04 - val_mean_squared_error: 5.9025e-04\n",
      "Epoch 483/1000\n",
      " - 15s - loss: 3.5286e-04 - mean_squared_error: 3.5286e-04 - val_loss: 4.0004e-04 - val_mean_squared_error: 4.0004e-04\n",
      "Epoch 484/1000\n",
      " - 15s - loss: 3.5235e-04 - mean_squared_error: 3.5235e-04 - val_loss: 3.6071e-04 - val_mean_squared_error: 3.6071e-04\n",
      "Epoch 485/1000\n",
      " - 15s - loss: 3.5246e-04 - mean_squared_error: 3.5246e-04 - val_loss: 2.8485e-04 - val_mean_squared_error: 2.8485e-04\n",
      "Epoch 486/1000\n",
      " - 15s - loss: 3.5209e-04 - mean_squared_error: 3.5209e-04 - val_loss: 3.8986e-04 - val_mean_squared_error: 3.8986e-04\n",
      "Epoch 487/1000\n",
      " - 15s - loss: 3.5242e-04 - mean_squared_error: 3.5242e-04 - val_loss: 2.5215e-04 - val_mean_squared_error: 2.5215e-04\n",
      "Epoch 488/1000\n",
      " - 15s - loss: 3.5151e-04 - mean_squared_error: 3.5151e-04 - val_loss: 3.2076e-04 - val_mean_squared_error: 3.2076e-04\n",
      "Epoch 489/1000\n",
      " - 15s - loss: 3.5171e-04 - mean_squared_error: 3.5171e-04 - val_loss: 4.1042e-04 - val_mean_squared_error: 4.1042e-04\n",
      "Epoch 490/1000\n",
      " - 15s - loss: 3.5146e-04 - mean_squared_error: 3.5146e-04 - val_loss: 3.3920e-04 - val_mean_squared_error: 3.3920e-04\n",
      "Epoch 491/1000\n",
      " - 15s - loss: 3.5149e-04 - mean_squared_error: 3.5149e-04 - val_loss: 3.5932e-04 - val_mean_squared_error: 3.5932e-04\n",
      "Epoch 492/1000\n",
      " - 15s - loss: 3.5167e-04 - mean_squared_error: 3.5167e-04 - val_loss: 3.5071e-04 - val_mean_squared_error: 3.5071e-04\n",
      "Epoch 493/1000\n",
      " - 15s - loss: 3.5150e-04 - mean_squared_error: 3.5150e-04 - val_loss: 6.1649e-04 - val_mean_squared_error: 6.1649e-04\n",
      "Epoch 494/1000\n",
      " - 15s - loss: 3.5133e-04 - mean_squared_error: 3.5133e-04 - val_loss: 3.5669e-04 - val_mean_squared_error: 3.5669e-04\n",
      "Epoch 495/1000\n",
      " - 15s - loss: 3.5120e-04 - mean_squared_error: 3.5120e-04 - val_loss: 3.8405e-04 - val_mean_squared_error: 3.8405e-04\n",
      "Epoch 496/1000\n",
      " - 15s - loss: 3.5113e-04 - mean_squared_error: 3.5113e-04 - val_loss: 3.8214e-04 - val_mean_squared_error: 3.8214e-04\n",
      "Epoch 497/1000\n",
      " - 15s - loss: 3.5113e-04 - mean_squared_error: 3.5113e-04 - val_loss: 3.0293e-04 - val_mean_squared_error: 3.0293e-04\n",
      "Epoch 498/1000\n",
      " - 15s - loss: 3.5072e-04 - mean_squared_error: 3.5072e-04 - val_loss: 3.2309e-04 - val_mean_squared_error: 3.2309e-04\n",
      "Epoch 499/1000\n",
      " - 15s - loss: 3.5037e-04 - mean_squared_error: 3.5037e-04 - val_loss: 5.4829e-04 - val_mean_squared_error: 5.4829e-04\n",
      "Epoch 500/1000\n",
      " - 15s - loss: 3.5043e-04 - mean_squared_error: 3.5043e-04 - val_loss: 3.8096e-04 - val_mean_squared_error: 3.8096e-04\n",
      "Epoch 501/1000\n",
      " - 15s - loss: 3.5039e-04 - mean_squared_error: 3.5039e-04 - val_loss: 3.0341e-04 - val_mean_squared_error: 3.0341e-04\n",
      "Epoch 502/1000\n",
      " - 15s - loss: 3.5022e-04 - mean_squared_error: 3.5022e-04 - val_loss: 3.7947e-04 - val_mean_squared_error: 3.7947e-04\n",
      "Epoch 503/1000\n",
      " - 15s - loss: 3.5014e-04 - mean_squared_error: 3.5014e-04 - val_loss: 4.4823e-04 - val_mean_squared_error: 4.4823e-04\n",
      "Epoch 504/1000\n",
      " - 15s - loss: 3.4972e-04 - mean_squared_error: 3.4972e-04 - val_loss: 4.0498e-04 - val_mean_squared_error: 4.0498e-04\n",
      "Epoch 505/1000\n",
      " - 15s - loss: 3.4986e-04 - mean_squared_error: 3.4986e-04 - val_loss: 3.5722e-04 - val_mean_squared_error: 3.5722e-04\n",
      "Epoch 506/1000\n",
      " - 15s - loss: 3.4991e-04 - mean_squared_error: 3.4991e-04 - val_loss: 3.1553e-04 - val_mean_squared_error: 3.1553e-04\n",
      "Epoch 507/1000\n",
      " - 15s - loss: 3.4943e-04 - mean_squared_error: 3.4943e-04 - val_loss: 3.5156e-04 - val_mean_squared_error: 3.5156e-04\n",
      "Epoch 508/1000\n",
      " - 15s - loss: 3.4932e-04 - mean_squared_error: 3.4932e-04 - val_loss: 3.8955e-04 - val_mean_squared_error: 3.8955e-04\n",
      "Epoch 509/1000\n",
      " - 15s - loss: 3.4960e-04 - mean_squared_error: 3.4960e-04 - val_loss: 5.0809e-04 - val_mean_squared_error: 5.0809e-04\n",
      "Epoch 510/1000\n",
      " - 15s - loss: 3.4893e-04 - mean_squared_error: 3.4893e-04 - val_loss: 2.7897e-04 - val_mean_squared_error: 2.7897e-04\n",
      "Epoch 511/1000\n",
      " - 15s - loss: 3.4929e-04 - mean_squared_error: 3.4929e-04 - val_loss: 3.5404e-04 - val_mean_squared_error: 3.5404e-04\n",
      "Epoch 512/1000\n",
      " - 15s - loss: 3.4925e-04 - mean_squared_error: 3.4925e-04 - val_loss: 3.5499e-04 - val_mean_squared_error: 3.5499e-04\n",
      "Epoch 513/1000\n",
      " - 15s - loss: 3.4867e-04 - mean_squared_error: 3.4867e-04 - val_loss: 3.0287e-04 - val_mean_squared_error: 3.0287e-04\n",
      "Epoch 514/1000\n",
      " - 15s - loss: 3.4901e-04 - mean_squared_error: 3.4901e-04 - val_loss: 3.5143e-04 - val_mean_squared_error: 3.5143e-04\n",
      "Epoch 515/1000\n",
      " - 15s - loss: 3.4845e-04 - mean_squared_error: 3.4845e-04 - val_loss: 3.6564e-04 - val_mean_squared_error: 3.6564e-04\n",
      "Epoch 516/1000\n",
      " - 15s - loss: 3.4864e-04 - mean_squared_error: 3.4864e-04 - val_loss: 5.5469e-04 - val_mean_squared_error: 5.5469e-04\n",
      "Epoch 517/1000\n",
      " - 15s - loss: 3.4901e-04 - mean_squared_error: 3.4901e-04 - val_loss: 2.8380e-04 - val_mean_squared_error: 2.8380e-04\n",
      "Epoch 518/1000\n",
      " - 15s - loss: 3.4797e-04 - mean_squared_error: 3.4797e-04 - val_loss: 4.6971e-04 - val_mean_squared_error: 4.6971e-04\n",
      "Epoch 519/1000\n",
      " - 15s - loss: 3.4808e-04 - mean_squared_error: 3.4808e-04 - val_loss: 2.6117e-04 - val_mean_squared_error: 2.6117e-04\n",
      "Epoch 520/1000\n",
      " - 15s - loss: 3.4875e-04 - mean_squared_error: 3.4875e-04 - val_loss: 2.4672e-04 - val_mean_squared_error: 2.4672e-04\n",
      "Epoch 521/1000\n",
      " - 15s - loss: 3.4803e-04 - mean_squared_error: 3.4803e-04 - val_loss: 3.3627e-04 - val_mean_squared_error: 3.3627e-04\n",
      "Epoch 522/1000\n",
      " - 15s - loss: 3.4803e-04 - mean_squared_error: 3.4803e-04 - val_loss: 3.6009e-04 - val_mean_squared_error: 3.6009e-04\n",
      "Epoch 523/1000\n",
      " - 15s - loss: 3.4739e-04 - mean_squared_error: 3.4739e-04 - val_loss: 3.2894e-04 - val_mean_squared_error: 3.2894e-04\n",
      "Epoch 524/1000\n",
      " - 15s - loss: 3.4829e-04 - mean_squared_error: 3.4829e-04 - val_loss: 3.0614e-04 - val_mean_squared_error: 3.0614e-04\n",
      "Epoch 525/1000\n",
      " - 15s - loss: 3.4745e-04 - mean_squared_error: 3.4745e-04 - val_loss: 3.1878e-04 - val_mean_squared_error: 3.1878e-04\n",
      "Epoch 526/1000\n",
      " - 15s - loss: 3.4725e-04 - mean_squared_error: 3.4725e-04 - val_loss: 4.7762e-04 - val_mean_squared_error: 4.7762e-04\n",
      "Epoch 527/1000\n",
      " - 15s - loss: 3.4735e-04 - mean_squared_error: 3.4735e-04 - val_loss: 2.6961e-04 - val_mean_squared_error: 2.6961e-04\n",
      "Epoch 528/1000\n",
      " - 15s - loss: 3.4724e-04 - mean_squared_error: 3.4724e-04 - val_loss: 4.8685e-04 - val_mean_squared_error: 4.8685e-04\n",
      "Epoch 529/1000\n",
      " - 15s - loss: 3.4733e-04 - mean_squared_error: 3.4733e-04 - val_loss: 3.4131e-04 - val_mean_squared_error: 3.4131e-04\n",
      "Epoch 530/1000\n",
      " - 15s - loss: 3.4702e-04 - mean_squared_error: 3.4702e-04 - val_loss: 2.7634e-04 - val_mean_squared_error: 2.7634e-04\n",
      "Epoch 531/1000\n",
      " - 15s - loss: 3.4654e-04 - mean_squared_error: 3.4654e-04 - val_loss: 3.5438e-04 - val_mean_squared_error: 3.5438e-04\n",
      "Epoch 532/1000\n",
      " - 15s - loss: 3.4683e-04 - mean_squared_error: 3.4683e-04 - val_loss: 3.3716e-04 - val_mean_squared_error: 3.3716e-04\n",
      "Epoch 533/1000\n",
      " - 15s - loss: 3.4679e-04 - mean_squared_error: 3.4679e-04 - val_loss: 3.7893e-04 - val_mean_squared_error: 3.7893e-04\n",
      "Epoch 534/1000\n",
      " - 15s - loss: 3.4681e-04 - mean_squared_error: 3.4681e-04 - val_loss: 4.0630e-04 - val_mean_squared_error: 4.0630e-04\n",
      "Epoch 535/1000\n",
      " - 15s - loss: 3.4573e-04 - mean_squared_error: 3.4573e-04 - val_loss: 3.3030e-04 - val_mean_squared_error: 3.3030e-04\n",
      "Epoch 536/1000\n",
      " - 15s - loss: 3.4684e-04 - mean_squared_error: 3.4684e-04 - val_loss: 3.0393e-04 - val_mean_squared_error: 3.0393e-04\n",
      "Epoch 537/1000\n",
      " - 15s - loss: 3.4592e-04 - mean_squared_error: 3.4592e-04 - val_loss: 4.1269e-04 - val_mean_squared_error: 4.1269e-04\n",
      "Epoch 538/1000\n",
      " - 15s - loss: 3.4609e-04 - mean_squared_error: 3.4609e-04 - val_loss: 3.9159e-04 - val_mean_squared_error: 3.9159e-04\n",
      "Epoch 539/1000\n",
      " - 15s - loss: 3.4571e-04 - mean_squared_error: 3.4571e-04 - val_loss: 3.0569e-04 - val_mean_squared_error: 3.0569e-04\n",
      "Epoch 540/1000\n",
      " - 15s - loss: 3.4537e-04 - mean_squared_error: 3.4537e-04 - val_loss: 3.5611e-04 - val_mean_squared_error: 3.5611e-04\n",
      "Epoch 541/1000\n",
      " - 15s - loss: 3.4584e-04 - mean_squared_error: 3.4584e-04 - val_loss: 4.4970e-04 - val_mean_squared_error: 4.4970e-04\n",
      "Epoch 542/1000\n",
      " - 15s - loss: 3.4556e-04 - mean_squared_error: 3.4556e-04 - val_loss: 3.5202e-04 - val_mean_squared_error: 3.5202e-04\n",
      "Epoch 543/1000\n",
      " - 15s - loss: 3.4549e-04 - mean_squared_error: 3.4549e-04 - val_loss: 3.1197e-04 - val_mean_squared_error: 3.1197e-04\n",
      "Epoch 544/1000\n",
      " - 15s - loss: 3.4519e-04 - mean_squared_error: 3.4519e-04 - val_loss: 4.5441e-04 - val_mean_squared_error: 4.5441e-04\n",
      "Epoch 545/1000\n",
      " - 15s - loss: 3.4572e-04 - mean_squared_error: 3.4572e-04 - val_loss: 4.7089e-04 - val_mean_squared_error: 4.7089e-04\n",
      "Epoch 546/1000\n",
      " - 15s - loss: 3.4503e-04 - mean_squared_error: 3.4503e-04 - val_loss: 3.8331e-04 - val_mean_squared_error: 3.8331e-04\n",
      "Epoch 547/1000\n",
      " - 15s - loss: 3.4554e-04 - mean_squared_error: 3.4554e-04 - val_loss: 4.0960e-04 - val_mean_squared_error: 4.0960e-04\n",
      "Epoch 548/1000\n",
      " - 15s - loss: 3.4489e-04 - mean_squared_error: 3.4489e-04 - val_loss: 3.7373e-04 - val_mean_squared_error: 3.7373e-04\n",
      "Epoch 549/1000\n",
      " - 15s - loss: 3.4457e-04 - mean_squared_error: 3.4457e-04 - val_loss: 2.9234e-04 - val_mean_squared_error: 2.9234e-04\n",
      "Epoch 550/1000\n",
      " - 15s - loss: 3.4499e-04 - mean_squared_error: 3.4499e-04 - val_loss: 3.4425e-04 - val_mean_squared_error: 3.4425e-04\n",
      "Epoch 551/1000\n",
      " - 15s - loss: 3.4465e-04 - mean_squared_error: 3.4465e-04 - val_loss: 4.2586e-04 - val_mean_squared_error: 4.2586e-04\n",
      "Epoch 552/1000\n",
      " - 15s - loss: 3.4436e-04 - mean_squared_error: 3.4436e-04 - val_loss: 2.7829e-04 - val_mean_squared_error: 2.7829e-04\n",
      "Epoch 553/1000\n",
      " - 15s - loss: 3.4481e-04 - mean_squared_error: 3.4481e-04 - val_loss: 2.5534e-04 - val_mean_squared_error: 2.5534e-04\n",
      "Epoch 554/1000\n",
      " - 15s - loss: 3.4440e-04 - mean_squared_error: 3.4440e-04 - val_loss: 3.2710e-04 - val_mean_squared_error: 3.2710e-04\n",
      "Epoch 555/1000\n",
      " - 15s - loss: 3.4442e-04 - mean_squared_error: 3.4442e-04 - val_loss: 3.1618e-04 - val_mean_squared_error: 3.1618e-04\n",
      "Epoch 556/1000\n",
      " - 15s - loss: 3.4408e-04 - mean_squared_error: 3.4408e-04 - val_loss: 3.7497e-04 - val_mean_squared_error: 3.7497e-04\n",
      "Epoch 557/1000\n",
      " - 15s - loss: 3.4391e-04 - mean_squared_error: 3.4391e-04 - val_loss: 4.4753e-04 - val_mean_squared_error: 4.4753e-04\n",
      "Epoch 558/1000\n",
      " - 15s - loss: 3.4473e-04 - mean_squared_error: 3.4473e-04 - val_loss: 2.9766e-04 - val_mean_squared_error: 2.9766e-04\n",
      "Epoch 559/1000\n",
      " - 15s - loss: 3.4333e-04 - mean_squared_error: 3.4333e-04 - val_loss: 4.5607e-04 - val_mean_squared_error: 4.5607e-04\n",
      "Epoch 560/1000\n",
      " - 15s - loss: 3.4386e-04 - mean_squared_error: 3.4386e-04 - val_loss: 3.2944e-04 - val_mean_squared_error: 3.2944e-04\n",
      "Epoch 561/1000\n",
      " - 15s - loss: 3.4345e-04 - mean_squared_error: 3.4345e-04 - val_loss: 4.5792e-04 - val_mean_squared_error: 4.5792e-04\n",
      "Epoch 562/1000\n",
      " - 15s - loss: 3.4365e-04 - mean_squared_error: 3.4365e-04 - val_loss: 2.7542e-04 - val_mean_squared_error: 2.7542e-04\n",
      "Epoch 563/1000\n",
      " - 15s - loss: 3.4344e-04 - mean_squared_error: 3.4344e-04 - val_loss: 3.7441e-04 - val_mean_squared_error: 3.7441e-04\n",
      "Epoch 564/1000\n",
      " - 15s - loss: 3.4359e-04 - mean_squared_error: 3.4359e-04 - val_loss: 3.2196e-04 - val_mean_squared_error: 3.2196e-04\n",
      "Epoch 565/1000\n",
      " - 15s - loss: 3.4321e-04 - mean_squared_error: 3.4321e-04 - val_loss: 3.9122e-04 - val_mean_squared_error: 3.9122e-04\n",
      "Epoch 566/1000\n",
      " - 15s - loss: 3.4301e-04 - mean_squared_error: 3.4301e-04 - val_loss: 3.7127e-04 - val_mean_squared_error: 3.7127e-04\n",
      "Epoch 567/1000\n",
      " - 15s - loss: 3.4319e-04 - mean_squared_error: 3.4319e-04 - val_loss: 3.1529e-04 - val_mean_squared_error: 3.1529e-04\n",
      "Epoch 568/1000\n",
      " - 15s - loss: 3.4301e-04 - mean_squared_error: 3.4301e-04 - val_loss: 3.0154e-04 - val_mean_squared_error: 3.0154e-04\n",
      "Epoch 569/1000\n",
      " - 15s - loss: 3.4308e-04 - mean_squared_error: 3.4308e-04 - val_loss: 3.5378e-04 - val_mean_squared_error: 3.5378e-04\n",
      "Epoch 570/1000\n",
      " - 15s - loss: 3.4280e-04 - mean_squared_error: 3.4280e-04 - val_loss: 2.8922e-04 - val_mean_squared_error: 2.8922e-04\n",
      "Epoch 571/1000\n",
      " - 15s - loss: 3.4280e-04 - mean_squared_error: 3.4280e-04 - val_loss: 4.2338e-04 - val_mean_squared_error: 4.2338e-04\n",
      "Epoch 572/1000\n",
      " - 15s - loss: 3.4269e-04 - mean_squared_error: 3.4269e-04 - val_loss: 4.0763e-04 - val_mean_squared_error: 4.0763e-04\n",
      "Epoch 573/1000\n",
      " - 15s - loss: 3.4241e-04 - mean_squared_error: 3.4241e-04 - val_loss: 4.1239e-04 - val_mean_squared_error: 4.1239e-04\n",
      "Epoch 574/1000\n",
      " - 15s - loss: 3.4233e-04 - mean_squared_error: 3.4233e-04 - val_loss: 3.3812e-04 - val_mean_squared_error: 3.3812e-04\n",
      "Epoch 575/1000\n",
      " - 15s - loss: 3.4233e-04 - mean_squared_error: 3.4233e-04 - val_loss: 2.9848e-04 - val_mean_squared_error: 2.9848e-04\n",
      "Epoch 576/1000\n",
      " - 15s - loss: 3.4231e-04 - mean_squared_error: 3.4231e-04 - val_loss: 2.9533e-04 - val_mean_squared_error: 2.9533e-04\n",
      "Epoch 577/1000\n",
      " - 15s - loss: 3.4187e-04 - mean_squared_error: 3.4187e-04 - val_loss: 4.1462e-04 - val_mean_squared_error: 4.1462e-04\n",
      "Epoch 578/1000\n",
      " - 15s - loss: 3.4228e-04 - mean_squared_error: 3.4228e-04 - val_loss: 4.6827e-04 - val_mean_squared_error: 4.6827e-04\n",
      "Epoch 579/1000\n",
      " - 15s - loss: 3.4188e-04 - mean_squared_error: 3.4188e-04 - val_loss: 2.9506e-04 - val_mean_squared_error: 2.9506e-04\n",
      "Epoch 580/1000\n",
      " - 15s - loss: 3.4159e-04 - mean_squared_error: 3.4159e-04 - val_loss: 3.4476e-04 - val_mean_squared_error: 3.4476e-04\n",
      "Epoch 581/1000\n",
      " - 15s - loss: 3.4139e-04 - mean_squared_error: 3.4139e-04 - val_loss: 3.3251e-04 - val_mean_squared_error: 3.3251e-04\n",
      "Epoch 582/1000\n",
      " - 15s - loss: 3.4161e-04 - mean_squared_error: 3.4161e-04 - val_loss: 3.6930e-04 - val_mean_squared_error: 3.6930e-04\n",
      "Epoch 583/1000\n",
      " - 15s - loss: 3.4191e-04 - mean_squared_error: 3.4191e-04 - val_loss: 3.3533e-04 - val_mean_squared_error: 3.3533e-04\n",
      "Epoch 584/1000\n",
      " - 15s - loss: 3.4136e-04 - mean_squared_error: 3.4136e-04 - val_loss: 2.7973e-04 - val_mean_squared_error: 2.7973e-04\n",
      "Epoch 585/1000\n",
      " - 15s - loss: 3.4123e-04 - mean_squared_error: 3.4123e-04 - val_loss: 3.9587e-04 - val_mean_squared_error: 3.9587e-04\n",
      "Epoch 586/1000\n",
      " - 15s - loss: 3.4056e-04 - mean_squared_error: 3.4056e-04 - val_loss: 4.6100e-04 - val_mean_squared_error: 4.6100e-04\n",
      "Epoch 587/1000\n",
      " - 15s - loss: 3.4125e-04 - mean_squared_error: 3.4125e-04 - val_loss: 2.9324e-04 - val_mean_squared_error: 2.9324e-04\n",
      "Epoch 588/1000\n",
      " - 15s - loss: 3.4070e-04 - mean_squared_error: 3.4070e-04 - val_loss: 3.2536e-04 - val_mean_squared_error: 3.2536e-04\n",
      "Epoch 589/1000\n",
      " - 15s - loss: 3.4101e-04 - mean_squared_error: 3.4101e-04 - val_loss: 4.6558e-04 - val_mean_squared_error: 4.6558e-04\n",
      "Epoch 590/1000\n",
      " - 15s - loss: 3.4093e-04 - mean_squared_error: 3.4093e-04 - val_loss: 2.7612e-04 - val_mean_squared_error: 2.7612e-04\n",
      "Epoch 591/1000\n",
      " - 15s - loss: 3.4024e-04 - mean_squared_error: 3.4024e-04 - val_loss: 3.3818e-04 - val_mean_squared_error: 3.3818e-04\n",
      "Epoch 592/1000\n",
      " - 15s - loss: 3.4068e-04 - mean_squared_error: 3.4068e-04 - val_loss: 3.4070e-04 - val_mean_squared_error: 3.4070e-04\n",
      "Epoch 593/1000\n",
      " - 15s - loss: 3.4056e-04 - mean_squared_error: 3.4056e-04 - val_loss: 3.0406e-04 - val_mean_squared_error: 3.0406e-04\n",
      "Epoch 594/1000\n",
      " - 15s - loss: 3.4067e-04 - mean_squared_error: 3.4067e-04 - val_loss: 2.9882e-04 - val_mean_squared_error: 2.9882e-04\n",
      "Epoch 595/1000\n",
      " - 15s - loss: 3.4060e-04 - mean_squared_error: 3.4060e-04 - val_loss: 4.8822e-04 - val_mean_squared_error: 4.8822e-04\n",
      "Epoch 596/1000\n",
      " - 15s - loss: 3.4032e-04 - mean_squared_error: 3.4032e-04 - val_loss: 3.5369e-04 - val_mean_squared_error: 3.5369e-04\n",
      "Epoch 597/1000\n",
      " - 15s - loss: 3.4023e-04 - mean_squared_error: 3.4023e-04 - val_loss: 3.6109e-04 - val_mean_squared_error: 3.6109e-04\n",
      "Epoch 598/1000\n",
      " - 15s - loss: 3.3993e-04 - mean_squared_error: 3.3993e-04 - val_loss: 3.1220e-04 - val_mean_squared_error: 3.1220e-04\n",
      "Epoch 599/1000\n",
      " - 15s - loss: 3.4011e-04 - mean_squared_error: 3.4011e-04 - val_loss: 4.7234e-04 - val_mean_squared_error: 4.7234e-04\n",
      "Epoch 600/1000\n",
      " - 15s - loss: 3.4007e-04 - mean_squared_error: 3.4007e-04 - val_loss: 3.9423e-04 - val_mean_squared_error: 3.9423e-04\n",
      "Epoch 601/1000\n",
      " - 15s - loss: 3.3996e-04 - mean_squared_error: 3.3996e-04 - val_loss: 5.1013e-04 - val_mean_squared_error: 5.1013e-04\n",
      "Epoch 602/1000\n",
      " - 15s - loss: 3.3946e-04 - mean_squared_error: 3.3946e-04 - val_loss: 3.2727e-04 - val_mean_squared_error: 3.2727e-04\n",
      "Epoch 603/1000\n",
      " - 15s - loss: 3.4027e-04 - mean_squared_error: 3.4027e-04 - val_loss: 2.5739e-04 - val_mean_squared_error: 2.5739e-04\n",
      "Epoch 604/1000\n",
      " - 15s - loss: 3.3938e-04 - mean_squared_error: 3.3938e-04 - val_loss: 2.7000e-04 - val_mean_squared_error: 2.7000e-04\n",
      "Epoch 605/1000\n",
      " - 15s - loss: 3.3960e-04 - mean_squared_error: 3.3960e-04 - val_loss: 2.6838e-04 - val_mean_squared_error: 2.6838e-04\n",
      "Epoch 606/1000\n",
      " - 15s - loss: 3.3922e-04 - mean_squared_error: 3.3922e-04 - val_loss: 4.1512e-04 - val_mean_squared_error: 4.1512e-04\n",
      "Epoch 607/1000\n",
      " - 15s - loss: 3.3926e-04 - mean_squared_error: 3.3926e-04 - val_loss: 5.0143e-04 - val_mean_squared_error: 5.0143e-04\n",
      "Epoch 608/1000\n",
      " - 15s - loss: 3.3891e-04 - mean_squared_error: 3.3891e-04 - val_loss: 3.5754e-04 - val_mean_squared_error: 3.5754e-04\n",
      "Epoch 609/1000\n",
      " - 15s - loss: 3.3874e-04 - mean_squared_error: 3.3874e-04 - val_loss: 4.1073e-04 - val_mean_squared_error: 4.1073e-04\n",
      "Epoch 610/1000\n",
      " - 15s - loss: 3.3924e-04 - mean_squared_error: 3.3924e-04 - val_loss: 3.2906e-04 - val_mean_squared_error: 3.2906e-04\n",
      "Epoch 611/1000\n",
      " - 15s - loss: 3.3878e-04 - mean_squared_error: 3.3878e-04 - val_loss: 3.7504e-04 - val_mean_squared_error: 3.7504e-04\n",
      "Epoch 612/1000\n",
      " - 15s - loss: 3.3874e-04 - mean_squared_error: 3.3874e-04 - val_loss: 4.4267e-04 - val_mean_squared_error: 4.4267e-04\n",
      "Epoch 613/1000\n",
      " - 15s - loss: 3.3874e-04 - mean_squared_error: 3.3874e-04 - val_loss: 3.3776e-04 - val_mean_squared_error: 3.3776e-04\n",
      "Epoch 614/1000\n",
      " - 15s - loss: 3.3874e-04 - mean_squared_error: 3.3874e-04 - val_loss: 2.7467e-04 - val_mean_squared_error: 2.7467e-04\n",
      "Epoch 615/1000\n",
      " - 15s - loss: 3.3823e-04 - mean_squared_error: 3.3823e-04 - val_loss: 3.7353e-04 - val_mean_squared_error: 3.7353e-04\n",
      "Epoch 616/1000\n",
      " - 15s - loss: 3.3864e-04 - mean_squared_error: 3.3864e-04 - val_loss: 3.7310e-04 - val_mean_squared_error: 3.7310e-04\n",
      "Epoch 617/1000\n",
      " - 15s - loss: 3.3844e-04 - mean_squared_error: 3.3844e-04 - val_loss: 3.4386e-04 - val_mean_squared_error: 3.4386e-04\n",
      "Epoch 618/1000\n",
      " - 15s - loss: 3.3859e-04 - mean_squared_error: 3.3859e-04 - val_loss: 3.1600e-04 - val_mean_squared_error: 3.1600e-04\n",
      "Epoch 619/1000\n",
      " - 15s - loss: 3.3798e-04 - mean_squared_error: 3.3798e-04 - val_loss: 4.6940e-04 - val_mean_squared_error: 4.6940e-04\n",
      "Epoch 620/1000\n",
      " - 15s - loss: 3.3840e-04 - mean_squared_error: 3.3840e-04 - val_loss: 3.1925e-04 - val_mean_squared_error: 3.1925e-04\n",
      "Epoch 621/1000\n",
      " - 15s - loss: 3.3829e-04 - mean_squared_error: 3.3829e-04 - val_loss: 3.2796e-04 - val_mean_squared_error: 3.2796e-04\n",
      "Epoch 622/1000\n",
      " - 15s - loss: 3.3832e-04 - mean_squared_error: 3.3832e-04 - val_loss: 3.2753e-04 - val_mean_squared_error: 3.2753e-04\n",
      "Epoch 623/1000\n",
      " - 15s - loss: 3.3797e-04 - mean_squared_error: 3.3797e-04 - val_loss: 9.9045e-04 - val_mean_squared_error: 9.9045e-04\n",
      "Epoch 624/1000\n",
      " - 15s - loss: 3.3780e-04 - mean_squared_error: 3.3780e-04 - val_loss: 3.5515e-04 - val_mean_squared_error: 3.5515e-04\n",
      "Epoch 625/1000\n",
      " - 15s - loss: 3.3750e-04 - mean_squared_error: 3.3750e-04 - val_loss: 4.7011e-04 - val_mean_squared_error: 4.7011e-04\n",
      "Epoch 626/1000\n",
      " - 15s - loss: 3.3743e-04 - mean_squared_error: 3.3743e-04 - val_loss: 2.7123e-04 - val_mean_squared_error: 2.7123e-04\n",
      "Epoch 627/1000\n",
      " - 15s - loss: 3.3725e-04 - mean_squared_error: 3.3725e-04 - val_loss: 3.0182e-04 - val_mean_squared_error: 3.0182e-04\n",
      "Epoch 628/1000\n",
      " - 15s - loss: 3.3745e-04 - mean_squared_error: 3.3745e-04 - val_loss: 3.1072e-04 - val_mean_squared_error: 3.1072e-04\n",
      "Epoch 629/1000\n",
      " - 15s - loss: 3.3752e-04 - mean_squared_error: 3.3752e-04 - val_loss: 3.1672e-04 - val_mean_squared_error: 3.1672e-04\n",
      "Epoch 630/1000\n",
      " - 15s - loss: 3.3709e-04 - mean_squared_error: 3.3709e-04 - val_loss: 4.4496e-04 - val_mean_squared_error: 4.4496e-04\n",
      "Epoch 631/1000\n",
      " - 15s - loss: 3.3770e-04 - mean_squared_error: 3.3770e-04 - val_loss: 3.1775e-04 - val_mean_squared_error: 3.1775e-04\n",
      "Epoch 632/1000\n",
      " - 15s - loss: 3.3675e-04 - mean_squared_error: 3.3675e-04 - val_loss: 7.2113e-04 - val_mean_squared_error: 7.2113e-04\n",
      "Epoch 633/1000\n",
      " - 15s - loss: 3.3691e-04 - mean_squared_error: 3.3691e-04 - val_loss: 3.2603e-04 - val_mean_squared_error: 3.2603e-04\n",
      "Epoch 634/1000\n",
      " - 15s - loss: 3.3664e-04 - mean_squared_error: 3.3664e-04 - val_loss: 3.4659e-04 - val_mean_squared_error: 3.4659e-04\n",
      "Epoch 635/1000\n",
      " - 15s - loss: 3.3666e-04 - mean_squared_error: 3.3666e-04 - val_loss: 5.8889e-04 - val_mean_squared_error: 5.8889e-04\n",
      "Epoch 636/1000\n",
      " - 15s - loss: 3.3688e-04 - mean_squared_error: 3.3688e-04 - val_loss: 2.9254e-04 - val_mean_squared_error: 2.9254e-04\n",
      "Epoch 637/1000\n",
      " - 15s - loss: 3.3653e-04 - mean_squared_error: 3.3653e-04 - val_loss: 3.2473e-04 - val_mean_squared_error: 3.2473e-04\n",
      "Epoch 638/1000\n",
      " - 15s - loss: 3.3638e-04 - mean_squared_error: 3.3638e-04 - val_loss: 3.0686e-04 - val_mean_squared_error: 3.0686e-04\n",
      "Epoch 639/1000\n",
      " - 15s - loss: 3.3625e-04 - mean_squared_error: 3.3625e-04 - val_loss: 3.4070e-04 - val_mean_squared_error: 3.4070e-04\n",
      "Epoch 640/1000\n",
      " - 15s - loss: 3.3662e-04 - mean_squared_error: 3.3662e-04 - val_loss: 5.8869e-04 - val_mean_squared_error: 5.8869e-04\n",
      "Epoch 641/1000\n",
      " - 15s - loss: 3.3611e-04 - mean_squared_error: 3.3611e-04 - val_loss: 5.5578e-04 - val_mean_squared_error: 5.5578e-04\n",
      "Epoch 642/1000\n",
      " - 15s - loss: 3.3597e-04 - mean_squared_error: 3.3597e-04 - val_loss: 4.2771e-04 - val_mean_squared_error: 4.2771e-04\n",
      "Epoch 643/1000\n",
      " - 15s - loss: 3.3593e-04 - mean_squared_error: 3.3593e-04 - val_loss: 3.4135e-04 - val_mean_squared_error: 3.4135e-04\n",
      "Epoch 644/1000\n",
      " - 15s - loss: 3.3624e-04 - mean_squared_error: 3.3624e-04 - val_loss: 2.9373e-04 - val_mean_squared_error: 2.9373e-04\n",
      "Epoch 645/1000\n",
      " - 15s - loss: 3.3606e-04 - mean_squared_error: 3.3606e-04 - val_loss: 4.0521e-04 - val_mean_squared_error: 4.0521e-04\n",
      "Epoch 646/1000\n",
      " - 15s - loss: 3.3624e-04 - mean_squared_error: 3.3624e-04 - val_loss: 3.6236e-04 - val_mean_squared_error: 3.6236e-04\n",
      "Epoch 647/1000\n",
      " - 15s - loss: 3.3586e-04 - mean_squared_error: 3.3586e-04 - val_loss: 3.1272e-04 - val_mean_squared_error: 3.1272e-04\n",
      "Epoch 648/1000\n",
      " - 15s - loss: 3.3571e-04 - mean_squared_error: 3.3571e-04 - val_loss: 3.0083e-04 - val_mean_squared_error: 3.0083e-04\n",
      "Epoch 649/1000\n",
      " - 15s - loss: 3.3580e-04 - mean_squared_error: 3.3580e-04 - val_loss: 3.6459e-04 - val_mean_squared_error: 3.6459e-04\n",
      "Epoch 650/1000\n",
      " - 15s - loss: 3.3578e-04 - mean_squared_error: 3.3578e-04 - val_loss: 2.5566e-04 - val_mean_squared_error: 2.5566e-04\n",
      "Epoch 651/1000\n",
      " - 15s - loss: 3.3551e-04 - mean_squared_error: 3.3551e-04 - val_loss: 5.0111e-04 - val_mean_squared_error: 5.0111e-04\n",
      "Epoch 652/1000\n",
      " - 15s - loss: 3.3525e-04 - mean_squared_error: 3.3525e-04 - val_loss: 5.6447e-04 - val_mean_squared_error: 5.6447e-04\n",
      "Epoch 653/1000\n",
      " - 15s - loss: 3.3532e-04 - mean_squared_error: 3.3532e-04 - val_loss: 3.8095e-04 - val_mean_squared_error: 3.8095e-04\n",
      "Epoch 654/1000\n",
      " - 15s - loss: 3.3569e-04 - mean_squared_error: 3.3569e-04 - val_loss: 2.9313e-04 - val_mean_squared_error: 2.9313e-04\n",
      "Epoch 655/1000\n",
      " - 15s - loss: 3.3502e-04 - mean_squared_error: 3.3502e-04 - val_loss: 2.8221e-04 - val_mean_squared_error: 2.8221e-04\n",
      "Epoch 656/1000\n",
      " - 15s - loss: 3.3501e-04 - mean_squared_error: 3.3501e-04 - val_loss: 3.8766e-04 - val_mean_squared_error: 3.8766e-04\n",
      "Epoch 657/1000\n",
      " - 15s - loss: 3.3524e-04 - mean_squared_error: 3.3524e-04 - val_loss: 3.1455e-04 - val_mean_squared_error: 3.1455e-04\n",
      "Epoch 658/1000\n",
      " - 15s - loss: 3.3475e-04 - mean_squared_error: 3.3475e-04 - val_loss: 2.6727e-04 - val_mean_squared_error: 2.6727e-04\n",
      "Epoch 659/1000\n",
      " - 15s - loss: 3.3494e-04 - mean_squared_error: 3.3494e-04 - val_loss: 3.3014e-04 - val_mean_squared_error: 3.3014e-04\n",
      "Epoch 660/1000\n",
      " - 15s - loss: 3.3508e-04 - mean_squared_error: 3.3508e-04 - val_loss: 3.1663e-04 - val_mean_squared_error: 3.1663e-04\n",
      "Epoch 661/1000\n",
      " - 15s - loss: 3.3464e-04 - mean_squared_error: 3.3464e-04 - val_loss: 3.0070e-04 - val_mean_squared_error: 3.0070e-04\n",
      "Epoch 662/1000\n",
      " - 15s - loss: 3.3475e-04 - mean_squared_error: 3.3475e-04 - val_loss: 3.6532e-04 - val_mean_squared_error: 3.6532e-04\n",
      "Epoch 663/1000\n",
      " - 15s - loss: 3.3477e-04 - mean_squared_error: 3.3477e-04 - val_loss: 3.0263e-04 - val_mean_squared_error: 3.0263e-04\n",
      "Epoch 664/1000\n",
      " - 15s - loss: 3.3460e-04 - mean_squared_error: 3.3460e-04 - val_loss: 3.2097e-04 - val_mean_squared_error: 3.2097e-04\n",
      "Epoch 665/1000\n",
      " - 15s - loss: 3.3461e-04 - mean_squared_error: 3.3461e-04 - val_loss: 3.8129e-04 - val_mean_squared_error: 3.8129e-04\n",
      "Epoch 666/1000\n",
      " - 15s - loss: 3.3439e-04 - mean_squared_error: 3.3439e-04 - val_loss: 4.4202e-04 - val_mean_squared_error: 4.4202e-04\n",
      "Epoch 667/1000\n",
      " - 15s - loss: 3.3453e-04 - mean_squared_error: 3.3453e-04 - val_loss: 4.0427e-04 - val_mean_squared_error: 4.0427e-04\n",
      "Epoch 668/1000\n",
      " - 15s - loss: 3.3431e-04 - mean_squared_error: 3.3431e-04 - val_loss: 4.0564e-04 - val_mean_squared_error: 4.0564e-04\n",
      "Epoch 669/1000\n",
      " - 15s - loss: 3.3434e-04 - mean_squared_error: 3.3434e-04 - val_loss: 3.6336e-04 - val_mean_squared_error: 3.6336e-04\n",
      "Epoch 670/1000\n",
      " - 15s - loss: 3.3399e-04 - mean_squared_error: 3.3399e-04 - val_loss: 3.1663e-04 - val_mean_squared_error: 3.1663e-04\n",
      "Epoch 00670: early stopping\n"
     ]
    }
   ],
   "source": [
    "# train without pruning\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, \n",
    "                    validation_data=(Xval_scaled, Yval_scaled), \n",
    "                    callbacks = [earlystop],\n",
    "                    verbose = 2, batch_size=2**12, epochs = 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save history\n",
    "historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1bb7334ce48>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.rcParams.update({'font.size': 18})\n",
    "plot_model_history(history, saveFig=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(os.path.join(savedModels,  modelName + '.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_wts.pkl'\n",
    "pickle.dump(wts, open(os.path.join(dataOutput, wtsFile), 'wb'))\n",
    "\n",
    "# save history with same name as model\n",
    "historyFile = modeltimestamp + '_history.pkl'\n",
    "pickle.dump(scalerY, open(os.path.join(dataOutput, scalerfileY), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  plot error rates on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "Ytest_pred = model.predict(Xtest_scaled)\n",
    "\n",
    "\n",
    "# make data frames\n",
    "XtestDF = pd.DataFrame(scalerX.inverse_transform(Xtest_scaled), columns = Xtrain.columns)\n",
    "YtestDF = pd.DataFrame(Ytest, columns = Ytrain.columns)\n",
    "YpredDF = pd.DataFrame(scalerY.inverse_transform(Ytest_pred), columns = Ytrain.columns+ \"_pred\")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df_c = pd.concat([YtestDF.reset_index(drop=True), YpredDF], axis=1)\n",
    "df_c.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_c = df_c.iloc[:1000, :]\n",
    "\n",
    "# df_c = df_c.replace([np.inf, -np.inf], np.nan)\n",
    "# df_c = df_c.replace([np.inf, -np.inf], np.nan).dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mtick\n",
    "import matplotlib\n",
    "class MathTextSciFormatter(mtick.Formatter):\n",
    "    def __init__(self, fmt=\"%1.2e\"):\n",
    "        self.fmt = fmt\n",
    "    def __call__(self, x, pos=None):\n",
    "        s = self.fmt % x\n",
    "        decimal_point = '.'\n",
    "        positive_sign = '+'\n",
    "        tup = s.split('e')\n",
    "        significand = tup[0].rstrip(decimal_point)\n",
    "        sign = tup[1][0].replace(positive_sign, '')\n",
    "        exponent = tup[1][1:].lstrip('0')\n",
    "        if exponent:\n",
    "            exponent = '10^{%s%s}' % (sign, exponent)\n",
    "        if significand and exponent:\n",
    "            s =  r'%s{\\times}%s' % (significand, exponent)\n",
    "        else:\n",
    "            return(\" \")\n",
    "        return \"${}$\".format(s)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# make plots\n",
    "from sklearn.metrics import r2_score\n",
    "from matplotlib import ticker\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['mathtext.default'] = 'regular'\n",
    "import matplotlib.ticker as mtick\n",
    "plt.rcParams.update({'font.size': 18})\n",
    "\n",
    "\n",
    "fig_col_names = [r'$F_x$', r'$F_y$', r'$\\tau$', r'$\\dot{x}_f$', r'$\\dot{y}_f$', r'$\\dot{\\phi}_f$', r'$\\dot{\\theta}_f$']\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,Ytest.shape[1], figsize=np.array([25, 5.5]), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.4, wspace=.9)\n",
    "# fig.suptitle('Predicted vs. acutal ', fontsize=14, fontweight='bold')\n",
    "\n",
    "axs = axs.ravel(\"C\")\n",
    "\n",
    "ylabs = [r'$gcm/s^2$', \"$gcm/s^2$\", \"$gcm^2/s^2$\", \"$cm/s$\", \"$cm/s$\", \"$rad/s$\", \"$rad/s$\"]\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "#cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "# Plot y = actual, x = predicted\n",
    "for ii in np.arange(0, df_c.shape[1] //2):\n",
    "    axs[ii].hexbin(y = df_c.loc[:,YtestDF.columns[ii]],\n",
    "                   x = df_c.loc[:,YpredDF.columns[ii]], \n",
    "                   gridsize = 50, cmap = cmap)\n",
    "    axs[ii].xaxis.set_major_locator(ticker.MaxNLocator(3))\n",
    "    axs[ii].yaxis.set_major_locator(ticker.MaxNLocator(3))\n",
    "\n",
    "    if(ii == 0):\n",
    "        axs[ii].set_ylabel(\"Actual Value\\n\" + ylabs[ii])\n",
    "    else:\n",
    "        axs[ii].set_ylabel(ylabs[ii])\n",
    "\n",
    "    #axs[ii].set_title(YtestDF.columns[ii])\n",
    "    axs[ii].set_title(fig_col_names[ii], fontdict = {'verticalalignment': 'bottom'})\n",
    "    axs[ii].plot(df_c.loc[:,YtestDF.columns[ii]], \n",
    "                 df_c.loc[:,YtestDF.columns[ii]], \n",
    "                 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    axs[ii].yaxis.set_major_formatter(MathTextSciFormatter(\"%1.0e\"))\n",
    "    axs[ii].xaxis.set_major_formatter(MathTextSciFormatter(\"%1.0e\"))\n",
    "    axs[ii].set_aspect('equal', 'box')\n",
    "\n",
    "    # annotate with R^2\n",
    "    axs[ii].text(np.max(df_c.loc[:,YtestDF.columns[ii]])*-0.4, \n",
    "                 np.min(df_c.loc[:,YtestDF.columns[ii]])*0.9, \n",
    "                 r'$r^2$ =' + \n",
    "                 str(np.round((r2_score(df_c.loc[:,YtestDF.columns[ii]],  \n",
    "                                        df_c.loc[:,YpredDF.columns[ii]])), 3)))\n",
    "    axs[ii].set_xlim([-np.max(np.abs(df_c.loc[:,YpredDF.columns[ii]])), \n",
    "                      np.max(np.abs(df_c.loc[:,YpredDF.columns[ii]]))])\n",
    "    axs[ii].set_ylim([-np.max(np.abs(df_c.loc[:,YpredDF.columns[ii]])), \n",
    "                  np.max(np.abs(df_c.loc[:,YpredDF.columns[ii]]))])\n",
    "\n",
    "# # residual plots x = predicted, y = actual - predicted\n",
    "# jj is column in dataset, plotNum is plot position\n",
    "for jj, plotNum in enumerate(np.arange(Ytest.shape[1], df_c.shape[1])):\n",
    "\n",
    "    axs[plotNum].hexbin(y = df_c.loc[:,YtestDF.columns[jj]] - df_c.loc[:,YpredDF.columns[jj]],\n",
    "                   x = df_c.loc[:,YpredDF.columns[jj]], \n",
    "                   gridsize = 50, cmap = cmap) \n",
    "    axs[plotNum].xaxis.set_major_locator(ticker.MaxNLocator(3))\n",
    "    axs[plotNum].yaxis.set_major_locator(ticker.MaxNLocator(3))  \n",
    "    \n",
    "    if jj == 3:\n",
    "        axs[plotNum].set_xlabel(ylabs[jj] + \"\\n\\n\" + \"Predicted Value\")\n",
    "    else:\n",
    "        axs[plotNum].set_xlabel(ylabs[jj] + \"\\n\")\n",
    "    axs[plotNum].yaxis.set_major_formatter(MathTextSciFormatter(\"%1.0e\"))\n",
    "    axs[plotNum].xaxis.set_major_formatter(MathTextSciFormatter(\"%1.0e\"))\n",
    "\n",
    "    if(jj == 0):\n",
    "        axs[plotNum].set_ylabel(\"Actual - Predicted\\n\" + ylabs[jj])\n",
    "    else:\n",
    "        axs[plotNum].set_ylabel(ylabs[jj])\n",
    "\n",
    "    axs[plotNum].hlines(y = 0, xmin = np.min( df_c.loc[:,YpredDF.columns[jj]]), \n",
    "                   xmax = np.max( df_c.loc[:,YpredDF.columns[jj]]), \n",
    "                   linestyle =  \"--\", linewidth = 1)\n",
    "    axs[plotNum].set_ylim([-np.max(np.abs(df_c.loc[:,YtestDF.columns[jj]] - df_c.loc[:,YpredDF.columns[jj]])), \n",
    "                      np.max(np.abs(df_c.loc[:,YtestDF.columns[jj]]- df_c.loc[:,YpredDF.columns[jj]]))])\n",
    "\n",
    "\n",
    "fig.savefig(os.path.join(figDir, \"PredVActual\" + modelName + \".pdf\"), dpi = 500, bbox_inches='tight')\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots\n",
    "from sklearn.metrics import r2_score\n",
    "from matplotlib import ticker\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['mathtext.default'] = 'regular'\n",
    "import matplotlib.ticker as mtick\n",
    "plt.rcParams.update({'font.size': 11})\n",
    "matplotlib.rcParams['pdf.fonttype'] = 42\n",
    "matplotlib.rcParams['ps.fonttype'] = 42\n",
    "import matplotlib.transforms as mtrans\n",
    "\n",
    "\n",
    "fig_col_names = [r'$F_x$', r'$F_y$', r'$\\tau$', r'$\\dot{x}_f$', r'$\\dot{y}_f$', r'$\\dot{\\phi}_f$', r'$\\dot{\\theta}_f$']\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(4,4, figsize=np.array([8, 7.5]), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.9, wspace=.9)\n",
    "# fig.suptitle('Predicted vs. acutal ', fontsize=14, fontweight='bold')\n",
    "\n",
    "axs = axs.ravel(\"C\")\n",
    "\n",
    "ylabs = [r'$gcm/s^2$', \"$gcm/s^2$\", \"$gcm^2/s^2$\", \"$cm/s$\", \"$cm/s$\", \"$rad/s$\", \"$rad/s$\"]\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "# Plot y = actual, x = predicted\n",
    "for ii in np.arange(0, 3):\n",
    "    axs[ii].hexbin(y = df_c.loc[:,YtestDF.columns[ii]],\n",
    "                   x = df_c.loc[:,YpredDF.columns[ii]], \n",
    "                   gridsize = 50, cmap = cmap)\n",
    "    axs[ii].xaxis.set_major_locator(ticker.MaxNLocator(3))\n",
    "    axs[ii].yaxis.set_major_locator(ticker.MaxNLocator(3))\n",
    "    axs[ii].set_yticklabels(axs[ii].get_yticklabels(), \n",
    "                            rotation = 45, ha=\"center\",\n",
    "                            va = \"bottom\", rotation_mode=\"anchor\")\n",
    "    axs[ii].yaxis.set_label_coords(-0.4,0.5)\n",
    "    axs[ii].set_xlabel(ylabs[ii] + \"\\n\")\n",
    "    axs[ii].xaxis.set_label_coords(0.5,-0.2)\n",
    "#     axs[ii].set_xticklabels(axs[ii].get_xticklabels(), \n",
    "#                            va = \"center\", rotation_mode=\"anchor\")\n",
    "    axs[ii].tick_params(axis=\"x\",direction=\"out\", pad=-0)\n",
    "    \n",
    "\n",
    "    if(ii == 0):\n",
    "        axs[ii].set_ylabel(\"Actual Value\\n\" + ylabs[ii])\n",
    "    else:\n",
    "        axs[ii].set_ylabel(ylabs[ii])\n",
    "\n",
    "    #axs[ii].set_title(YtestDF.columns[ii])\n",
    "    axs[ii].set_title(fig_col_names[ii], fontdict = {'verticalalignment': 'bottom'})\n",
    "    ttl = axs[ii].title\n",
    "    ttl.set_position([.15, 0.62])\n",
    "    axs[ii].plot(df_c.loc[:,YtestDF.columns[ii]], \n",
    "                 df_c.loc[:,YtestDF.columns[ii]], \n",
    "                 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    axs[ii].yaxis.set_major_formatter(MathTextSciFormatter(\"%1.0e\"))\n",
    "    axs[ii].xaxis.set_major_formatter(MathTextSciFormatter(\"%1.0e\"))\n",
    "    axs[ii].set_aspect('equal', 'box')\n",
    "\n",
    "    # annotate with R^2\n",
    "    axs[ii].text(np.max(df_c.loc[:,YtestDF.columns[ii]])*-0.4, \n",
    "                 np.min(df_c.loc[:,YtestDF.columns[ii]])*0.9, \n",
    "                 r'$r^2$ =' + \n",
    "                 str(np.round((r2_score(df_c.loc[:,YtestDF.columns[ii]],  \n",
    "                                        df_c.loc[:,YpredDF.columns[ii]])), 3)))\n",
    "    axs[ii].set_xlim([-np.max(np.abs(df_c.loc[:,YpredDF.columns[ii]])), \n",
    "                      np.max(np.abs(df_c.loc[:,YpredDF.columns[ii]]))])\n",
    "    axs[ii].set_ylim([-np.max(np.abs(df_c.loc[:,YpredDF.columns[ii]])), \n",
    "                  np.max(np.abs(df_c.loc[:,YpredDF.columns[ii]]))])\n",
    "\n",
    "# # residual plots x = predicted, y = actual - predicted\n",
    "# jj is column in dataset, plotNum is plot position\n",
    "for jj, plotNum in enumerate(np.arange(4, 7)):\n",
    "\n",
    "    axs[plotNum].hexbin(y = df_c.loc[:,YtestDF.columns[jj]] - df_c.loc[:,YpredDF.columns[jj]],\n",
    "                   x = df_c.loc[:,YpredDF.columns[jj]], \n",
    "                   gridsize = 50, cmap = cmap) \n",
    "    axs[plotNum].xaxis.set_major_locator(ticker.MaxNLocator(3))\n",
    "    axs[plotNum].yaxis.set_major_locator(ticker.MaxNLocator(3))  \n",
    "    axs[plotNum].set_yticklabels(axs[plotNum].get_yticklabels(), \n",
    "                                 rotation = 45, ha=\"center\", \n",
    "                                 va = \"bottom\", rotation_mode=\"anchor\")\n",
    "    axs[plotNum].yaxis.set_label_coords(-0.4,0.5)\n",
    "    axs[plotNum].xaxis.set_label_coords(0.5,-0.2)\n",
    "    \n",
    "    if jj == 3:\n",
    "        axs[plotNum].set_xlabel(ylabs[jj] + \"\\n\\n\" + \"                      Predicted Value\")\n",
    "    else:\n",
    "        axs[plotNum].set_xlabel(ylabs[jj] + \"\\n\")\n",
    "    axs[plotNum].yaxis.set_major_formatter(MathTextSciFormatter(\"%1.0e\"))\n",
    "    axs[plotNum].xaxis.set_major_formatter(MathTextSciFormatter(\"%1.0e\"))\n",
    "\n",
    "    if(jj == 0):\n",
    "        axs[plotNum].set_ylabel(\"Actual - Predicted\\n\" + ylabs[jj])\n",
    "    else:\n",
    "        axs[plotNum].set_ylabel(ylabs[jj])\n",
    "        \n",
    "    axs[plotNum].set_title(fig_col_names[jj], fontdict = {'verticalalignment': 'bottom'})\n",
    "    ttl = axs[plotNum].title\n",
    "    ttl.set_position([.15, 0.62])\n",
    "\n",
    "    axs[plotNum].hlines(y = 0, xmin = np.min( df_c.loc[:,YpredDF.columns[jj]]), \n",
    "                   xmax = np.max( df_c.loc[:,YpredDF.columns[jj]]), \n",
    "                   linestyle =  \"--\", linewidth = 1)\n",
    "    axs[plotNum].set_ylim([-np.max(np.abs(df_c.loc[:,YtestDF.columns[jj]] - df_c.loc[:,YpredDF.columns[jj]])), \n",
    "                      np.max(np.abs(df_c.loc[:,YtestDF.columns[jj]]- df_c.loc[:,YpredDF.columns[jj]]))])\n",
    "    axs[plotNum].tick_params(axis=\"x\",direction=\"out\", pad=-0)\n",
    "#####\n",
    "#### Part 2\n",
    "#####\n",
    "\n",
    "#fig.subplots_adjust(hspace = 0.9, wspace=.9)\n",
    "\n",
    "# Plot y = actual, x = predicted\n",
    "for plotnum, dataColNum in zip(np.arange(8,12), np.arange(3, 7)):\n",
    "    axs[plotnum].hexbin(y = df_c.loc[:,YtestDF.columns[dataColNum]],\n",
    "                   x = df_c.loc[:,YpredDF.columns[dataColNum]], \n",
    "                   gridsize = 50, cmap = cmap)\n",
    "    axs[plotnum].xaxis.set_major_locator(ticker.MaxNLocator(3))\n",
    "    axs[plotnum].yaxis.set_major_locator(ticker.MaxNLocator(3))\n",
    "    axs[plotnum].set_yticklabels(axs[plotnum].get_yticklabels(),\n",
    "                                 rotation = 45, ha=\"center\",\n",
    "                                 va = \"bottom\", rotation_mode=\"anchor\")\n",
    "    axs[plotnum].yaxis.set_label_coords(-0.5,0.5)\n",
    "    axs[plotnum].set_xlabel(ylabs[dataColNum] + \"\\n\")\n",
    "    axs[plotnum].xaxis.set_label_coords(0.5,-0.2)\n",
    "\n",
    "    if(plotnum == 8):\n",
    "        axs[plotnum].set_ylabel(\"Actual Value\\n\" + ylabs[dataColNum])\n",
    "    else:\n",
    "        axs[plotnum].set_ylabel(ylabs[dataColNum])\n",
    "\n",
    "    #axs[ii].set_title(YtestDF.columns[ii])\n",
    "    axs[plotnum].set_title(fig_col_names[dataColNum], \n",
    "                           fontdict = {'verticalalignment': 'bottom'})\n",
    "    ttl = axs[plotnum].title\n",
    "    ttl.set_position([.15, 0.60])\n",
    "    axs[plotnum].plot(df_c.loc[:,YtestDF.columns[dataColNum]], \n",
    "                 df_c.loc[:,YtestDF.columns[dataColNum]], \n",
    "                 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    axs[plotnum].yaxis.set_major_formatter(MathTextSciFormatter(\"%1.0e\"))\n",
    "    axs[plotnum].xaxis.set_major_formatter(MathTextSciFormatter(\"%1.0e\"))\n",
    "    axs[plotnum].set_aspect('equal', 'box')\n",
    "\n",
    "    # annotate with R^2\n",
    "    axs[plotnum].text(np.max(df_c.loc[:,YtestDF.columns[dataColNum]])*-0.4, \n",
    "                 np.min(df_c.loc[:,YtestDF.columns[dataColNum]])*0.85, \n",
    "                 r'$r^2$ =' + \n",
    "                 str(np.round((r2_score(df_c.loc[:,YtestDF.columns[dataColNum]],  \n",
    "                                        df_c.loc[:,YpredDF.columns[dataColNum]])), 3)))\n",
    "    axs[plotnum].set_xlim([-np.max(np.abs(df_c.loc[:,YpredDF.columns[dataColNum]])), \n",
    "                      np.max(np.abs(df_c.loc[:,YpredDF.columns[dataColNum]]))])\n",
    "    axs[plotnum].set_ylim([-np.max(np.abs(df_c.loc[:,YpredDF.columns[dataColNum]])), \n",
    "                  np.max(np.abs(df_c.loc[:,YpredDF.columns[dataColNum]]))])\n",
    "    \n",
    "    axs[plotnum].tick_params(axis=\"x\",direction=\"out\", pad=-0)\n",
    "\n",
    "# residual plots x = predicted, y = actual - predicted\n",
    "# jj is column in dataset, plotNum is plot position\n",
    "# refref Here\n",
    "for jj, plotNum in zip(np.arange(3, 7), np.arange(12, 16)):\n",
    "\n",
    "    axs[plotNum].hexbin(y = df_c.loc[:,YtestDF.columns[jj]] - df_c.loc[:,YpredDF.columns[jj]],\n",
    "                   x = df_c.loc[:,YpredDF.columns[jj]], \n",
    "                   gridsize = 50, cmap = cmap) \n",
    "    axs[plotNum].xaxis.set_major_locator(ticker.MaxNLocator(3))\n",
    "    axs[plotNum].yaxis.set_major_locator(ticker.MaxNLocator(3))  \n",
    "    axs[plotNum].set_yticklabels(axs[plotNum].get_yticklabels(), \n",
    "                                 rotation = 45, ha=\"center\", \n",
    "                                 va = \"bottom\", rotation_mode=\"anchor\")\n",
    "    axs[plotNum].yaxis.set_label_coords(-0.4,0.5)\n",
    "    axs[plotNum].xaxis.set_label_coords(0.5,-0.2)\n",
    "    \n",
    "    if jj == 4:\n",
    "        axs[plotNum].set_xlabel(ylabs[jj] + \"\\n\\n\" + \"                                       Predicted Value\")\n",
    "    else:\n",
    "        axs[plotNum].set_xlabel(ylabs[jj] + \"\\n\")\n",
    "    axs[plotNum].yaxis.set_major_formatter(MathTextSciFormatter(\"%1.0e\"))\n",
    "    axs[plotNum].xaxis.set_major_formatter(MathTextSciFormatter(\"%1.0e\"))\n",
    "\n",
    "    if(jj == 3):\n",
    "        axs[plotNum].set_ylabel(\"Actual - Predicted\\n\" + ylabs[jj])\n",
    "    else:\n",
    "        axs[plotNum].set_ylabel(ylabs[jj])\n",
    "\n",
    "    axs[plotNum].hlines(y = 0, xmin = np.min( df_c.loc[:,YpredDF.columns[jj]]), \n",
    "                   xmax = np.max( df_c.loc[:,YpredDF.columns[jj]]), \n",
    "                   linestyle =  \"--\", linewidth = 1)\n",
    "    axs[plotNum].set_ylim([-np.max(np.abs(df_c.loc[:,YtestDF.columns[jj]] - df_c.loc[:,YpredDF.columns[jj]])), \n",
    "                      np.max(np.abs(df_c.loc[:,YtestDF.columns[jj]]- df_c.loc[:,YpredDF.columns[jj]]))])\n",
    "    \n",
    "    axs[plotNum].set_title(fig_col_names[jj], fontdict = {'verticalalignment': 'bottom'})\n",
    "    ttl = axs[plotNum].title\n",
    "    ttl.set_position([.15, 0.67])\n",
    "    axs[plotNum].tick_params(axis=\"x\",direction=\"out\", pad=-0)\n",
    "    \n",
    "\n",
    "# add black horizontal line\n",
    "ax3 = plt.figure(1).add_subplot(111)\n",
    "ax3.plot([-1,1],[0.48,0.48], '-', color = \"black\" )\n",
    "ax3.set_xlim([0,1])\n",
    "ax3.set_ylim([0,1])\n",
    "ax3.axis(\"off\")\n",
    "\n",
    "#plt.tight_layout()\n",
    "fig.savefig(os.path.join(figDir, \"PredVActual\" + modelName + \".pdf\"),)\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.arange(4, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots --- Vertical\n",
    "from sklearn.metrics import r2_score\n",
    "from matplotlib import ticker\n",
    "matplotlib.rcParams['mathtext.fontset'] = 'stix'\n",
    "matplotlib.rcParams['mathtext.default'] = 'regular'\n",
    "import matplotlib.ticker as mtick\n",
    "plt.rcParams.update({'font.size': 8})\n",
    "\n",
    "\n",
    "fig_col_names = [r'$F_x$', r'$F_y$', r'$\\tau$', r'$\\dot{x}_f$', r'$\\dot{y}_f$', r'$\\dot{\\phi}_f$', r'$\\dot{\\theta}_f$']\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(Ytest.shape[1], 2,figsize=np.array([ 3, 22]), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 1.4, wspace=1.5)\n",
    "# fig.suptitle('Predicted vs. acutal ', fontsize=14, fontweight='bold')\n",
    "\n",
    "axs = axs.ravel(\"C\")\n",
    "\n",
    "ylabs = [r'$gcm/s^2$', \"$gcm/s^2$\", \"$gcm^2/s^2$\", \"$cm/s$\", \"$cm/s$\", \"$rad/s$\", \"$rad/s$\"]\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "# Plot y = actual, x = predicted\n",
    "for ii, colnum in enumerate(np.arange(0, df_c.shape[1], 2)):\n",
    "    axs[colnum].hexbin(y = df_c.loc[:,YtestDF.columns[ii]],\n",
    "                   x = df_c.loc[:,YpredDF.columns[ii]], \n",
    "                   gridsize = 50, cmap = cmap)\n",
    "    axs[colnum].xaxis.set_major_locator(ticker.MaxNLocator(3))\n",
    "    axs[colnum].yaxis.set_major_locator(ticker.MaxNLocator(3))\n",
    "\n",
    "    if(ii == 0):\n",
    "        axs[colnum].set_title(\"Actual Value\\n\")\n",
    "    \n",
    "    axs[colnum].set_ylabel(fig_col_names[ii] + \"\\n\" + ylabs[ii])\n",
    "    axs[colnum].set_xlabel(ylabs[ii])\n",
    "\n",
    "    #axs[ii].set_title(YtestDF.columns[ii])\n",
    "#     axs[colnum].set_title(fig_col_names[ii], fontdict = {'verticalalignment': 'bottom'})\n",
    "    axs[colnum].plot(df_c.loc[:,YtestDF.columns[ii]], \n",
    "                 df_c.loc[:,YtestDF.columns[ii]], \n",
    "                 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    axs[colnum].yaxis.set_major_formatter(MathTextSciFormatter(\"%1.0e\"))\n",
    "    axs[colnum].xaxis.set_major_formatter(MathTextSciFormatter(\"%1.0e\"))\n",
    "    axs[colnum].set_aspect('equal', 'box')\n",
    "\n",
    "    # annotate with R^2\n",
    "    axs[colnum].text(np.max(df_c.loc[:,YtestDF.columns[ii]])*-0.4, \n",
    "                 np.min(df_c.loc[:,YtestDF.columns[ii]])*0.9, \n",
    "                 r'$r^2$ =' + \n",
    "                 str(np.round((r2_score(df_c.loc[:,YtestDF.columns[ii]],  \n",
    "                                        df_c.loc[:,YpredDF.columns[ii]])), 3)))\n",
    "    axs[colnum].set_xlim([-np.max(np.abs(df_c.loc[:,YpredDF.columns[ii]])), \n",
    "                      np.max(np.abs(df_c.loc[:,YpredDF.columns[ii]]))])\n",
    "    axs[colnum].set_ylim([-np.max(np.abs(df_c.loc[:,YpredDF.columns[ii]])), \n",
    "                  np.max(np.abs(df_c.loc[:,YpredDF.columns[ii]]))])\n",
    "\n",
    "# # residual plots x = predicted, y = actual - predicted\n",
    "# jj is column in dataset, plotNum is plot position\n",
    "for jj, plotNum in enumerate(np.arange(1, df_c.shape[1], 2)):\n",
    "\n",
    "    axs[plotNum].hexbin(y = df_c.loc[:,YtestDF.columns[jj]] - df_c.loc[:,YpredDF.columns[jj]],\n",
    "                   x = df_c.loc[:,YpredDF.columns[jj]], \n",
    "                   gridsize = 50, cmap = cmap) \n",
    "    axs[plotNum].xaxis.set_major_locator(ticker.MaxNLocator(3))\n",
    "    axs[plotNum].yaxis.set_major_locator(ticker.MaxNLocator(3))  \n",
    "    \n",
    "    if jj == 3:\n",
    "        axs[plotNum].set_xlabel(ylabs[jj])\n",
    "    else:\n",
    "        axs[plotNum].set_xlabel(ylabs[jj])\n",
    "    axs[plotNum].yaxis.set_major_formatter(MathTextSciFormatter(\"%1.0e\"))\n",
    "    axs[plotNum].xaxis.set_major_formatter(MathTextSciFormatter(\"%1.0e\"))\n",
    "\n",
    "    if(jj == 0):\n",
    "        axs[plotNum].set_title(\"Actual - Predicted\\n\")\n",
    "\n",
    "    axs[plotNum].hlines(y = 0, xmin = np.min( df_c.loc[:,YpredDF.columns[jj]]), \n",
    "                   xmax = np.max( df_c.loc[:,YpredDF.columns[jj]]), \n",
    "                   linestyle =  \"--\", linewidth = 1)\n",
    "    axs[plotNum].set_ylim([-np.max(np.abs(df_c.loc[:,YtestDF.columns[jj]] - df_c.loc[:,YpredDF.columns[jj]])), \n",
    "                      np.max(np.abs(df_c.loc[:,YtestDF.columns[jj]]- df_c.loc[:,YpredDF.columns[jj]]))])\n",
    "\n",
    "\n",
    "#fig.savefig(os.path.join(figDir, \"PredVActual\" + modelName + \".pdf\"), dpi = 500, bbox_inches='tight')\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train with pruning\n",
    "numCuts = 1\n",
    "\n",
    "wts = model.get_weights()\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    wtLengths.append(np.prod(wts[ii].shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "def prune_percent_updater(x):\n",
    "    logit = np.exp(x*8) / (np.exp(x*8) + 1)\n",
    "    return((logit - 0.5)*2*50)\n",
    "\n",
    "\n",
    "# cuts a smaller portion as the percent gets closer to 100%\n",
    "cutPercent = prune_percent_updater(np.linspace(0, 1, 26))\n",
    "\n",
    "while True:   \n",
    "   \n",
    "    for numEpocs in range(100):\n",
    "        \n",
    "        MSE_tmp = []\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**12, epochs = 1)\n",
    "\n",
    "        \n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "        \n",
    "        # local MSE\n",
    "        MSE_tmp.append(history.history[\"mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 1):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent[numCuts], 50 + cutPercent[numCuts]), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        \n",
    "        # check the change in mean squared error, and if it's not changing much, then cut out more data\n",
    "        # calculate slope of loss, based on previous 5 data points\n",
    "        if numEpocs > 5:\n",
    "            inputData = historyDict[\"mean_squared_error\"][-5:]\n",
    "\n",
    "            m = np.shape(inputData)\n",
    "            X = np.matrix([np.ones(m), np.arange(0, len(inputData))]).T\n",
    "            y = np.matrix(np.log(inputData)).T\n",
    "\n",
    "            # Solve for projection matrix\n",
    "            intercept, slope = np.array(np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)).reshape(-1,)\n",
    "            print(\"change in log loss:\", slope)\n",
    "    \n",
    "            # break if slope has stopped changing or if the overall min has been surpassed\n",
    "            # in the first training, it will automatically prune after 5 epochs, because the min will be passed\n",
    "            if (np.abs(slope) < 0.0001) or (history.history[\"mean_squared_error\"][0] < np.min(historyDict[\"mean_squared_error\"][:-1])): \n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                model.save(os.path.join(figDir,  modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'))\n",
    "                break\n",
    "                       \n",
    "                    \n",
    "    ## refref: may want to save weights before each pruning, so I can go back, if I need to\n",
    "    ## refref: should I be pruning the biases too?\n",
    "    \n",
    "    ## keep running tally of min mse, and if we can't get back to the min, then break\n",
    "#     print(\"Min MSE for this prune \", np.min(MSE_tmp), \"______overall Min MSE \", np.min(historyDict[\"mean_squared_error\"]))\n",
    "#     if np.min(MSE_tmp) > np.min(historyDict[\"mean_squared_error\"]):\n",
    "#         print(\"no more gain by pruning:  STOPPING Pruning\")\n",
    "#         break\n",
    "    \n",
    "    numCuts += 1\n",
    "    if numCuts >= len(cutPercent):\n",
    "        break\n",
    "\n",
    "        \n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "    \n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "    \n",
    "plot_model_history_fromDict(historyDict, saveFig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(historyDict[\"mean_squared_error\"])\n",
    "plt.plot(historyDict[\"val_mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save model\n",
    "model.save(os.path.join(savedModels,  modelName + '.h5'))\n",
    "\n",
    "# save scaler with same name as model\n",
    "scalerfileX = modelName + '_scalerX.pkl'\n",
    "pickle.dump(scalerX, open(os.path.join(dataOutput, scalerfileX), 'wb'))\n",
    "\n",
    "scalerfileY = modelName + '_scalerY.pkl'\n",
    "pickle.dump(scalerY, open(os.path.join(dataOutput, scalerfileY), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if model saved: \n",
    "K.clear_session()\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels,  modelName + '.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wts[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((20,3)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 100)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 100)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(Xtest_scaled, Ytest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (5, 95), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this is the original model\n",
    "inputs = Input(shape=(Xtrain_scaled.shape[1],))\n",
    "x = Dense(400, activation='tanh')(inputs)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(16, activation='tanh')(x)\n",
    "predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics = ['mse'])\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=50, \n",
    "                          verbose=1, mode='auto', min_delta = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "\n",
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (2, 98), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "model.set_weights(wts)\n",
    "\n",
    "\n",
    "# start training\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                    verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                    callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (2.5, 97.5), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "model.set_weights(wts)\n",
    "\n",
    "model.evaluate(Xtest_scaled, Ytest_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history.history['mean_squared_error'])+1),\n",
    "             model_history.history['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "             model_history.history['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE')\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "                   len(model_history.history['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    if saveFig:\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining.png\"), dpi = 120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "plot_model_history(history)\n",
    "print(history.history[\"loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model that was trained for much longer\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels, 'my_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "nzwts = [np.nonzero(wts[ii].reshape(-1))[0] for ii in range(len(wts))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((20,5)) , facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(nzwts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(nzwts[jj].shape))\n",
    "    axs[jj+1].hist(nzwts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(nzwts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((10,10)) , facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n",
    "#fig.savefig(os.path.join(figDir, \"SmallModelResids.png\"), dpi = 120, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim distribution of weights -- cut out middle 20%\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (40, 60), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show new histogram of weights (excluding the 0's)\n",
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array((15, 6)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    \n",
    "    d1 = wts[jj].reshape(-1)\n",
    "    axs[jj].hist(d1[d1!=0], bins = 30, facecolor = '#d6bddb' )\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "\n",
    "    d2 = wts[jj+1]\n",
    "    axs[jj+1].hist(d2[d2!=0], bins = 30, facecolor = '#d6bddb')\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the validation.split is the last X% of the data\n",
    "int(0.3*Xtrain_scaled.shape[0])\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict of hyperparameters\n",
    "\n",
    "\n",
    "# regularization, num layers, num nodes, learning rate, optimizer, activation function, batch size\n",
    "\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Create hyperparameter space\n",
    "NumHiddenLayers = randint(low = 2, high = 20)#[4, 2, 8]\n",
    "numUnits  = [2**4, 2**5, 2**6, 2**7, 2**8, 2**9, 2**10]\n",
    "epochs = [200]\n",
    "batches1 = [2**12, 2**10, 2**8, 2**14] \n",
    "optimizers = ['rmsprop', 'adam']\n",
    "dropout_rate =  uniform(loc = 0, scale = 0.5) #[0.0, 0.2, 0.5]\n",
    "weightRegularization = uniform(loc = 0, scale = 0.001) #[0, 0.0001, 0.001, 0.01]\n",
    "secondToLastUnits = [8, 16, 32, 64]\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(optimizer=optimizers, \n",
    "                        epochs=epochs, \n",
    "                        batch_size=batches1,\n",
    "                        dropout_rate = dropout_rate, \n",
    "                        numUnits = numUnits, \n",
    "                        NumHiddenLayers = NumHiddenLayers, \n",
    "                        weightRegularization = weightRegularization, \n",
    "                        secondToLastUnits = secondToLastUnits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
