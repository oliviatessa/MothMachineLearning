{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callin Switzer\n",
    "### 30 May 2019\n",
    "### eScience Community Seminar Prep"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Outline:\n",
    "\n",
    "- Train full network with 400 units\n",
    "- calculate error on test set\n",
    "    - create error plots\n",
    "** show how well moth can follow trajectory\n",
    "\n",
    "\n",
    "Pt2: \n",
    "Pruning: \n",
    "- train smaller network for demonstration (compare MSE to huge network)\n",
    "- prune smaller network for demonstration\n",
    "\n",
    "Prune larger network\n",
    "-show error on pruned network, compared to smaller network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calli\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow successfully installed.\n",
      "The installed version of TensorFlow includes GPU support.\n",
      "3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)] \n",
      "\n",
      "last run on 2019-06-03 13:22:36.162287\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.colors as colors\n",
    "from  mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "import subprocess\n",
    "import winsound\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow successfully installed.\")\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"The installed version of TensorFlow includes GPU support.\")\n",
    "print(sys.version, \"\\n\")\n",
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))\n",
    "\n",
    "# define directories\n",
    "baseDir = os.getcwd()\n",
    "dataDir = r'D:\\MothSimulations\\11c-AggressiveManeuver\\Qstore\\hws_am_con'\n",
    "figDir = r'D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019'\n",
    "dataOutput = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput'\n",
    "savedModels = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels'\n",
    "randomRawData = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\PythonGeneratedData\\TrainingData'\n",
    "if not os.path.exists(dataOutput):\n",
    "    os.mkdir(dataOutput)\n",
    "if not os.path.exists(figDir):\n",
    "    os.mkdir(figDir)\n",
    "if not os.path.exists(savedModels):\n",
    "    os.mkdir(savedModels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.models import load_model\n",
    "\n",
    "# Keras callcacks\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some functions\n",
    "\n",
    "def format_e(n):\n",
    "    a = '%E' % n\n",
    "    return a.split('E')[0].rstrip('0').rstrip('.') + 'E' + a.split('E')[1]\n",
    "\n",
    "\n",
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        plt.ylim([0.000001, 0.05])\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned_2.png\"), dpi = 120, bbox_inches='tight')\n",
    "        print(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make training and test set"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# concatenate all files (only need to do this once)\n",
    "# it takes a few minutes\n",
    "all_files = glob.glob(os.path.join(randomRawData, \"*.csv\"))     \n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "concatenated_df   = pd.concat(df_from_each_file, ignore_index=True)\n",
    "\n",
    "# check for duplicates\n",
    "concatenated_df.drop_duplicates(inplace=True)\n",
    "concatenated_df.shape\n",
    "\n",
    "print(concatenated_df.shape)\n",
    "concatenated_df.tail()\n",
    "\n",
    "# save to hdf5\n",
    "concatenated_df.to_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "trainDF = pd.read_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: check for repeats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check for repeats!\n",
    "np.sum(trainDF.iloc[:, [16,17,18]].duplicated()) # 0 means no repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9900510, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>xf</th>\n",
       "      <th>xd0</th>\n",
       "      <th>xdf</th>\n",
       "      <th>y0</th>\n",
       "      <th>yf</th>\n",
       "      <th>yd0</th>\n",
       "      <th>ydf</th>\n",
       "      <th>theta0</th>\n",
       "      <th>thetaf</th>\n",
       "      <th>thetad0</th>\n",
       "      <th>thetadf</th>\n",
       "      <th>phi0</th>\n",
       "      <th>phif</th>\n",
       "      <th>phid0</th>\n",
       "      <th>phidf</th>\n",
       "      <th>F</th>\n",
       "      <th>alpha</th>\n",
       "      <th>tau0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.367432</td>\n",
       "      <td>1240.975696</td>\n",
       "      <td>1047.460389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.222497</td>\n",
       "      <td>-321.289498</td>\n",
       "      <td>-38.377027</td>\n",
       "      <td>4.539917</td>\n",
       "      <td>6.334514</td>\n",
       "      <td>5.761704</td>\n",
       "      <td>166.050842</td>\n",
       "      <td>2.909070</td>\n",
       "      <td>4.628560</td>\n",
       "      <td>10.607821</td>\n",
       "      <td>162.092739</td>\n",
       "      <td>29718.210402</td>\n",
       "      <td>3.057406</td>\n",
       "      <td>53852.149654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.768748</td>\n",
       "      <td>-1149.257088</td>\n",
       "      <td>-1075.409015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.106142</td>\n",
       "      <td>365.093207</td>\n",
       "      <td>697.828947</td>\n",
       "      <td>3.243816</td>\n",
       "      <td>4.921125</td>\n",
       "      <td>16.957561</td>\n",
       "      <td>146.364185</td>\n",
       "      <td>3.308109</td>\n",
       "      <td>4.891662</td>\n",
       "      <td>22.615302</td>\n",
       "      <td>141.667777</td>\n",
       "      <td>28169.483755</td>\n",
       "      <td>3.504285</td>\n",
       "      <td>66579.923810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.280989</td>\n",
       "      <td>-1496.313673</td>\n",
       "      <td>-1133.713595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.318522</td>\n",
       "      <td>244.869357</td>\n",
       "      <td>748.985152</td>\n",
       "      <td>5.436117</td>\n",
       "      <td>-0.270820</td>\n",
       "      <td>7.760703</td>\n",
       "      <td>-563.122968</td>\n",
       "      <td>5.548527</td>\n",
       "      <td>-0.137526</td>\n",
       "      <td>0.328348</td>\n",
       "      <td>-561.725041</td>\n",
       "      <td>42042.954099</td>\n",
       "      <td>1.460073</td>\n",
       "      <td>-13638.356558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.931729</td>\n",
       "      <td>-560.948725</td>\n",
       "      <td>-26.956023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.748787</td>\n",
       "      <td>86.858301</td>\n",
       "      <td>45.961219</td>\n",
       "      <td>4.004344</td>\n",
       "      <td>4.826500</td>\n",
       "      <td>-0.067853</td>\n",
       "      <td>72.504068</td>\n",
       "      <td>0.510978</td>\n",
       "      <td>1.423037</td>\n",
       "      <td>24.197259</td>\n",
       "      <td>77.007517</td>\n",
       "      <td>32817.596791</td>\n",
       "      <td>1.943183</td>\n",
       "      <td>-59677.690610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.280447</td>\n",
       "      <td>-214.455052</td>\n",
       "      <td>-539.671502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.707153</td>\n",
       "      <td>225.808462</td>\n",
       "      <td>488.013492</td>\n",
       "      <td>6.129205</td>\n",
       "      <td>4.399997</td>\n",
       "      <td>-16.195650</td>\n",
       "      <td>-177.812751</td>\n",
       "      <td>1.609007</td>\n",
       "      <td>-0.231868</td>\n",
       "      <td>9.118306</td>\n",
       "      <td>-183.140660</td>\n",
       "      <td>35120.738164</td>\n",
       "      <td>3.267484</td>\n",
       "      <td>77836.665059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x0         xf          xd0          xdf   y0         yf         yd0  \\\n",
       "0  0.0  23.367432  1240.975696  1047.460389  0.0  -2.222497 -321.289498   \n",
       "1  0.0 -20.768748 -1149.257088 -1075.409015  0.0  11.106142  365.093207   \n",
       "2  0.0 -25.280989 -1496.313673 -1133.713595  0.0   4.318522  244.869357   \n",
       "3  0.0  -5.931729  -560.948725   -26.956023  0.0   0.748787   86.858301   \n",
       "4  0.0  -9.280447  -214.455052  -539.671502  0.0   6.707153  225.808462   \n",
       "\n",
       "          ydf    theta0    thetaf    thetad0     thetadf      phi0      phif  \\\n",
       "0  -38.377027  4.539917  6.334514   5.761704  166.050842  2.909070  4.628560   \n",
       "1  697.828947  3.243816  4.921125  16.957561  146.364185  3.308109  4.891662   \n",
       "2  748.985152  5.436117 -0.270820   7.760703 -563.122968  5.548527 -0.137526   \n",
       "3   45.961219  4.004344  4.826500  -0.067853   72.504068  0.510978  1.423037   \n",
       "4  488.013492  6.129205  4.399997 -16.195650 -177.812751  1.609007 -0.231868   \n",
       "\n",
       "       phid0       phidf             F     alpha          tau0  \n",
       "0  10.607821  162.092739  29718.210402  3.057406  53852.149654  \n",
       "1  22.615302  141.667777  28169.483755  3.504285  66579.923810  \n",
       "2   0.328348 -561.725041  42042.954099  1.460073 -13638.356558  \n",
       "3  24.197259   77.007517  32817.596791  1.943183 -59677.690610  \n",
       "4   9.118306 -183.140660  35120.738164  3.267484  77836.665059  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trainDF.shape)\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to be consistent with other code\n",
    "trainDF.rename(columns={\"x0\" : \"x_0\", \"y0\" : \"y_0\", \"phi0\" : \"phi_0\", \"theta0\" : \"theta_0\", \n",
    "                        \"xf\" : \"x_99\", \"yf\" : \"y_99\", \"phif\" : \"phi_99\", \"thetaf\" : \"theta_99\", \n",
    "                        \"xd0\" : \"x_dot_0\", \"yd0\" : \"y_dot_0\", \"phid0\" : \"phi_dot_0\", \"thetad0\": \"theta_dot_0\", \n",
    "                        \"xdf\" : \"x_dot_99\", \"ydf\": \"y_dot_99\", \"phidf\": \"phi_dot_99\", \"thetadf\": \"theta_dot_99\", \n",
    "                        \"tau0\" : \"tau\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to fx and fy\n",
    "trainDF[\"Fx\"] = trainDF.F * np.cos(trainDF.alpha)\n",
    "trainDF[\"Fy\"] = trainDF.F * np.sin(trainDF.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phi_0</th>\n",
       "      <th>theta_0</th>\n",
       "      <th>x_99</th>\n",
       "      <th>y_99</th>\n",
       "      <th>phi_99</th>\n",
       "      <th>theta_99</th>\n",
       "      <th>x_dot_0</th>\n",
       "      <th>y_dot_0</th>\n",
       "      <th>phi_dot_0</th>\n",
       "      <th>theta_dot_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.909070</td>\n",
       "      <td>4.539917</td>\n",
       "      <td>23.367432</td>\n",
       "      <td>-2.222497</td>\n",
       "      <td>4.628560</td>\n",
       "      <td>6.334514</td>\n",
       "      <td>1240.975696</td>\n",
       "      <td>-321.289498</td>\n",
       "      <td>10.607821</td>\n",
       "      <td>5.761704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.308109</td>\n",
       "      <td>3.243816</td>\n",
       "      <td>-20.768748</td>\n",
       "      <td>11.106142</td>\n",
       "      <td>4.891662</td>\n",
       "      <td>4.921125</td>\n",
       "      <td>-1149.257088</td>\n",
       "      <td>365.093207</td>\n",
       "      <td>22.615302</td>\n",
       "      <td>16.957561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.548527</td>\n",
       "      <td>5.436117</td>\n",
       "      <td>-25.280989</td>\n",
       "      <td>4.318522</td>\n",
       "      <td>-0.137526</td>\n",
       "      <td>-0.270820</td>\n",
       "      <td>-1496.313673</td>\n",
       "      <td>244.869357</td>\n",
       "      <td>0.328348</td>\n",
       "      <td>7.760703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.510978</td>\n",
       "      <td>4.004344</td>\n",
       "      <td>-5.931729</td>\n",
       "      <td>0.748787</td>\n",
       "      <td>1.423037</td>\n",
       "      <td>4.826500</td>\n",
       "      <td>-560.948725</td>\n",
       "      <td>86.858301</td>\n",
       "      <td>24.197259</td>\n",
       "      <td>-0.067853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.609007</td>\n",
       "      <td>6.129205</td>\n",
       "      <td>-9.280447</td>\n",
       "      <td>6.707153</td>\n",
       "      <td>-0.231868</td>\n",
       "      <td>4.399997</td>\n",
       "      <td>-214.455052</td>\n",
       "      <td>225.808462</td>\n",
       "      <td>9.118306</td>\n",
       "      <td>-16.195650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phi_0   theta_0       x_99       y_99    phi_99  theta_99      x_dot_0  \\\n",
       "0  2.909070  4.539917  23.367432  -2.222497  4.628560  6.334514  1240.975696   \n",
       "1  3.308109  3.243816 -20.768748  11.106142  4.891662  4.921125 -1149.257088   \n",
       "2  5.548527  5.436117 -25.280989   4.318522 -0.137526 -0.270820 -1496.313673   \n",
       "3  0.510978  4.004344  -5.931729   0.748787  1.423037  4.826500  -560.948725   \n",
       "4  1.609007  6.129205  -9.280447   6.707153 -0.231868  4.399997  -214.455052   \n",
       "\n",
       "      y_dot_0  phi_dot_0  theta_dot_0  \n",
       "0 -321.289498  10.607821     5.761704  \n",
       "1  365.093207  22.615302    16.957561  \n",
       "2  244.869357   0.328348     7.760703  \n",
       "3   86.858301  24.197259    -0.067853  \n",
       "4  225.808462   9.118306   -16.195650  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fx</th>\n",
       "      <th>Fy</th>\n",
       "      <th>tau</th>\n",
       "      <th>x_dot_99</th>\n",
       "      <th>y_dot_99</th>\n",
       "      <th>phi_dot_99</th>\n",
       "      <th>theta_dot_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-29612.961122</td>\n",
       "      <td>2498.912376</td>\n",
       "      <td>53852.149654</td>\n",
       "      <td>1047.460389</td>\n",
       "      <td>-38.377027</td>\n",
       "      <td>162.092739</td>\n",
       "      <td>166.050842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-26336.915345</td>\n",
       "      <td>-9994.333651</td>\n",
       "      <td>66579.923810</td>\n",
       "      <td>-1075.409015</td>\n",
       "      <td>697.828947</td>\n",
       "      <td>141.667777</td>\n",
       "      <td>146.364185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4645.636361</td>\n",
       "      <td>41785.500502</td>\n",
       "      <td>-13638.356558</td>\n",
       "      <td>-1133.713595</td>\n",
       "      <td>748.985152</td>\n",
       "      <td>-561.725041</td>\n",
       "      <td>-563.122968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-11940.326951</td>\n",
       "      <td>30568.337400</td>\n",
       "      <td>-59677.690610</td>\n",
       "      <td>-26.956023</td>\n",
       "      <td>45.961219</td>\n",
       "      <td>77.007517</td>\n",
       "      <td>72.504068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-34842.795622</td>\n",
       "      <td>-4409.744037</td>\n",
       "      <td>77836.665059</td>\n",
       "      <td>-539.671502</td>\n",
       "      <td>488.013492</td>\n",
       "      <td>-183.140660</td>\n",
       "      <td>-177.812751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Fx            Fy           tau     x_dot_99    y_dot_99  \\\n",
       "0 -29612.961122   2498.912376  53852.149654  1047.460389  -38.377027   \n",
       "1 -26336.915345  -9994.333651  66579.923810 -1075.409015  697.828947   \n",
       "2   4645.636361  41785.500502 -13638.356558 -1133.713595  748.985152   \n",
       "3 -11940.326951  30568.337400 -59677.690610   -26.956023   45.961219   \n",
       "4 -34842.795622  -4409.744037  77836.665059  -539.671502  488.013492   \n",
       "\n",
       "   phi_dot_99  theta_dot_99  \n",
       "0  162.092739    166.050842  \n",
       "1  141.667777    146.364185  \n",
       "2 -561.725041   -563.122968  \n",
       "3   77.007517     72.504068  \n",
       "4 -183.140660   -177.812751  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data \n",
    "scalerX = MinMaxScaler([-0.5, 0.5])  \n",
    "scalerY = MinMaxScaler([-0.5, 0.5])  \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phi_0</th>\n",
       "      <th>theta_0</th>\n",
       "      <th>x_99</th>\n",
       "      <th>y_99</th>\n",
       "      <th>phi_99</th>\n",
       "      <th>theta_99</th>\n",
       "      <th>x_dot_0</th>\n",
       "      <th>y_dot_0</th>\n",
       "      <th>phi_dot_0</th>\n",
       "      <th>theta_dot_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.479611</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>-0.318639</td>\n",
       "      <td>-0.229442</td>\n",
       "      <td>-0.094704</td>\n",
       "      <td>0.071486</td>\n",
       "      <td>-0.491811</td>\n",
       "      <td>-0.220474</td>\n",
       "      <td>0.168732</td>\n",
       "      <td>0.450440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.453551</td>\n",
       "      <td>0.264615</td>\n",
       "      <td>0.295886</td>\n",
       "      <td>0.197180</td>\n",
       "      <td>-0.188053</td>\n",
       "      <td>0.054898</td>\n",
       "      <td>0.469097</td>\n",
       "      <td>0.195148</td>\n",
       "      <td>0.353807</td>\n",
       "      <td>-0.446865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.102133</td>\n",
       "      <td>-0.139825</td>\n",
       "      <td>0.314624</td>\n",
       "      <td>0.345313</td>\n",
       "      <td>-0.234415</td>\n",
       "      <td>-0.252743</td>\n",
       "      <td>0.486725</td>\n",
       "      <td>0.399421</td>\n",
       "      <td>0.036643</td>\n",
       "      <td>-0.265189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.025410</td>\n",
       "      <td>0.473391</td>\n",
       "      <td>-0.026110</td>\n",
       "      <td>0.073530</td>\n",
       "      <td>0.050494</td>\n",
       "      <td>0.209861</td>\n",
       "      <td>-0.032577</td>\n",
       "      <td>-0.026313</td>\n",
       "      <td>-0.037384</td>\n",
       "      <td>-0.004011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.492691</td>\n",
       "      <td>-0.269698</td>\n",
       "      <td>-0.131405</td>\n",
       "      <td>0.348033</td>\n",
       "      <td>0.118454</td>\n",
       "      <td>-0.135028</td>\n",
       "      <td>-0.191459</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>-0.416592</td>\n",
       "      <td>-0.057925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phi_0   theta_0      x_99      y_99    phi_99  theta_99   x_dot_0  \\\n",
       "0 -0.479611  0.002266 -0.318639 -0.229442 -0.094704  0.071486 -0.491811   \n",
       "1 -0.453551  0.264615  0.295886  0.197180 -0.188053  0.054898  0.469097   \n",
       "2 -0.102133 -0.139825  0.314624  0.345313 -0.234415 -0.252743  0.486725   \n",
       "3 -0.025410  0.473391 -0.026110  0.073530  0.050494  0.209861 -0.032577   \n",
       "4  0.492691 -0.269698 -0.131405  0.348033  0.118454 -0.135028 -0.191459   \n",
       "\n",
       "    y_dot_0  phi_dot_0  theta_dot_0  \n",
       "0 -0.220474   0.168732     0.450440  \n",
       "1  0.195148   0.353807    -0.446865  \n",
       "2  0.399421   0.036643    -0.265189  \n",
       "3 -0.026313  -0.037384    -0.004011  \n",
       "4  0.408163  -0.416592    -0.057925  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Xtrain_scaled, columns = X.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scalers, to be used on test set\n",
    "scalerfileX = 'scalerX.pkl'\n",
    "pickle.dump(scalerX, open(os.path.join(dataOutput, scalerfileX), 'wb'))\n",
    "\n",
    "scalerfileY = 'scalerY.pkl'\n",
    "pickle.dump(scalerY, open(os.path.join(dataOutput, scalerfileY), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#model.get_config()\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=150, \n",
    "                          verbose=1, mode='auto', min_delta = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: start with small network and then build up\n",
    "# refref: start with large network and prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network\n",
    "def create_network(optimizer = 'rmsprop', \n",
    "                    numUnits = [32, 32, 32, 32], \n",
    "                    weightRegularization = 0.0, \n",
    "                    dropout_rate=0.1):\n",
    "    \n",
    "    '''\n",
    "    Create a feed forward network.  Assumes Xtrain & Ytrain have been created and scaled\n",
    "    \n",
    "    Params: \n",
    "    optimizer (str): choice of optimizer\n",
    "    numUnits (list): number of units in each hidden\n",
    "    weightRegularization (float): between 0 and 1\n",
    "    dropout_rate (float): between 0 and 1\n",
    "    \n",
    "    '''\n",
    "    K.clear_session()\n",
    "    inputs = Input(shape=(Xtrain_scaled.shape[1],))    \n",
    "    \n",
    "    # add layers\n",
    "    for ii in np.arange(0, len(numUnits)):\n",
    "        if ii >= 1: \n",
    "            x = Dense(numUnits[ii], activation='tanh', \n",
    "                      kernel_regularizer=regularizers.l1(weightRegularization))(x)\n",
    "\n",
    "        else: \n",
    "            x = Dense(numUnits[ii], activation='tanh')(inputs)\n",
    "\n",
    "\n",
    "        # add dropout\n",
    "        if dropout_rate > 0: \n",
    "            x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "    # create model\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer = optimizer, metrics = ['mse'])\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "\n",
    "# model = load_model(r\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels\\Opt_rmsprop__Dro_0.0__Num_400_400_400_16__Wei_0.0.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelParams = {\"optimizer\": \"rmsprop\", \n",
    "              \"dropout_rate\" : 0, \n",
    "               \"numUnits\": [400, 400, 400, 16],\n",
    "               \"weightRegularization\": 0\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "model = create_network(**modelParams)\n",
    "\n",
    "modelName = ''.join('{}_{}__'.format(key[0:3].capitalize(), val) for  key, val in modelParams.items()).replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \"_\")[0:-2]+ \"_\" + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\")\n",
    "print(modelName)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show random weight matrices\n",
    "# show images for matrices\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2-5:256//2+5, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 200, 400])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 413])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"RandomWeightMatrices\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "historyDict = {\"mean_squared_error\": [], \n",
    "               \"val_mean_squared_error\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=15, \n",
    "                          verbose=1, mode='auto', min_delta = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit model without regularization\n",
    "stt = time.time()\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 1000, verbose = 2, \n",
    "                        batch_size=2**14, callbacks = [earlystop], validation_split = 0.3)\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)\n",
    "endd = time.time() - stt\n",
    "print(endd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historyDict[\"mean_squared_error\"].extend(history.history[\"mean_squared_error\"][0:])\n",
    "historyDict[\"val_mean_squared_error\"].extend(history.history[\"val_mean_squared_error\"][0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: save history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        plt.ylim([0.0001, 0.05])\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_NOTpruned_2.png\"), dpi = 120, bbox_inches='tight')\n",
    "        print(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "    \n",
    "plot_model_history_fromDict(historyDict, saveFig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "# if I need to remake, use this\n",
    "# wtsPath = \"D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019\\Opt_rmsprop__Dro_0__Num_400_400_400_16__Wei_0_2019_05_30__11_59_54_wts.pkl\"\n",
    "# wts =  pickle.load(open(wtsPath, 'rb'))\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2 + 1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 200, 400])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 413])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"TrainedWeightMatrices\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# refref: plot predictions on test set and make figures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "# apply same transformation to test data\n",
    "# Xtest_scaled = scalerX.transform(Xtest)\n",
    "# Ytest_scaled = scalerY.transform(Ytest)\n",
    "\n",
    "\n",
    "Ytest_pred = model.predict(Xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]\n",
    "\n",
    "\n",
    "# make data frames\n",
    "XtestDF = pd.DataFrame(scalerX.inverse_transform(Xtest_scaled), columns = X.columns)\n",
    "YtestDF = pd.DataFrame(scalerY.inverse_transform(Ytest_scaled), columns = Y.columns)\n",
    "YpredDF = pd.DataFrame(scalerY.inverse_transform(Ytest_pred), columns = Y.columns+ \"_pred\")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df_c = pd.concat([YtestDF.reset_index(drop=True), YpredDF], axis=1)\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_c = df_c[0:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array([30, 10]) / 1.3, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.2, wspace=0.7)\n",
    "#fig.suptitle('Predicted vs. acutal ', fontsize=14, fontweight='bold')\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "ylabs = [r\"g*cm/$s^2$\", r\"g*cm/$s^2$\", r\"g*$cm^2$/$s^2$\", \"cm/s\", \"cm/s\", \"rad/s\", \"rad/s\"]\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(df_c.shape[1] //2):\n",
    "    try:\n",
    "        axs[ii].hexbin(y = df_c.iloc[:,ii],x = df_c.iloc[:,ii + 7], gridsize = 50, cmap = cmap)\n",
    "        #axs[ii].set_xlabel(\"Predicted Value\\n(unscaled)\")\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\\n\" + ylabs[ii])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[ii])\n",
    "        axs[ii].set_title(df_c.columns[ii])\n",
    "        axs[ii].plot(df_c.iloc[:,ii], df_c.iloc[:,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "        \n",
    "        # annotate with R^2\n",
    "        axs[ii].text(np.max(df_c.iloc[:,ii])*0.1, np.min(df_c.iloc[:,ii])*0.9, r'$r^2$ =' + str(np.round((r2_score(df_c.iloc[:,ii ],  df_c.iloc[:,ii+7])), 3)))\n",
    "        axs[ii].set_xlim([-np.max(np.abs(df_c.iloc[:,ii+7])), np.max(np.abs(df_c.iloc[:,ii+7]))])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# # residual plots x = predicted, y = actual - predicted\n",
    "for jj in range(df_c.shape[1] //2):\n",
    "    \n",
    "    ii = jj + 7\n",
    "    try:\n",
    "        axs[ii].hexbin(x = df_c.iloc[:,jj],\n",
    "                     y = df_c.iloc[:,jj ] - df_c.iloc[:,jj+7], gridsize = (35, 50), cmap = cmap)\n",
    "        axs[ii].set_xlabel(\"Predicted Value\")\n",
    "\n",
    "        if(jj == 0):\n",
    "            axs[ii].set_ylabel(\"Actual - Predicted\\n\" + ylabs[jj])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[jj])\n",
    "        \n",
    "        axs[ii].hlines(y = 0, xmin = np.min( df_c.iloc[:,jj+7]), \n",
    "                       xmax = np.max( df_c.iloc[:,jj+7]), linestyle =  \"--\", linewidth = 1)\n",
    "        axs[ii].set_ylim([-np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7])), np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7]))])\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "fig.savefig(os.path.join(figDir, \"PredVActual_\" + modelName + \".png\"), dpi = 500, bbox_inches='tight')\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#(y_true, y_pred, sample_weight=None, multioutput=uniform_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save model\n",
    "model.save(os.path.join(figDir,  modelName + '_notPruned.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_wts.pkl'\n",
    "pickle.dump(wts, open(os.path.join(figDir, wtsFile), 'wb'))\n",
    "\n",
    "# save history\n",
    "histName = modelName + '_history.pkl'\n",
    "pickle.dump(historyDict, open(os.path.join(figDir, histName), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jj in range(7):\n",
    "    print (r2_score(df_c.iloc[:,jj ],  df_c.iloc[:,jj+7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## START NEW ITEM: train and trim weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and trim weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "#wts =  pickle.load(open(os.path.join(dataOutput, wtsFile), 'rb'))\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    print(wts[ii].shape)\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # start training\n",
    "# historyDict = {\"mean_squared_error\": [], \n",
    "#                \"val_mean_squared_error\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start pruning\n",
    "modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numCuts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: \n",
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "def prune_percent_updater(x):\n",
    "    logit = np.exp(x*8) / (np.exp(x*8) + 1)\n",
    "    return((logit - 0.5)*2*50)\n",
    "\n",
    "\n",
    "# cuts a smaller portion as the percent gets closer to 100%\n",
    "cutPercent = prune_percent_updater(np.linspace(0, 1, 26))\n",
    "\n",
    "while True:   \n",
    "   \n",
    "    for numEpocs in range(100):\n",
    "        \n",
    "        MSE_tmp = []\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                            callbacks = [earlystop])\n",
    "        \n",
    "        # refref: earlystop doesn't do anything here\n",
    "        \n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "        \n",
    "        # local MSE\n",
    "        MSE_tmp.append(history.history[\"mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 1):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent[numCuts], 50 + cutPercent[numCuts]), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        \n",
    "        # check the change in mean squared error, and if it's not changing much, then cut out more data\n",
    "        # calculate slope of loss, based on previous 5 data points\n",
    "        if numEpocs > 5:\n",
    "            inputData = historyDict[\"mean_squared_error\"][-5:]\n",
    "\n",
    "            m = np.shape(inputData)\n",
    "            X = np.matrix([np.ones(m), np.arange(0, len(inputData))]).T\n",
    "            y = np.matrix(np.log(inputData)).T\n",
    "\n",
    "            # Solve for projection matrix\n",
    "            intercept, slope = np.array(np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)).reshape(-1,)\n",
    "            print(\"change in log loss:\", slope)\n",
    "    \n",
    "            # break if slope has stopped changing or if the overall min has been surpassed\n",
    "            # in the first training, it will automatically prune after 5 epochs, because the min will be passed\n",
    "            if (np.abs(slope) < 0.0001) or (history.history[\"mean_squared_error\"][0] < np.min(historyDict[\"mean_squared_error\"][:-1])): \n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                model.save(os.path.join(figDir,  modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'))\n",
    "                break\n",
    "                       \n",
    "                    \n",
    "    ## refref: may want to save weights before each pruning, so I can go back, if I need to\n",
    "    ## refref: should I be pruning the biases too?\n",
    "    \n",
    "    ## keep running tally of min mse, and if we can't get back to the min, then break\n",
    "#     print(\"Min MSE for this prune \", np.min(MSE_tmp), \"______overall Min MSE \", np.min(historyDict[\"mean_squared_error\"]))\n",
    "#     if np.min(MSE_tmp) > np.min(historyDict[\"mean_squared_error\"]):\n",
    "#         print(\"no more gain by pruning:  STOPPING Pruning\")\n",
    "#         break\n",
    "    \n",
    "    numCuts += 1\n",
    "    if numCuts >= len(cutPercent):\n",
    "        break\n",
    "\n",
    "        \n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numCuts)\n",
    "(50 - cutPercent[numCuts]) * 2 # percent of original network size that is used the pruned version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save model\n",
    "model.save(os.path.join(figDir,  modelName + '_Pruned.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_wts_pruned.pkl'\n",
    "pickle.dump(wts, open(os.path.join(figDir, wtsFile), 'wb'))\n",
    "\n",
    "# save history\n",
    "histName = modelName + '_history_pruned.pkl'\n",
    "pickle.dump(historyDict, open(os.path.join(figDir, histName), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numCuts = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        plt.ylim([0.0001, 0.05])\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"), dpi = 120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "    \n",
    "plot_model_history_fromDict(historyDict, saveFig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(dictLen).zfill(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video of training\n",
    "tmpDir = os.path.join(figDir, \"tmpImgs\")\n",
    "if not os.path.exists(tmpDir):\n",
    "    os.mkdir(tmpDir)\n",
    "fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "#for dictLen in np.arange(1, len(historyDict[\"mean_squared_error\"])):\n",
    "for dictLen in range(300):\n",
    "\n",
    "    # save images\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(historyDict['mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "             historyDict['mean_squared_error'][dictLen-1:dictLen])\n",
    "    axs.plot(range(1,len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "             historyDict['val_mean_squared_error'][dictLen-1:dictLen])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(historyDict['val_mean_squared_error'][dictLen])))\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "#     axs.set_xticks(np.arange(1,len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "#                    len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])//10)\n",
    "    axs.legend(['train', 'val'], loc='lower left')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "\n",
    "    plt.ylim([0.0001, 0.05])\n",
    "    fig.savefig(os.path.join(tmpDir, str(dictLen).zfill(4)+ \".png\"), dpi = 120,  pad_inches = 0.5)\n",
    "    #plt.close()\n",
    "    \n",
    "    if np.mod(dictLen, 100) == 0:\n",
    "        print(dictLen)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video of training\n",
    "tmpDir = os.path.join(figDir, \"tmpImgs\")\n",
    "if not os.path.exists(tmpDir):\n",
    "    os.mkdir(tmpDir)\n",
    "fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "for dictLen in np.arange(1, len(historyDict[\"mean_squared_error\"])):\n",
    "#for dictLen in np.arange(1, 100):\n",
    "\n",
    "    # save images\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    axs.plot([dictLen -1, dictLen],\n",
    "             historyDict['mean_squared_error'][dictLen-1:dictLen+1], c= \"C0\")\n",
    "    axs.plot([dictLen -1, dictLen],\n",
    "             historyDict['val_mean_squared_error'][dictLen-1:dictLen+1], c= \"C1\")\n",
    "    axs.set_title('Model MSE = '+ str(format_e(historyDict['val_mean_squared_error'][dictLen])))\n",
    "    axs.set_ylabel('mean squared error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "#     axs.set_xticks(np.arange(1,len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "#                    len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])//10)\n",
    "    axs.legend(['train', 'val'], loc='lower left')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "\n",
    "    plt.ylim([0.0001, 0.05])\n",
    "    fig.savefig(os.path.join(tmpDir, str(dictLen).zfill(4)+ \".png\"), dpi = 120,  pad_inches = 0.5)\n",
    "    #plt.close()\n",
    "    #plt.show()\n",
    "    \n",
    "    if np.mod(dictLen, 100) == 0:\n",
    "        print(dictLen)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make into video\n",
    "os.chdir(tmpDir)\n",
    "\n",
    "os.system('ffmpeg -start_number 0   -r 50 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264 -b:v 10000k  -pix_fmt yuv420p -y  0000000_output_epochs.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest_pred = model.predict(Xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data frames\n",
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]\n",
    "\n",
    "XtestDF = pd.DataFrame(scalerX.inverse_transform(Xtest_scaled), columns = X.columns)\n",
    "YtestDF = pd.DataFrame(scalerY.inverse_transform(Ytest_scaled), columns = Y.columns)\n",
    "YpredDF = pd.DataFrame(scalerY.inverse_transform(Ytest_pred), columns = Y.columns+ \"_pred\")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df_c = pd.concat([YtestDF.reset_index(drop=True), YpredDF], axis=1)\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(historyDict[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = df_c.iloc[0:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array([30, 10]) / 1.3, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.2, wspace=0.7)\n",
    "#fig.suptitle('Predicted vs. acutal ', fontsize=14, fontweight='bold')\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "ylabs = [r\"g*cm/$s^2$\", r\"g*cm/$s^2$\", r\"g*$cm^2$/$s^2$\", \"cm/s\", \"cm/s\", \"rad/s\", \"rad/s\"]\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(df_c.shape[1] //2):\n",
    "    try:\n",
    "        axs[ii].hexbin(y = df_c.iloc[:,ii],x = df_c.iloc[:,ii + 7], gridsize = 50, cmap = cmap)\n",
    "        #axs[ii].set_xlabel(\"Predicted Value\\n(unscaled)\")\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\\n\" + ylabs[ii])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[ii])\n",
    "        axs[ii].set_title(df_c.columns[ii])\n",
    "        axs[ii].plot(df_c.iloc[:,ii], df_c.iloc[:,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "        \n",
    "        # annotate with R^2\n",
    "        axs[ii].text(np.max(df_c.iloc[:,ii])*0.1, np.min(df_c.iloc[:,ii])*0.9, r'$r^2$ =' + str(np.round((r2_score(df_c.iloc[:,ii ],  df_c.iloc[:,ii+7])), 3)))\n",
    "        axs[ii].set_xlim([-np.max(np.abs(df_c.iloc[:,ii+7])), np.max(np.abs(df_c.iloc[:,ii+7]))])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# # residual plots x = predicted, y = actual - predicted\n",
    "for jj in range(df_c.shape[1] //2):\n",
    "    \n",
    "    ii = jj + 7\n",
    "    try:\n",
    "        axs[ii].hexbin(x = df_c.iloc[:,jj],\n",
    "                     y = df_c.iloc[:,jj ] - df_c.iloc[:,jj+7], gridsize = (35, 50), cmap = cmap)\n",
    "        axs[ii].set_xlabel(\"Predicted Value\")\n",
    "\n",
    "        if(jj == 0):\n",
    "            axs[ii].set_ylabel(\"Actual - Predicted\\n\" + ylabs[jj])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[jj])\n",
    "        \n",
    "        axs[ii].hlines(y = 0, xmin = np.min( df_c.iloc[:,jj+7]), \n",
    "                       xmax = np.max( df_c.iloc[:,jj+7]), linestyle =  \"--\", linewidth = 1)\n",
    "        axs[ii].set_ylim([-np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7])), np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7]))])\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "fig.savefig(os.path.join(figDir, \"PredVActual_\" + str(len(historyDict[\"mean_squared_error\"])) +  modelName + \".png\"), dpi = 500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2+1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 200, 400])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 413])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"Pruned_WeightMatrices\" + str(len(historyDict[\"mean_squared_error\"]))  + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show example small network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt_rmsprop__Dro_0__Num_20_20_16__Wei_0_2019_06_03__14_47_14\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 119       \n",
      "=================================================================\n",
      "Total params: 1,095\n",
      "Trainable params: 1,095\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelParams = {\"optimizer\": \"rmsprop\", \n",
    "              \"dropout_rate\" : 0, \n",
    "               \"numUnits\": [20, 20, 16],\n",
    "               \"weightRegularization\": 0\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "model = create_network(**modelParams)\n",
    "\n",
    "modelName = ''.join('{}_{}__'.format(key[0:3].capitalize(), val) for  key, val in modelParams.items()).replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \"_\")[0:-2]+ \"_\" + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\")\n",
    "print(modelName)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveWeightImages(model, ctr):\n",
    "    \n",
    "    wts = model.get_weights().copy()\n",
    "    for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "\n",
    "        if len(wts[ii].shape) < 2: \n",
    "            wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "        else:\n",
    "            wtsTmp = wts[ii].copy()\n",
    "\n",
    "        im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                                  vmin=-3.0, vmax=3.0))\n",
    "\n",
    "\n",
    "        if np.mod(ii+1, 2) == 0:\n",
    "            axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 1])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "\n",
    "\n",
    "\n",
    "        if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 21])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            #axs[jj].axis('off')\n",
    "\n",
    "\n",
    "        if ii == 7:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([0])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "\n",
    "        if ii == 0:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "    cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "    cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "\n",
    "\n",
    "    plt.savefig(os.path.join(figDir, tmpFolder, str(ctr).zfill(4) + \"_\" + modelName  + \".png\"), dpi = 120, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1757609cfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "PRGn = cm.get_cmap('PRGn', 256)\n",
    "newcolors = PRGn(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2 + 1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "tmpFolder = \"smallNetworkTraingingPruning\"\n",
    "\n",
    "if not os.path.exists(os.path.join(figDir, tmpFolder)):\n",
    "    os.mkdir(os.path.join(figDir, tmpFolder))\n",
    "saveWeightImages(model, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20)\n",
      "(20,)\n",
      "(20, 20)\n",
      "(20,)\n",
      "(20, 16)\n",
      "(16,)\n",
      "(16, 7)\n",
      "(7,)\n",
      "1095 total weights\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "historyDict = {\"mean_squared_error\": [], \n",
    "               \"val_mean_squared_error\": []}\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    print(wts[ii].shape)\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "ctr = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0255 - mean_squared_error: 0.0255 - val_loss: 0.0218 - val_mean_squared_error: 0.0218\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0196 - mean_squared_error: 0.0196 - val_loss: 0.0172 - val_mean_squared_error: 0.0172\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0158 - mean_squared_error: 0.0158 - val_loss: 0.0151 - val_mean_squared_error: 0.0151\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0145 - mean_squared_error: 0.0145 - val_loss: 0.0147 - val_mean_squared_error: 0.0147\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0141 - mean_squared_error: 0.0141 - val_loss: 0.0142 - val_mean_squared_error: 0.0142\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0139 - mean_squared_error: 0.0139 - val_loss: 0.0136 - val_mean_squared_error: 0.0136\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0137 - mean_squared_error: 0.0137 - val_loss: 0.0140 - val_mean_squared_error: 0.0140\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0135 - mean_squared_error: 0.0135 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0134 - mean_squared_error: 0.0134 - val_loss: 0.0136 - val_mean_squared_error: 0.0136\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0133 - mean_squared_error: 0.0133 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0132 - mean_squared_error: 0.0132 - val_loss: 0.0132 - val_mean_squared_error: 0.0132\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0131 - mean_squared_error: 0.0131 - val_loss: 0.0128 - val_mean_squared_error: 0.0128\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0130 - mean_squared_error: 0.0130 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0129 - mean_squared_error: 0.0129 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0128 - mean_squared_error: 0.0128 - val_loss: 0.0134 - val_mean_squared_error: 0.0134\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0127 - mean_squared_error: 0.0127 - val_loss: 0.0135 - val_mean_squared_error: 0.0135\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0126 - mean_squared_error: 0.0126 - val_loss: 0.0130 - val_mean_squared_error: 0.0130\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0125 - mean_squared_error: 0.0125 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0123 - mean_squared_error: 0.0123 - val_loss: 0.0127 - val_mean_squared_error: 0.0127\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0122 - mean_squared_error: 0.0122 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0120 - mean_squared_error: 0.0120 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0118 - mean_squared_error: 0.0118 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0117 - mean_squared_error: 0.0117 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0116 - mean_squared_error: 0.0116 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0109 - mean_squared_error: 0.0109 - val_loss: 0.0106 - val_mean_squared_error: 0.0106\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0103 - mean_squared_error: 0.0103 - val_loss: 0.0102 - val_mean_squared_error: 0.0102\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0101 - val_mean_squared_error: 0.0101\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0099 - mean_squared_error: 0.0099 - val_loss: 0.0097 - val_mean_squared_error: 0.0097\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0096 - mean_squared_error: 0.0096 - val_loss: 0.0094 - val_mean_squared_error: 0.0094\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0092 - val_mean_squared_error: 0.0092\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0085 - mean_squared_error: 0.0085 - val_loss: 0.0080 - val_mean_squared_error: 0.0080\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0070 - val_mean_squared_error: 0.0070\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0056 - val_mean_squared_error: 0.0056\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0040 - val_mean_squared_error: 0.0040\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0018 - val_mean_squared_error: 0.0018\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 9.9342e-04 - val_mean_squared_error: 9.9342e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 9.4767e-04 - val_mean_squared_error: 9.4767e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 8.5391e-04 - val_mean_squared_error: 8.5391e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 9.1206e-04 - val_mean_squared_error: 9.1206e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 8.4626e-04 - val_mean_squared_error: 8.4626e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 9.9549e-04 - mean_squared_error: 9.9549e-04 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 9.8916e-04 - mean_squared_error: 9.8916e-04 - val_loss: 9.6453e-04 - val_mean_squared_error: 9.6453e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 9.8329e-04 - mean_squared_error: 9.8329e-04 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 9.7684e-04 - mean_squared_error: 9.7684e-04 - val_loss: 8.9928e-04 - val_mean_squared_error: 8.9928e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 9.7029e-04 - mean_squared_error: 9.7029e-04 - val_loss: 8.5352e-04 - val_mean_squared_error: 8.5352e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 9.6734e-04 - mean_squared_error: 9.6734e-04 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 9.5933e-04 - mean_squared_error: 9.5933e-04 - val_loss: 9.8241e-04 - val_mean_squared_error: 9.8241e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 9.5561e-04 - mean_squared_error: 9.5561e-04 - val_loss: 9.1661e-04 - val_mean_squared_error: 9.1661e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 9.4850e-04 - mean_squared_error: 9.4850e-04 - val_loss: 8.6422e-04 - val_mean_squared_error: 8.6422e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 9.3949e-04 - mean_squared_error: 9.3949e-04 - val_loss: 8.6099e-04 - val_mean_squared_error: 8.6099e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 9.4021e-04 - mean_squared_error: 9.4021e-04 - val_loss: 9.1830e-04 - val_mean_squared_error: 9.1830e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 9.3502e-04 - mean_squared_error: 9.3502e-04 - val_loss: 8.5179e-04 - val_mean_squared_error: 8.5179e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 9.2864e-04 - mean_squared_error: 9.2864e-04 - val_loss: 9.0087e-04 - val_mean_squared_error: 9.0087e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 9.2086e-04 - mean_squared_error: 9.2086e-04 - val_loss: 9.6007e-04 - val_mean_squared_error: 9.6007e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 9.1977e-04 - mean_squared_error: 9.1977e-04 - val_loss: 9.4841e-04 - val_mean_squared_error: 9.4841e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 9.1302e-04 - mean_squared_error: 9.1302e-04 - val_loss: 8.4867e-04 - val_mean_squared_error: 8.4867e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 9.0857e-04 - mean_squared_error: 9.0857e-04 - val_loss: 9.1920e-04 - val_mean_squared_error: 9.1920e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 9.0184e-04 - mean_squared_error: 9.0184e-04 - val_loss: 8.9932e-04 - val_mean_squared_error: 8.9932e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.9768e-04 - mean_squared_error: 8.9768e-04 - val_loss: 9.3212e-04 - val_mean_squared_error: 9.3212e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.9420e-04 - mean_squared_error: 8.9420e-04 - val_loss: 8.9773e-04 - val_mean_squared_error: 8.9773e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.8826e-04 - mean_squared_error: 8.8826e-04 - val_loss: 8.3025e-04 - val_mean_squared_error: 8.3025e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 8.8340e-04 - mean_squared_error: 8.8340e-04 - val_loss: 8.7686e-04 - val_mean_squared_error: 8.7686e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 8.7833e-04 - mean_squared_error: 8.7833e-04 - val_loss: 7.9204e-04 - val_mean_squared_error: 7.9204e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 8.7383e-04 - mean_squared_error: 8.7383e-04 - val_loss: 8.5833e-04 - val_mean_squared_error: 8.5833e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 8.7106e-04 - mean_squared_error: 8.7106e-04 - val_loss: 8.1506e-04 - val_mean_squared_error: 8.1506e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 8.6649e-04 - mean_squared_error: 8.6649e-04 - val_loss: 9.5131e-04 - val_mean_squared_error: 9.5131e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.6235e-04 - mean_squared_error: 8.6235e-04 - val_loss: 8.6954e-04 - val_mean_squared_error: 8.6954e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 8.5671e-04 - mean_squared_error: 8.5671e-04 - val_loss: 9.0197e-04 - val_mean_squared_error: 9.0197e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 8.5342e-04 - mean_squared_error: 8.5342e-04 - val_loss: 9.0059e-04 - val_mean_squared_error: 9.0059e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.4849e-04 - mean_squared_error: 8.4849e-04 - val_loss: 8.3623e-04 - val_mean_squared_error: 8.3623e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 8.4407e-04 - mean_squared_error: 8.4407e-04 - val_loss: 7.3771e-04 - val_mean_squared_error: 7.3771e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 8.3801e-04 - mean_squared_error: 8.3801e-04 - val_loss: 7.7683e-04 - val_mean_squared_error: 7.7683e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.3685e-04 - mean_squared_error: 8.3685e-04 - val_loss: 6.9209e-04 - val_mean_squared_error: 6.9209e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.3152e-04 - mean_squared_error: 8.3152e-04 - val_loss: 7.5114e-04 - val_mean_squared_error: 7.5114e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 8.2858e-04 - mean_squared_error: 8.2858e-04 - val_loss: 8.5141e-04 - val_mean_squared_error: 8.5141e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 8.2432e-04 - mean_squared_error: 8.2432e-04 - val_loss: 8.3575e-04 - val_mean_squared_error: 8.3575e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 8.1985e-04 - mean_squared_error: 8.1985e-04 - val_loss: 7.5449e-04 - val_mean_squared_error: 7.5449e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.1515e-04 - mean_squared_error: 8.1515e-04 - val_loss: 8.2815e-04 - val_mean_squared_error: 8.2815e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 8.1083e-04 - mean_squared_error: 8.1083e-04 - val_loss: 8.1978e-04 - val_mean_squared_error: 8.1978e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 8.0927e-04 - mean_squared_error: 8.0927e-04 - val_loss: 7.5576e-04 - val_mean_squared_error: 7.5576e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 8.0506e-04 - mean_squared_error: 8.0506e-04 - val_loss: 8.4564e-04 - val_mean_squared_error: 8.4564e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.0040e-04 - mean_squared_error: 8.0040e-04 - val_loss: 7.8355e-04 - val_mean_squared_error: 7.8355e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 7.9859e-04 - mean_squared_error: 7.9859e-04 - val_loss: 7.2997e-04 - val_mean_squared_error: 7.2997e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.9399e-04 - mean_squared_error: 7.9399e-04 - val_loss: 8.2617e-04 - val_mean_squared_error: 8.2617e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 7.8923e-04 - mean_squared_error: 7.8923e-04 - val_loss: 8.7097e-04 - val_mean_squared_error: 8.7097e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 7.8658e-04 - mean_squared_error: 7.8658e-04 - val_loss: 6.8004e-04 - val_mean_squared_error: 6.8004e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.8407e-04 - mean_squared_error: 7.8407e-04 - val_loss: 7.1967e-04 - val_mean_squared_error: 7.1967e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.8031e-04 - mean_squared_error: 7.8031e-04 - val_loss: 7.4578e-04 - val_mean_squared_error: 7.4578e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 7.7539e-04 - mean_squared_error: 7.7539e-04 - val_loss: 7.3681e-04 - val_mean_squared_error: 7.3681e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.7389e-04 - mean_squared_error: 7.7389e-04 - val_loss: 6.4120e-04 - val_mean_squared_error: 6.4120e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.6819e-04 - mean_squared_error: 7.6819e-04 - val_loss: 8.2827e-04 - val_mean_squared_error: 8.2827e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.6649e-04 - mean_squared_error: 7.6649e-04 - val_loss: 8.3665e-04 - val_mean_squared_error: 8.3665e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.6380e-04 - mean_squared_error: 7.6380e-04 - val_loss: 7.3680e-04 - val_mean_squared_error: 7.3680e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 7.6004e-04 - mean_squared_error: 7.6004e-04 - val_loss: 7.5835e-04 - val_mean_squared_error: 7.5835e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 7.5676e-04 - mean_squared_error: 7.5676e-04 - val_loss: 7.3800e-04 - val_mean_squared_error: 7.3800e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 7.5289e-04 - mean_squared_error: 7.5289e-04 - val_loss: 7.7385e-04 - val_mean_squared_error: 7.7385e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 7.4882e-04 - mean_squared_error: 7.4882e-04 - val_loss: 7.2134e-04 - val_mean_squared_error: 7.2134e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 7.4858e-04 - mean_squared_error: 7.4858e-04 - val_loss: 7.1468e-04 - val_mean_squared_error: 7.1468e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 7.4544e-04 - mean_squared_error: 7.4544e-04 - val_loss: 7.2470e-04 - val_mean_squared_error: 7.2470e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 7.4111e-04 - mean_squared_error: 7.4111e-04 - val_loss: 7.2496e-04 - val_mean_squared_error: 7.2496e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.3779e-04 - mean_squared_error: 7.3779e-04 - val_loss: 7.3036e-04 - val_mean_squared_error: 7.3036e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 7.3534e-04 - mean_squared_error: 7.3534e-04 - val_loss: 7.2391e-04 - val_mean_squared_error: 7.2391e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 7.3140e-04 - mean_squared_error: 7.3140e-04 - val_loss: 6.3411e-04 - val_mean_squared_error: 6.3411e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.2911e-04 - mean_squared_error: 7.2911e-04 - val_loss: 7.5509e-04 - val_mean_squared_error: 7.5509e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.2621e-04 - mean_squared_error: 7.2621e-04 - val_loss: 7.9860e-04 - val_mean_squared_error: 7.9860e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.2363e-04 - mean_squared_error: 7.2363e-04 - val_loss: 6.6477e-04 - val_mean_squared_error: 6.6477e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.1911e-04 - mean_squared_error: 7.1911e-04 - val_loss: 7.6838e-04 - val_mean_squared_error: 7.6838e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.1695e-04 - mean_squared_error: 7.1695e-04 - val_loss: 8.0489e-04 - val_mean_squared_error: 8.0489e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.1313e-04 - mean_squared_error: 7.1313e-04 - val_loss: 7.7173e-04 - val_mean_squared_error: 7.7173e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.1052e-04 - mean_squared_error: 7.1052e-04 - val_loss: 6.7975e-04 - val_mean_squared_error: 6.7975e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.0884e-04 - mean_squared_error: 7.0884e-04 - val_loss: 6.5141e-04 - val_mean_squared_error: 6.5141e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.0635e-04 - mean_squared_error: 7.0635e-04 - val_loss: 6.9491e-04 - val_mean_squared_error: 6.9491e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.0373e-04 - mean_squared_error: 7.0373e-04 - val_loss: 6.5404e-04 - val_mean_squared_error: 6.5404e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.9896e-04 - mean_squared_error: 6.9896e-04 - val_loss: 6.5535e-04 - val_mean_squared_error: 6.5535e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.9651e-04 - mean_squared_error: 6.9651e-04 - val_loss: 8.2506e-04 - val_mean_squared_error: 8.2506e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.9187e-04 - mean_squared_error: 6.9187e-04 - val_loss: 7.4912e-04 - val_mean_squared_error: 7.4912e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.9093e-04 - mean_squared_error: 6.9093e-04 - val_loss: 7.3560e-04 - val_mean_squared_error: 7.3560e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.8681e-04 - mean_squared_error: 6.8681e-04 - val_loss: 6.6912e-04 - val_mean_squared_error: 6.6912e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.8443e-04 - mean_squared_error: 6.8443e-04 - val_loss: 6.2019e-04 - val_mean_squared_error: 6.2019e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.8249e-04 - mean_squared_error: 6.8249e-04 - val_loss: 7.8170e-04 - val_mean_squared_error: 7.8170e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.7993e-04 - mean_squared_error: 6.7993e-04 - val_loss: 8.7376e-04 - val_mean_squared_error: 8.7376e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.7765e-04 - mean_squared_error: 6.7765e-04 - val_loss: 7.0775e-04 - val_mean_squared_error: 7.0775e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.7541e-04 - mean_squared_error: 6.7541e-04 - val_loss: 6.3520e-04 - val_mean_squared_error: 6.3520e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.6931e-04 - mean_squared_error: 6.6931e-04 - val_loss: 6.9884e-04 - val_mean_squared_error: 6.9884e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.6624e-04 - mean_squared_error: 6.6624e-04 - val_loss: 6.6489e-04 - val_mean_squared_error: 6.6489e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.6420e-04 - mean_squared_error: 6.6420e-04 - val_loss: 7.6431e-04 - val_mean_squared_error: 7.6431e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.6241e-04 - mean_squared_error: 6.6241e-04 - val_loss: 6.7106e-04 - val_mean_squared_error: 6.7106e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.6146e-04 - mean_squared_error: 6.6146e-04 - val_loss: 7.1764e-04 - val_mean_squared_error: 7.1764e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.5812e-04 - mean_squared_error: 6.5812e-04 - val_loss: 7.4129e-04 - val_mean_squared_error: 7.4129e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.5474e-04 - mean_squared_error: 6.5474e-04 - val_loss: 6.1921e-04 - val_mean_squared_error: 6.1921e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.5193e-04 - mean_squared_error: 6.5193e-04 - val_loss: 6.5415e-04 - val_mean_squared_error: 6.5415e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.5065e-04 - mean_squared_error: 6.5065e-04 - val_loss: 6.5072e-04 - val_mean_squared_error: 6.5072e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.4787e-04 - mean_squared_error: 6.4787e-04 - val_loss: 6.4749e-04 - val_mean_squared_error: 6.4749e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.4466e-04 - mean_squared_error: 6.4466e-04 - val_loss: 8.1236e-04 - val_mean_squared_error: 8.1236e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.4213e-04 - mean_squared_error: 6.4213e-04 - val_loss: 6.5838e-04 - val_mean_squared_error: 6.5838e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.4055e-04 - mean_squared_error: 6.4055e-04 - val_loss: 6.4967e-04 - val_mean_squared_error: 6.4967e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.3715e-04 - mean_squared_error: 6.3715e-04 - val_loss: 6.4045e-04 - val_mean_squared_error: 6.4045e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.3460e-04 - mean_squared_error: 6.3460e-04 - val_loss: 6.1452e-04 - val_mean_squared_error: 6.1452e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.3283e-04 - mean_squared_error: 6.3283e-04 - val_loss: 6.9241e-04 - val_mean_squared_error: 6.9241e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.3228e-04 - mean_squared_error: 6.3228e-04 - val_loss: 6.1222e-04 - val_mean_squared_error: 6.1222e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.3023e-04 - mean_squared_error: 6.3023e-04 - val_loss: 5.3995e-04 - val_mean_squared_error: 5.3995e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.2462e-04 - mean_squared_error: 6.2462e-04 - val_loss: 6.5148e-04 - val_mean_squared_error: 6.5148e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.2328e-04 - mean_squared_error: 6.2328e-04 - val_loss: 6.2110e-04 - val_mean_squared_error: 6.2110e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.2096e-04 - mean_squared_error: 6.2096e-04 - val_loss: 5.3022e-04 - val_mean_squared_error: 5.3022e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.1906e-04 - mean_squared_error: 6.1906e-04 - val_loss: 5.8318e-04 - val_mean_squared_error: 5.8318e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.1570e-04 - mean_squared_error: 6.1570e-04 - val_loss: 7.0924e-04 - val_mean_squared_error: 7.0924e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.1569e-04 - mean_squared_error: 6.1569e-04 - val_loss: 6.7492e-04 - val_mean_squared_error: 6.7492e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.1309e-04 - mean_squared_error: 6.1309e-04 - val_loss: 6.0477e-04 - val_mean_squared_error: 6.0477e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.1168e-04 - mean_squared_error: 6.1168e-04 - val_loss: 6.7452e-04 - val_mean_squared_error: 6.7452e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.0947e-04 - mean_squared_error: 6.0947e-04 - val_loss: 6.0801e-04 - val_mean_squared_error: 6.0801e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.0849e-04 - mean_squared_error: 6.0849e-04 - val_loss: 6.7812e-04 - val_mean_squared_error: 6.7812e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.0483e-04 - mean_squared_error: 6.0483e-04 - val_loss: 5.7600e-04 - val_mean_squared_error: 5.7600e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.0372e-04 - mean_squared_error: 6.0372e-04 - val_loss: 5.9825e-04 - val_mean_squared_error: 5.9825e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 6.0046e-04 - mean_squared_error: 6.0046e-04 - val_loss: 5.7135e-04 - val_mean_squared_error: 5.7135e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.0047e-04 - mean_squared_error: 6.0047e-04 - val_loss: 5.8939e-04 - val_mean_squared_error: 5.8939e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.9748e-04 - mean_squared_error: 5.9748e-04 - val_loss: 6.3861e-04 - val_mean_squared_error: 6.3861e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.9642e-04 - mean_squared_error: 5.9642e-04 - val_loss: 6.2630e-04 - val_mean_squared_error: 6.2630e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.9464e-04 - mean_squared_error: 5.9464e-04 - val_loss: 5.9690e-04 - val_mean_squared_error: 5.9690e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.9213e-04 - mean_squared_error: 5.9213e-04 - val_loss: 5.6188e-04 - val_mean_squared_error: 5.6188e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.8946e-04 - mean_squared_error: 5.8946e-04 - val_loss: 6.1369e-04 - val_mean_squared_error: 6.1369e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.8810e-04 - mean_squared_error: 5.8810e-04 - val_loss: 5.6417e-04 - val_mean_squared_error: 5.6417e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.8694e-04 - mean_squared_error: 5.8694e-04 - val_loss: 5.6788e-04 - val_mean_squared_error: 5.6788e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.8513e-04 - mean_squared_error: 5.8513e-04 - val_loss: 5.8393e-04 - val_mean_squared_error: 5.8393e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.8422e-04 - mean_squared_error: 5.8422e-04 - val_loss: 5.7641e-04 - val_mean_squared_error: 5.7641e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.8203e-04 - mean_squared_error: 5.8203e-04 - val_loss: 5.9491e-04 - val_mean_squared_error: 5.9491e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.7923e-04 - mean_squared_error: 5.7923e-04 - val_loss: 5.2254e-04 - val_mean_squared_error: 5.2254e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.7695e-04 - mean_squared_error: 5.7695e-04 - val_loss: 5.3891e-04 - val_mean_squared_error: 5.3891e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.7664e-04 - mean_squared_error: 5.7664e-04 - val_loss: 6.8367e-04 - val_mean_squared_error: 6.8367e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.7414e-04 - mean_squared_error: 5.7414e-04 - val_loss: 5.7983e-04 - val_mean_squared_error: 5.7983e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.7506e-04 - mean_squared_error: 5.7506e-04 - val_loss: 5.5241e-04 - val_mean_squared_error: 5.5241e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.7162e-04 - mean_squared_error: 5.7162e-04 - val_loss: 5.5865e-04 - val_mean_squared_error: 5.5865e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.7034e-04 - mean_squared_error: 5.7034e-04 - val_loss: 6.0810e-04 - val_mean_squared_error: 6.0810e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.6839e-04 - mean_squared_error: 5.6839e-04 - val_loss: 5.2408e-04 - val_mean_squared_error: 5.2408e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.6717e-04 - mean_squared_error: 5.6717e-04 - val_loss: 5.3622e-04 - val_mean_squared_error: 5.3622e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.6395e-04 - mean_squared_error: 5.6395e-04 - val_loss: 6.0048e-04 - val_mean_squared_error: 6.0048e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.6420e-04 - mean_squared_error: 5.6420e-04 - val_loss: 6.2668e-04 - val_mean_squared_error: 6.2668e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.6208e-04 - mean_squared_error: 5.6208e-04 - val_loss: 5.7016e-04 - val_mean_squared_error: 5.7016e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.6069e-04 - mean_squared_error: 5.6069e-04 - val_loss: 5.5599e-04 - val_mean_squared_error: 5.5599e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.5996e-04 - mean_squared_error: 5.5996e-04 - val_loss: 4.7353e-04 - val_mean_squared_error: 4.7353e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.5722e-04 - mean_squared_error: 5.5722e-04 - val_loss: 5.7383e-04 - val_mean_squared_error: 5.7383e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.5603e-04 - mean_squared_error: 5.5603e-04 - val_loss: 5.2097e-04 - val_mean_squared_error: 5.2097e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.5625e-04 - mean_squared_error: 5.5625e-04 - val_loss: 5.4890e-04 - val_mean_squared_error: 5.4890e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.5323e-04 - mean_squared_error: 5.5323e-04 - val_loss: 5.4765e-04 - val_mean_squared_error: 5.4765e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.5149e-04 - mean_squared_error: 5.5149e-04 - val_loss: 5.0222e-04 - val_mean_squared_error: 5.0222e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.5080e-04 - mean_squared_error: 5.5080e-04 - val_loss: 6.6051e-04 - val_mean_squared_error: 6.6051e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.4799e-04 - mean_squared_error: 5.4799e-04 - val_loss: 5.0633e-04 - val_mean_squared_error: 5.0633e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.4794e-04 - mean_squared_error: 5.4794e-04 - val_loss: 6.6321e-04 - val_mean_squared_error: 6.6321e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.4576e-04 - mean_squared_error: 5.4576e-04 - val_loss: 5.3845e-04 - val_mean_squared_error: 5.3845e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.4353e-04 - mean_squared_error: 5.4353e-04 - val_loss: 6.0283e-04 - val_mean_squared_error: 6.0283e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.4205e-04 - mean_squared_error: 5.4205e-04 - val_loss: 4.8229e-04 - val_mean_squared_error: 4.8229e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.4249e-04 - mean_squared_error: 5.4249e-04 - val_loss: 5.1452e-04 - val_mean_squared_error: 5.1452e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.4210e-04 - mean_squared_error: 5.4210e-04 - val_loss: 6.3560e-04 - val_mean_squared_error: 6.3560e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.4039e-04 - mean_squared_error: 5.4039e-04 - val_loss: 4.8145e-04 - val_mean_squared_error: 4.8145e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.3943e-04 - mean_squared_error: 5.3943e-04 - val_loss: 5.2620e-04 - val_mean_squared_error: 5.2620e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.3710e-04 - mean_squared_error: 5.3710e-04 - val_loss: 5.5721e-04 - val_mean_squared_error: 5.5721e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.3551e-04 - mean_squared_error: 5.3551e-04 - val_loss: 5.3114e-04 - val_mean_squared_error: 5.3114e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.3467e-04 - mean_squared_error: 5.3467e-04 - val_loss: 4.8790e-04 - val_mean_squared_error: 4.8790e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.3358e-04 - mean_squared_error: 5.3358e-04 - val_loss: 5.7473e-04 - val_mean_squared_error: 5.7473e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.3275e-04 - mean_squared_error: 5.3275e-04 - val_loss: 5.4673e-04 - val_mean_squared_error: 5.4673e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.2995e-04 - mean_squared_error: 5.2995e-04 - val_loss: 5.0843e-04 - val_mean_squared_error: 5.0843e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.2964e-04 - mean_squared_error: 5.2964e-04 - val_loss: 5.4487e-04 - val_mean_squared_error: 5.4487e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.2858e-04 - mean_squared_error: 5.2858e-04 - val_loss: 5.0045e-04 - val_mean_squared_error: 5.0045e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.2582e-04 - mean_squared_error: 5.2582e-04 - val_loss: 5.0275e-04 - val_mean_squared_error: 5.0275e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.2437e-04 - mean_squared_error: 5.2437e-04 - val_loss: 5.1945e-04 - val_mean_squared_error: 5.1945e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.2410e-04 - mean_squared_error: 5.2410e-04 - val_loss: 5.0843e-04 - val_mean_squared_error: 5.0843e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.2264e-04 - mean_squared_error: 5.2264e-04 - val_loss: 5.0015e-04 - val_mean_squared_error: 5.0015e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.2253e-04 - mean_squared_error: 5.2253e-04 - val_loss: 4.9479e-04 - val_mean_squared_error: 4.9479e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.2022e-04 - mean_squared_error: 5.2022e-04 - val_loss: 5.1301e-04 - val_mean_squared_error: 5.1301e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.1984e-04 - mean_squared_error: 5.1984e-04 - val_loss: 4.6172e-04 - val_mean_squared_error: 4.6172e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.1781e-04 - mean_squared_error: 5.1781e-04 - val_loss: 5.4180e-04 - val_mean_squared_error: 5.4180e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.1713e-04 - mean_squared_error: 5.1713e-04 - val_loss: 4.8804e-04 - val_mean_squared_error: 4.8804e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.1550e-04 - mean_squared_error: 5.1550e-04 - val_loss: 5.8444e-04 - val_mean_squared_error: 5.8444e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.1312e-04 - mean_squared_error: 5.1312e-04 - val_loss: 5.8964e-04 - val_mean_squared_error: 5.8964e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.1370e-04 - mean_squared_error: 5.1370e-04 - val_loss: 4.6691e-04 - val_mean_squared_error: 4.6691e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.1070e-04 - mean_squared_error: 5.1070e-04 - val_loss: 5.6786e-04 - val_mean_squared_error: 5.6786e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.1009e-04 - mean_squared_error: 5.1009e-04 - val_loss: 4.7887e-04 - val_mean_squared_error: 4.7887e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.0962e-04 - mean_squared_error: 5.0962e-04 - val_loss: 5.2517e-04 - val_mean_squared_error: 5.2517e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.0767e-04 - mean_squared_error: 5.0767e-04 - val_loss: 4.6027e-04 - val_mean_squared_error: 4.6027e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.0592e-04 - mean_squared_error: 5.0592e-04 - val_loss: 4.9069e-04 - val_mean_squared_error: 4.9069e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.0555e-04 - mean_squared_error: 5.0555e-04 - val_loss: 5.2451e-04 - val_mean_squared_error: 5.2451e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.0552e-04 - mean_squared_error: 5.0552e-04 - val_loss: 5.1591e-04 - val_mean_squared_error: 5.1591e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.0644e-04 - mean_squared_error: 5.0644e-04 - val_loss: 5.0111e-04 - val_mean_squared_error: 5.0111e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.0445e-04 - mean_squared_error: 5.0445e-04 - val_loss: 4.5218e-04 - val_mean_squared_error: 4.5218e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.0369e-04 - mean_squared_error: 5.0369e-04 - val_loss: 4.5609e-04 - val_mean_squared_error: 4.5609e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.0213e-04 - mean_squared_error: 5.0213e-04 - val_loss: 5.5083e-04 - val_mean_squared_error: 5.5083e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 5.0071e-04 - mean_squared_error: 5.0071e-04 - val_loss: 5.0066e-04 - val_mean_squared_error: 5.0066e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.9971e-04 - mean_squared_error: 4.9971e-04 - val_loss: 5.3098e-04 - val_mean_squared_error: 5.3098e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.9913e-04 - mean_squared_error: 4.9913e-04 - val_loss: 5.4949e-04 - val_mean_squared_error: 5.4949e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.9814e-04 - mean_squared_error: 4.9814e-04 - val_loss: 5.5507e-04 - val_mean_squared_error: 5.5507e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.9793e-04 - mean_squared_error: 4.9793e-04 - val_loss: 4.9990e-04 - val_mean_squared_error: 4.9990e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.9708e-04 - mean_squared_error: 4.9708e-04 - val_loss: 5.3257e-04 - val_mean_squared_error: 5.3257e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.9653e-04 - mean_squared_error: 4.9653e-04 - val_loss: 4.4217e-04 - val_mean_squared_error: 4.4217e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.9526e-04 - mean_squared_error: 4.9526e-04 - val_loss: 5.0724e-04 - val_mean_squared_error: 5.0724e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.9333e-04 - mean_squared_error: 4.9333e-04 - val_loss: 4.6491e-04 - val_mean_squared_error: 4.6491e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.9141e-04 - mean_squared_error: 4.9141e-04 - val_loss: 4.9264e-04 - val_mean_squared_error: 4.9264e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.8964e-04 - mean_squared_error: 4.8964e-04 - val_loss: 5.6580e-04 - val_mean_squared_error: 5.6580e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.8827e-04 - mean_squared_error: 4.8827e-04 - val_loss: 5.0696e-04 - val_mean_squared_error: 5.0696e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.8770e-04 - mean_squared_error: 4.8770e-04 - val_loss: 4.4502e-04 - val_mean_squared_error: 4.4502e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.8638e-04 - mean_squared_error: 4.8638e-04 - val_loss: 4.6413e-04 - val_mean_squared_error: 4.6413e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.8665e-04 - mean_squared_error: 4.8665e-04 - val_loss: 4.5438e-04 - val_mean_squared_error: 4.5438e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.8525e-04 - mean_squared_error: 4.8525e-04 - val_loss: 5.6981e-04 - val_mean_squared_error: 5.6981e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.8751e-04 - mean_squared_error: 4.8751e-04 - val_loss: 4.8233e-04 - val_mean_squared_error: 4.8233e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.8516e-04 - mean_squared_error: 4.8516e-04 - val_loss: 4.7036e-04 - val_mean_squared_error: 4.7036e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.8436e-04 - mean_squared_error: 4.8436e-04 - val_loss: 4.9420e-04 - val_mean_squared_error: 4.9420e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.8440e-04 - mean_squared_error: 4.8440e-04 - val_loss: 4.8963e-04 - val_mean_squared_error: 4.8963e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.8250e-04 - mean_squared_error: 4.8250e-04 - val_loss: 5.0211e-04 - val_mean_squared_error: 5.0211e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.8025e-04 - mean_squared_error: 4.8025e-04 - val_loss: 5.7678e-04 - val_mean_squared_error: 5.7678e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.8069e-04 - mean_squared_error: 4.8069e-04 - val_loss: 4.6113e-04 - val_mean_squared_error: 4.6113e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.7928e-04 - mean_squared_error: 4.7928e-04 - val_loss: 5.3741e-04 - val_mean_squared_error: 5.3741e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.7943e-04 - mean_squared_error: 4.7943e-04 - val_loss: 4.5867e-04 - val_mean_squared_error: 4.5867e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.7850e-04 - mean_squared_error: 4.7850e-04 - val_loss: 5.3544e-04 - val_mean_squared_error: 5.3544e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.7805e-04 - mean_squared_error: 4.7805e-04 - val_loss: 4.6876e-04 - val_mean_squared_error: 4.6876e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.7640e-04 - mean_squared_error: 4.7640e-04 - val_loss: 4.5248e-04 - val_mean_squared_error: 4.5248e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.7691e-04 - mean_squared_error: 4.7691e-04 - val_loss: 4.4858e-04 - val_mean_squared_error: 4.4858e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.7495e-04 - mean_squared_error: 4.7495e-04 - val_loss: 5.1833e-04 - val_mean_squared_error: 5.1833e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.7432e-04 - mean_squared_error: 4.7432e-04 - val_loss: 4.6058e-04 - val_mean_squared_error: 4.6058e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.7357e-04 - mean_squared_error: 4.7357e-04 - val_loss: 4.5099e-04 - val_mean_squared_error: 4.5099e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.7270e-04 - mean_squared_error: 4.7270e-04 - val_loss: 5.0196e-04 - val_mean_squared_error: 5.0196e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.7208e-04 - mean_squared_error: 4.7208e-04 - val_loss: 4.7894e-04 - val_mean_squared_error: 4.7894e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.7175e-04 - mean_squared_error: 4.7175e-04 - val_loss: 4.9908e-04 - val_mean_squared_error: 4.9908e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.6999e-04 - mean_squared_error: 4.6999e-04 - val_loss: 4.4778e-04 - val_mean_squared_error: 4.4778e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.6971e-04 - mean_squared_error: 4.6971e-04 - val_loss: 5.0950e-04 - val_mean_squared_error: 5.0950e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.6845e-04 - mean_squared_error: 4.6845e-04 - val_loss: 4.6431e-04 - val_mean_squared_error: 4.6431e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.6808e-04 - mean_squared_error: 4.6808e-04 - val_loss: 4.7628e-04 - val_mean_squared_error: 4.7628e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.6711e-04 - mean_squared_error: 4.6711e-04 - val_loss: 4.6631e-04 - val_mean_squared_error: 4.6631e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.6690e-04 - mean_squared_error: 4.6690e-04 - val_loss: 4.2269e-04 - val_mean_squared_error: 4.2269e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.6587e-04 - mean_squared_error: 4.6587e-04 - val_loss: 4.4281e-04 - val_mean_squared_error: 4.4281e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.6495e-04 - mean_squared_error: 4.6495e-04 - val_loss: 4.8127e-04 - val_mean_squared_error: 4.8127e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.6339e-04 - mean_squared_error: 4.6339e-04 - val_loss: 5.2814e-04 - val_mean_squared_error: 5.2814e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.6367e-04 - mean_squared_error: 4.6367e-04 - val_loss: 4.5782e-04 - val_mean_squared_error: 4.5782e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.6310e-04 - mean_squared_error: 4.6310e-04 - val_loss: 4.5829e-04 - val_mean_squared_error: 4.5829e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.6093e-04 - mean_squared_error: 4.6093e-04 - val_loss: 4.5959e-04 - val_mean_squared_error: 4.5959e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.6089e-04 - mean_squared_error: 4.6089e-04 - val_loss: 5.4781e-04 - val_mean_squared_error: 5.4781e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.6064e-04 - mean_squared_error: 4.6064e-04 - val_loss: 5.1284e-04 - val_mean_squared_error: 5.1284e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.6013e-04 - mean_squared_error: 4.6013e-04 - val_loss: 4.5784e-04 - val_mean_squared_error: 4.5784e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.5896e-04 - mean_squared_error: 4.5896e-04 - val_loss: 4.8263e-04 - val_mean_squared_error: 4.8263e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.5805e-04 - mean_squared_error: 4.5805e-04 - val_loss: 4.4619e-04 - val_mean_squared_error: 4.4619e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.5749e-04 - mean_squared_error: 4.5749e-04 - val_loss: 4.5650e-04 - val_mean_squared_error: 4.5650e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.5692e-04 - mean_squared_error: 4.5692e-04 - val_loss: 4.8024e-04 - val_mean_squared_error: 4.8024e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.5601e-04 - mean_squared_error: 4.5601e-04 - val_loss: 4.5779e-04 - val_mean_squared_error: 4.5779e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.5546e-04 - mean_squared_error: 4.5546e-04 - val_loss: 4.5616e-04 - val_mean_squared_error: 4.5616e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.5519e-04 - mean_squared_error: 4.5519e-04 - val_loss: 4.5466e-04 - val_mean_squared_error: 4.5466e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.5484e-04 - mean_squared_error: 4.5484e-04 - val_loss: 4.2220e-04 - val_mean_squared_error: 4.2220e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.5347e-04 - mean_squared_error: 4.5347e-04 - val_loss: 4.9247e-04 - val_mean_squared_error: 4.9247e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.5314e-04 - mean_squared_error: 4.5314e-04 - val_loss: 4.7443e-04 - val_mean_squared_error: 4.7443e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.5193e-04 - mean_squared_error: 4.5193e-04 - val_loss: 4.9745e-04 - val_mean_squared_error: 4.9745e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.5225e-04 - mean_squared_error: 4.5225e-04 - val_loss: 4.3214e-04 - val_mean_squared_error: 4.3214e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.5097e-04 - mean_squared_error: 4.5097e-04 - val_loss: 4.2407e-04 - val_mean_squared_error: 4.2407e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.5030e-04 - mean_squared_error: 4.5030e-04 - val_loss: 3.8033e-04 - val_mean_squared_error: 3.8033e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.5005e-04 - mean_squared_error: 4.5005e-04 - val_loss: 4.7440e-04 - val_mean_squared_error: 4.7440e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.4910e-04 - mean_squared_error: 4.4910e-04 - val_loss: 3.8334e-04 - val_mean_squared_error: 3.8334e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.4773e-04 - mean_squared_error: 4.4773e-04 - val_loss: 4.6023e-04 - val_mean_squared_error: 4.6023e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.4606e-04 - mean_squared_error: 4.4606e-04 - val_loss: 4.4931e-04 - val_mean_squared_error: 4.4931e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.4677e-04 - mean_squared_error: 4.4677e-04 - val_loss: 4.8691e-04 - val_mean_squared_error: 4.8691e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.4601e-04 - mean_squared_error: 4.4601e-04 - val_loss: 4.1052e-04 - val_mean_squared_error: 4.1052e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.4517e-04 - mean_squared_error: 4.4517e-04 - val_loss: 4.3075e-04 - val_mean_squared_error: 4.3075e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.4391e-04 - mean_squared_error: 4.4391e-04 - val_loss: 5.1244e-04 - val_mean_squared_error: 5.1244e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.4408e-04 - mean_squared_error: 4.4408e-04 - val_loss: 4.6131e-04 - val_mean_squared_error: 4.6131e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.4313e-04 - mean_squared_error: 4.4313e-04 - val_loss: 4.3376e-04 - val_mean_squared_error: 4.3376e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.4127e-04 - mean_squared_error: 4.4127e-04 - val_loss: 3.9848e-04 - val_mean_squared_error: 3.9848e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.4207e-04 - mean_squared_error: 4.4207e-04 - val_loss: 4.2944e-04 - val_mean_squared_error: 4.2944e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.4097e-04 - mean_squared_error: 4.4097e-04 - val_loss: 4.3960e-04 - val_mean_squared_error: 4.3960e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.4058e-04 - mean_squared_error: 4.4058e-04 - val_loss: 3.8762e-04 - val_mean_squared_error: 3.8762e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3950e-04 - mean_squared_error: 4.3950e-04 - val_loss: 4.0329e-04 - val_mean_squared_error: 4.0329e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.4020e-04 - mean_squared_error: 4.4020e-04 - val_loss: 4.3275e-04 - val_mean_squared_error: 4.3275e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3804e-04 - mean_squared_error: 4.3804e-04 - val_loss: 4.6178e-04 - val_mean_squared_error: 4.6178e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3852e-04 - mean_squared_error: 4.3852e-04 - val_loss: 4.2611e-04 - val_mean_squared_error: 4.2611e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.3795e-04 - mean_squared_error: 4.3795e-04 - val_loss: 4.0803e-04 - val_mean_squared_error: 4.0803e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3823e-04 - mean_squared_error: 4.3823e-04 - val_loss: 4.2057e-04 - val_mean_squared_error: 4.2057e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.3732e-04 - mean_squared_error: 4.3732e-04 - val_loss: 4.0898e-04 - val_mean_squared_error: 4.0898e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.3595e-04 - mean_squared_error: 4.3595e-04 - val_loss: 4.1868e-04 - val_mean_squared_error: 4.1868e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3538e-04 - mean_squared_error: 4.3538e-04 - val_loss: 4.1314e-04 - val_mean_squared_error: 4.1314e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3528e-04 - mean_squared_error: 4.3528e-04 - val_loss: 4.0802e-04 - val_mean_squared_error: 4.0802e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.3503e-04 - mean_squared_error: 4.3503e-04 - val_loss: 4.1508e-04 - val_mean_squared_error: 4.1508e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.3302e-04 - mean_squared_error: 4.3302e-04 - val_loss: 4.7598e-04 - val_mean_squared_error: 4.7598e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3404e-04 - mean_squared_error: 4.3404e-04 - val_loss: 4.4662e-04 - val_mean_squared_error: 4.4662e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.3265e-04 - mean_squared_error: 4.3265e-04 - val_loss: 4.3771e-04 - val_mean_squared_error: 4.3771e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3171e-04 - mean_squared_error: 4.3171e-04 - val_loss: 4.5433e-04 - val_mean_squared_error: 4.5433e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.3079e-04 - mean_squared_error: 4.3079e-04 - val_loss: 4.2580e-04 - val_mean_squared_error: 4.2580e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3103e-04 - mean_squared_error: 4.3103e-04 - val_loss: 3.8299e-04 - val_mean_squared_error: 3.8299e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.3065e-04 - mean_squared_error: 4.3065e-04 - val_loss: 4.3196e-04 - val_mean_squared_error: 4.3196e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3015e-04 - mean_squared_error: 4.3015e-04 - val_loss: 4.2195e-04 - val_mean_squared_error: 4.2195e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.2855e-04 - mean_squared_error: 4.2855e-04 - val_loss: 4.4362e-04 - val_mean_squared_error: 4.4362e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.2932e-04 - mean_squared_error: 4.2932e-04 - val_loss: 3.7413e-04 - val_mean_squared_error: 3.7413e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.2778e-04 - mean_squared_error: 4.2778e-04 - val_loss: 4.3068e-04 - val_mean_squared_error: 4.3068e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.2777e-04 - mean_squared_error: 4.2777e-04 - val_loss: 4.2364e-04 - val_mean_squared_error: 4.2364e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2573e-04 - mean_squared_error: 4.2573e-04 - val_loss: 4.4950e-04 - val_mean_squared_error: 4.4950e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2499e-04 - mean_squared_error: 4.2499e-04 - val_loss: 3.9810e-04 - val_mean_squared_error: 3.9810e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.2657e-04 - mean_squared_error: 4.2657e-04 - val_loss: 4.0021e-04 - val_mean_squared_error: 4.0021e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2512e-04 - mean_squared_error: 4.2512e-04 - val_loss: 3.4266e-04 - val_mean_squared_error: 3.4266e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2487e-04 - mean_squared_error: 4.2487e-04 - val_loss: 4.2904e-04 - val_mean_squared_error: 4.2904e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.2480e-04 - mean_squared_error: 4.2480e-04 - val_loss: 4.3875e-04 - val_mean_squared_error: 4.3875e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2293e-04 - mean_squared_error: 4.2293e-04 - val_loss: 3.7441e-04 - val_mean_squared_error: 3.7441e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.2354e-04 - mean_squared_error: 4.2354e-04 - val_loss: 4.1616e-04 - val_mean_squared_error: 4.1616e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2307e-04 - mean_squared_error: 4.2307e-04 - val_loss: 4.5273e-04 - val_mean_squared_error: 4.5273e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2104e-04 - mean_squared_error: 4.2104e-04 - val_loss: 4.1347e-04 - val_mean_squared_error: 4.1347e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.2070e-04 - mean_squared_error: 4.2070e-04 - val_loss: 3.9998e-04 - val_mean_squared_error: 3.9998e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.2053e-04 - mean_squared_error: 4.2053e-04 - val_loss: 4.1935e-04 - val_mean_squared_error: 4.1935e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2185e-04 - mean_squared_error: 4.2185e-04 - val_loss: 4.3545e-04 - val_mean_squared_error: 4.3545e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.1955e-04 - mean_squared_error: 4.1955e-04 - val_loss: 3.8619e-04 - val_mean_squared_error: 3.8619e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.1922e-04 - mean_squared_error: 4.1922e-04 - val_loss: 4.1272e-04 - val_mean_squared_error: 4.1272e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.1795e-04 - mean_squared_error: 4.1795e-04 - val_loss: 3.9348e-04 - val_mean_squared_error: 3.9348e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.1723e-04 - mean_squared_error: 4.1723e-04 - val_loss: 4.6674e-04 - val_mean_squared_error: 4.6674e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.1808e-04 - mean_squared_error: 4.1808e-04 - val_loss: 3.9218e-04 - val_mean_squared_error: 3.9218e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.1688e-04 - mean_squared_error: 4.1688e-04 - val_loss: 4.3507e-04 - val_mean_squared_error: 4.3507e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.1718e-04 - mean_squared_error: 4.1718e-04 - val_loss: 4.2833e-04 - val_mean_squared_error: 4.2833e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.1492e-04 - mean_squared_error: 4.1492e-04 - val_loss: 4.2227e-04 - val_mean_squared_error: 4.2227e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.1543e-04 - mean_squared_error: 4.1543e-04 - val_loss: 4.0603e-04 - val_mean_squared_error: 4.0603e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.1472e-04 - mean_squared_error: 4.1472e-04 - val_loss: 4.1502e-04 - val_mean_squared_error: 4.1502e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.1410e-04 - mean_squared_error: 4.1410e-04 - val_loss: 4.6608e-04 - val_mean_squared_error: 4.6608e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.1408e-04 - mean_squared_error: 4.1408e-04 - val_loss: 3.7267e-04 - val_mean_squared_error: 3.7267e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.1469e-04 - mean_squared_error: 4.1469e-04 - val_loss: 4.0705e-04 - val_mean_squared_error: 4.0705e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.1281e-04 - mean_squared_error: 4.1281e-04 - val_loss: 4.3173e-04 - val_mean_squared_error: 4.3173e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.1340e-04 - mean_squared_error: 4.1340e-04 - val_loss: 4.1712e-04 - val_mean_squared_error: 4.1712e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.1167e-04 - mean_squared_error: 4.1167e-04 - val_loss: 3.9162e-04 - val_mean_squared_error: 3.9162e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.1200e-04 - mean_squared_error: 4.1200e-04 - val_loss: 4.2829e-04 - val_mean_squared_error: 4.2829e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.1008e-04 - mean_squared_error: 4.1008e-04 - val_loss: 3.5791e-04 - val_mean_squared_error: 3.5791e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.1148e-04 - mean_squared_error: 4.1148e-04 - val_loss: 4.5473e-04 - val_mean_squared_error: 4.5473e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.0986e-04 - mean_squared_error: 4.0986e-04 - val_loss: 4.2273e-04 - val_mean_squared_error: 4.2273e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.0976e-04 - mean_squared_error: 4.0976e-04 - val_loss: 4.2681e-04 - val_mean_squared_error: 4.2681e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.0996e-04 - mean_squared_error: 4.0996e-04 - val_loss: 4.1205e-04 - val_mean_squared_error: 4.1205e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.0850e-04 - mean_squared_error: 4.0850e-04 - val_loss: 4.3931e-04 - val_mean_squared_error: 4.3931e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.0867e-04 - mean_squared_error: 4.0867e-04 - val_loss: 4.2511e-04 - val_mean_squared_error: 4.2511e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.0749e-04 - mean_squared_error: 4.0749e-04 - val_loss: 3.8980e-04 - val_mean_squared_error: 3.8980e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.0776e-04 - mean_squared_error: 4.0776e-04 - val_loss: 3.9151e-04 - val_mean_squared_error: 3.9151e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.0723e-04 - mean_squared_error: 4.0723e-04 - val_loss: 3.8280e-04 - val_mean_squared_error: 3.8280e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.0754e-04 - mean_squared_error: 4.0754e-04 - val_loss: 3.3393e-04 - val_mean_squared_error: 3.3393e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.0660e-04 - mean_squared_error: 4.0660e-04 - val_loss: 3.4329e-04 - val_mean_squared_error: 3.4329e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.0691e-04 - mean_squared_error: 4.0691e-04 - val_loss: 3.8637e-04 - val_mean_squared_error: 3.8637e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.0564e-04 - mean_squared_error: 4.0564e-04 - val_loss: 3.7011e-04 - val_mean_squared_error: 3.7011e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.0526e-04 - mean_squared_error: 4.0526e-04 - val_loss: 3.6608e-04 - val_mean_squared_error: 3.6608e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.0401e-04 - mean_squared_error: 4.0401e-04 - val_loss: 4.9109e-04 - val_mean_squared_error: 4.9109e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.0417e-04 - mean_squared_error: 4.0417e-04 - val_loss: 3.8268e-04 - val_mean_squared_error: 3.8268e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.0371e-04 - mean_squared_error: 4.0371e-04 - val_loss: 4.3953e-04 - val_mean_squared_error: 4.3953e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.0333e-04 - mean_squared_error: 4.0333e-04 - val_loss: 3.5581e-04 - val_mean_squared_error: 3.5581e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.0228e-04 - mean_squared_error: 4.0228e-04 - val_loss: 3.6833e-04 - val_mean_squared_error: 3.6833e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.0190e-04 - mean_squared_error: 4.0190e-04 - val_loss: 3.6549e-04 - val_mean_squared_error: 3.6549e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 4.0093e-04 - mean_squared_error: 4.0093e-04 - val_loss: 3.9819e-04 - val_mean_squared_error: 3.9819e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.0130e-04 - mean_squared_error: 4.0130e-04 - val_loss: 4.5557e-04 - val_mean_squared_error: 4.5557e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.0044e-04 - mean_squared_error: 4.0044e-04 - val_loss: 4.1726e-04 - val_mean_squared_error: 4.1726e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.0111e-04 - mean_squared_error: 4.0111e-04 - val_loss: 3.8981e-04 - val_mean_squared_error: 3.8981e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.9933e-04 - mean_squared_error: 3.9933e-04 - val_loss: 4.2119e-04 - val_mean_squared_error: 4.2119e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.9864e-04 - mean_squared_error: 3.9864e-04 - val_loss: 3.9411e-04 - val_mean_squared_error: 3.9411e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.9910e-04 - mean_squared_error: 3.9910e-04 - val_loss: 3.7563e-04 - val_mean_squared_error: 3.7563e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.9872e-04 - mean_squared_error: 3.9872e-04 - val_loss: 4.3874e-04 - val_mean_squared_error: 4.3874e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.9797e-04 - mean_squared_error: 3.9797e-04 - val_loss: 4.4283e-04 - val_mean_squared_error: 4.4283e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.9778e-04 - mean_squared_error: 3.9778e-04 - val_loss: 4.0663e-04 - val_mean_squared_error: 4.0663e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.9723e-04 - mean_squared_error: 3.9723e-04 - val_loss: 3.7627e-04 - val_mean_squared_error: 3.7627e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.9652e-04 - mean_squared_error: 3.9652e-04 - val_loss: 4.5536e-04 - val_mean_squared_error: 4.5536e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.9610e-04 - mean_squared_error: 3.9610e-04 - val_loss: 3.8623e-04 - val_mean_squared_error: 3.8623e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.9627e-04 - mean_squared_error: 3.9627e-04 - val_loss: 4.1081e-04 - val_mean_squared_error: 4.1081e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.9486e-04 - mean_squared_error: 3.9486e-04 - val_loss: 4.0252e-04 - val_mean_squared_error: 4.0252e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.9583e-04 - mean_squared_error: 3.9583e-04 - val_loss: 3.8887e-04 - val_mean_squared_error: 3.8887e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.9399e-04 - mean_squared_error: 3.9399e-04 - val_loss: 3.5598e-04 - val_mean_squared_error: 3.5598e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.9476e-04 - mean_squared_error: 3.9476e-04 - val_loss: 4.3615e-04 - val_mean_squared_error: 4.3615e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.9433e-04 - mean_squared_error: 3.9433e-04 - val_loss: 3.7549e-04 - val_mean_squared_error: 3.7549e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.9357e-04 - mean_squared_error: 3.9357e-04 - val_loss: 4.0160e-04 - val_mean_squared_error: 4.0160e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.9170e-04 - mean_squared_error: 3.9170e-04 - val_loss: 3.9627e-04 - val_mean_squared_error: 3.9627e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.9302e-04 - mean_squared_error: 3.9302e-04 - val_loss: 3.4402e-04 - val_mean_squared_error: 3.4402e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.9370e-04 - mean_squared_error: 3.9370e-04 - val_loss: 3.8707e-04 - val_mean_squared_error: 3.8707e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.9284e-04 - mean_squared_error: 3.9284e-04 - val_loss: 3.8655e-04 - val_mean_squared_error: 3.8655e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.9137e-04 - mean_squared_error: 3.9137e-04 - val_loss: 3.9611e-04 - val_mean_squared_error: 3.9611e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.9175e-04 - mean_squared_error: 3.9175e-04 - val_loss: 3.6862e-04 - val_mean_squared_error: 3.6862e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.9207e-04 - mean_squared_error: 3.9207e-04 - val_loss: 3.9714e-04 - val_mean_squared_error: 3.9714e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.9128e-04 - mean_squared_error: 3.9128e-04 - val_loss: 4.0137e-04 - val_mean_squared_error: 4.0137e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.8959e-04 - mean_squared_error: 3.8959e-04 - val_loss: 3.6164e-04 - val_mean_squared_error: 3.6164e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.8947e-04 - mean_squared_error: 3.8947e-04 - val_loss: 3.3466e-04 - val_mean_squared_error: 3.3466e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.8896e-04 - mean_squared_error: 3.8896e-04 - val_loss: 3.3903e-04 - val_mean_squared_error: 3.3903e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.8902e-04 - mean_squared_error: 3.8902e-04 - val_loss: 3.9996e-04 - val_mean_squared_error: 3.9996e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.8749e-04 - mean_squared_error: 3.8749e-04 - val_loss: 3.7168e-04 - val_mean_squared_error: 3.7168e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.8783e-04 - mean_squared_error: 3.8783e-04 - val_loss: 3.8489e-04 - val_mean_squared_error: 3.8489e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.8851e-04 - mean_squared_error: 3.8851e-04 - val_loss: 3.4052e-04 - val_mean_squared_error: 3.4052e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.8839e-04 - mean_squared_error: 3.8839e-04 - val_loss: 3.5132e-04 - val_mean_squared_error: 3.5132e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.8740e-04 - mean_squared_error: 3.8740e-04 - val_loss: 3.4837e-04 - val_mean_squared_error: 3.4837e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.8600e-04 - mean_squared_error: 3.8600e-04 - val_loss: 4.1963e-04 - val_mean_squared_error: 4.1963e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.8711e-04 - mean_squared_error: 3.8711e-04 - val_loss: 4.0623e-04 - val_mean_squared_error: 4.0623e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.8635e-04 - mean_squared_error: 3.8635e-04 - val_loss: 3.2499e-04 - val_mean_squared_error: 3.2499e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.8493e-04 - mean_squared_error: 3.8493e-04 - val_loss: 3.8818e-04 - val_mean_squared_error: 3.8818e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.8487e-04 - mean_squared_error: 3.8487e-04 - val_loss: 3.7307e-04 - val_mean_squared_error: 3.7307e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.8450e-04 - mean_squared_error: 3.8450e-04 - val_loss: 4.3863e-04 - val_mean_squared_error: 4.3863e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.8456e-04 - mean_squared_error: 3.8456e-04 - val_loss: 3.5707e-04 - val_mean_squared_error: 3.5707e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.8381e-04 - mean_squared_error: 3.8381e-04 - val_loss: 4.8390e-04 - val_mean_squared_error: 4.8390e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.8463e-04 - mean_squared_error: 3.8463e-04 - val_loss: 3.3303e-04 - val_mean_squared_error: 3.3303e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.8314e-04 - mean_squared_error: 3.8314e-04 - val_loss: 3.6454e-04 - val_mean_squared_error: 3.6454e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.8319e-04 - mean_squared_error: 3.8319e-04 - val_loss: 4.1849e-04 - val_mean_squared_error: 4.1849e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.8237e-04 - mean_squared_error: 3.8237e-04 - val_loss: 3.9540e-04 - val_mean_squared_error: 3.9540e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.8305e-04 - mean_squared_error: 3.8305e-04 - val_loss: 4.8394e-04 - val_mean_squared_error: 4.8394e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.8139e-04 - mean_squared_error: 3.8139e-04 - val_loss: 4.1801e-04 - val_mean_squared_error: 4.1801e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.8192e-04 - mean_squared_error: 3.8192e-04 - val_loss: 3.7908e-04 - val_mean_squared_error: 3.7908e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.8159e-04 - mean_squared_error: 3.8159e-04 - val_loss: 3.7679e-04 - val_mean_squared_error: 3.7679e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.8088e-04 - mean_squared_error: 3.8088e-04 - val_loss: 4.0112e-04 - val_mean_squared_error: 4.0112e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.8042e-04 - mean_squared_error: 3.8042e-04 - val_loss: 3.5056e-04 - val_mean_squared_error: 3.5056e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.8105e-04 - mean_squared_error: 3.8105e-04 - val_loss: 3.8533e-04 - val_mean_squared_error: 3.8533e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7988e-04 - mean_squared_error: 3.7988e-04 - val_loss: 3.6104e-04 - val_mean_squared_error: 3.6104e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7861e-04 - mean_squared_error: 3.7861e-04 - val_loss: 4.1655e-04 - val_mean_squared_error: 4.1655e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7932e-04 - mean_squared_error: 3.7932e-04 - val_loss: 3.4575e-04 - val_mean_squared_error: 3.4575e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7849e-04 - mean_squared_error: 3.7849e-04 - val_loss: 4.0661e-04 - val_mean_squared_error: 4.0661e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.7685e-04 - mean_squared_error: 3.7685e-04 - val_loss: 3.4557e-04 - val_mean_squared_error: 3.4557e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.7868e-04 - mean_squared_error: 3.7868e-04 - val_loss: 3.6581e-04 - val_mean_squared_error: 3.6581e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7716e-04 - mean_squared_error: 3.7716e-04 - val_loss: 3.4785e-04 - val_mean_squared_error: 3.4785e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7726e-04 - mean_squared_error: 3.7726e-04 - val_loss: 4.4376e-04 - val_mean_squared_error: 4.4376e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7649e-04 - mean_squared_error: 3.7649e-04 - val_loss: 3.6462e-04 - val_mean_squared_error: 3.6462e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7732e-04 - mean_squared_error: 3.7732e-04 - val_loss: 3.8226e-04 - val_mean_squared_error: 3.8226e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7629e-04 - mean_squared_error: 3.7629e-04 - val_loss: 3.1429e-04 - val_mean_squared_error: 3.1429e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7467e-04 - mean_squared_error: 3.7467e-04 - val_loss: 3.4209e-04 - val_mean_squared_error: 3.4209e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7551e-04 - mean_squared_error: 3.7551e-04 - val_loss: 3.6582e-04 - val_mean_squared_error: 3.6582e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.7532e-04 - mean_squared_error: 3.7532e-04 - val_loss: 3.6505e-04 - val_mean_squared_error: 3.6505e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7516e-04 - mean_squared_error: 3.7516e-04 - val_loss: 3.4889e-04 - val_mean_squared_error: 3.4889e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.7343e-04 - mean_squared_error: 3.7343e-04 - val_loss: 3.5907e-04 - val_mean_squared_error: 3.5907e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7496e-04 - mean_squared_error: 3.7496e-04 - val_loss: 3.6429e-04 - val_mean_squared_error: 3.6429e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7282e-04 - mean_squared_error: 3.7282e-04 - val_loss: 3.6700e-04 - val_mean_squared_error: 3.6700e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.7417e-04 - mean_squared_error: 3.7417e-04 - val_loss: 3.3528e-04 - val_mean_squared_error: 3.3528e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7305e-04 - mean_squared_error: 3.7305e-04 - val_loss: 3.8124e-04 - val_mean_squared_error: 3.8124e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7238e-04 - mean_squared_error: 3.7238e-04 - val_loss: 3.5851e-04 - val_mean_squared_error: 3.5851e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7274e-04 - mean_squared_error: 3.7274e-04 - val_loss: 3.8322e-04 - val_mean_squared_error: 3.8322e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7335e-04 - mean_squared_error: 3.7335e-04 - val_loss: 3.3507e-04 - val_mean_squared_error: 3.3507e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7104e-04 - mean_squared_error: 3.7104e-04 - val_loss: 3.5090e-04 - val_mean_squared_error: 3.5090e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7170e-04 - mean_squared_error: 3.7170e-04 - val_loss: 4.3015e-04 - val_mean_squared_error: 4.3015e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7081e-04 - mean_squared_error: 3.7081e-04 - val_loss: 3.4865e-04 - val_mean_squared_error: 3.4865e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7113e-04 - mean_squared_error: 3.7113e-04 - val_loss: 3.5211e-04 - val_mean_squared_error: 3.5211e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7025e-04 - mean_squared_error: 3.7025e-04 - val_loss: 3.6515e-04 - val_mean_squared_error: 3.6515e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7029e-04 - mean_squared_error: 3.7029e-04 - val_loss: 3.6387e-04 - val_mean_squared_error: 3.6387e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.6939e-04 - mean_squared_error: 3.6939e-04 - val_loss: 3.4464e-04 - val_mean_squared_error: 3.4464e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.6990e-04 - mean_squared_error: 3.6990e-04 - val_loss: 3.9483e-04 - val_mean_squared_error: 3.9483e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6922e-04 - mean_squared_error: 3.6922e-04 - val_loss: 3.3605e-04 - val_mean_squared_error: 3.3605e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.6822e-04 - mean_squared_error: 3.6822e-04 - val_loss: 3.6462e-04 - val_mean_squared_error: 3.6462e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6815e-04 - mean_squared_error: 3.6815e-04 - val_loss: 4.6630e-04 - val_mean_squared_error: 4.6630e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.6785e-04 - mean_squared_error: 3.6785e-04 - val_loss: 3.1187e-04 - val_mean_squared_error: 3.1187e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6749e-04 - mean_squared_error: 3.6749e-04 - val_loss: 3.8708e-04 - val_mean_squared_error: 3.8708e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6696e-04 - mean_squared_error: 3.6696e-04 - val_loss: 3.4744e-04 - val_mean_squared_error: 3.4744e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6781e-04 - mean_squared_error: 3.6781e-04 - val_loss: 3.1284e-04 - val_mean_squared_error: 3.1284e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.6662e-04 - mean_squared_error: 3.6662e-04 - val_loss: 3.5508e-04 - val_mean_squared_error: 3.5508e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6655e-04 - mean_squared_error: 3.6655e-04 - val_loss: 3.4055e-04 - val_mean_squared_error: 3.4055e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6604e-04 - mean_squared_error: 3.6604e-04 - val_loss: 3.1015e-04 - val_mean_squared_error: 3.1015e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6528e-04 - mean_squared_error: 3.6528e-04 - val_loss: 3.3550e-04 - val_mean_squared_error: 3.3550e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6574e-04 - mean_squared_error: 3.6574e-04 - val_loss: 3.4540e-04 - val_mean_squared_error: 3.4540e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6542e-04 - mean_squared_error: 3.6542e-04 - val_loss: 3.9019e-04 - val_mean_squared_error: 3.9019e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.6438e-04 - mean_squared_error: 3.6438e-04 - val_loss: 3.4221e-04 - val_mean_squared_error: 3.4221e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6488e-04 - mean_squared_error: 3.6488e-04 - val_loss: 3.4948e-04 - val_mean_squared_error: 3.4948e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.6367e-04 - mean_squared_error: 3.6367e-04 - val_loss: 3.7509e-04 - val_mean_squared_error: 3.7509e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.6405e-04 - mean_squared_error: 3.6405e-04 - val_loss: 3.2620e-04 - val_mean_squared_error: 3.2620e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.6393e-04 - mean_squared_error: 3.6393e-04 - val_loss: 4.2507e-04 - val_mean_squared_error: 4.2507e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.6332e-04 - mean_squared_error: 3.6332e-04 - val_loss: 4.3627e-04 - val_mean_squared_error: 4.3627e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6239e-04 - mean_squared_error: 3.6239e-04 - val_loss: 4.1078e-04 - val_mean_squared_error: 4.1078e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6287e-04 - mean_squared_error: 3.6287e-04 - val_loss: 3.4258e-04 - val_mean_squared_error: 3.4258e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.6256e-04 - mean_squared_error: 3.6256e-04 - val_loss: 3.8314e-04 - val_mean_squared_error: 3.8314e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.6301e-04 - mean_squared_error: 3.6301e-04 - val_loss: 4.0001e-04 - val_mean_squared_error: 4.0001e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6079e-04 - mean_squared_error: 3.6079e-04 - val_loss: 3.4120e-04 - val_mean_squared_error: 3.4120e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6174e-04 - mean_squared_error: 3.6174e-04 - val_loss: 3.5180e-04 - val_mean_squared_error: 3.5180e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6104e-04 - mean_squared_error: 3.6104e-04 - val_loss: 4.2649e-04 - val_mean_squared_error: 4.2649e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6067e-04 - mean_squared_error: 3.6067e-04 - val_loss: 3.7848e-04 - val_mean_squared_error: 3.7848e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.6055e-04 - mean_squared_error: 3.6055e-04 - val_loss: 3.3160e-04 - val_mean_squared_error: 3.3160e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6083e-04 - mean_squared_error: 3.6083e-04 - val_loss: 4.1547e-04 - val_mean_squared_error: 4.1547e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5911e-04 - mean_squared_error: 3.5911e-04 - val_loss: 3.3333e-04 - val_mean_squared_error: 3.3333e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5963e-04 - mean_squared_error: 3.5963e-04 - val_loss: 3.3475e-04 - val_mean_squared_error: 3.3475e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5924e-04 - mean_squared_error: 3.5924e-04 - val_loss: 3.2986e-04 - val_mean_squared_error: 3.2986e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5926e-04 - mean_squared_error: 3.5926e-04 - val_loss: 3.1805e-04 - val_mean_squared_error: 3.1805e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5854e-04 - mean_squared_error: 3.5854e-04 - val_loss: 4.6398e-04 - val_mean_squared_error: 4.6398e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5834e-04 - mean_squared_error: 3.5834e-04 - val_loss: 3.5570e-04 - val_mean_squared_error: 3.5570e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5785e-04 - mean_squared_error: 3.5785e-04 - val_loss: 3.2810e-04 - val_mean_squared_error: 3.2810e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5740e-04 - mean_squared_error: 3.5740e-04 - val_loss: 3.7655e-04 - val_mean_squared_error: 3.7655e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5756e-04 - mean_squared_error: 3.5756e-04 - val_loss: 3.8268e-04 - val_mean_squared_error: 3.8268e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.5733e-04 - mean_squared_error: 3.5733e-04 - val_loss: 3.6390e-04 - val_mean_squared_error: 3.6390e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.5628e-04 - mean_squared_error: 3.5628e-04 - val_loss: 4.2257e-04 - val_mean_squared_error: 4.2257e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5689e-04 - mean_squared_error: 3.5689e-04 - val_loss: 3.5123e-04 - val_mean_squared_error: 3.5123e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5590e-04 - mean_squared_error: 3.5590e-04 - val_loss: 3.2929e-04 - val_mean_squared_error: 3.2929e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5582e-04 - mean_squared_error: 3.5582e-04 - val_loss: 4.1719e-04 - val_mean_squared_error: 4.1719e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.5648e-04 - mean_squared_error: 3.5648e-04 - val_loss: 3.9933e-04 - val_mean_squared_error: 3.9933e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.5395e-04 - mean_squared_error: 3.5395e-04 - val_loss: 3.4024e-04 - val_mean_squared_error: 3.4024e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.5555e-04 - mean_squared_error: 3.5555e-04 - val_loss: 3.4180e-04 - val_mean_squared_error: 3.4180e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.5563e-04 - mean_squared_error: 3.5563e-04 - val_loss: 3.4939e-04 - val_mean_squared_error: 3.4939e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5496e-04 - mean_squared_error: 3.5496e-04 - val_loss: 4.0787e-04 - val_mean_squared_error: 4.0787e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5529e-04 - mean_squared_error: 3.5529e-04 - val_loss: 3.2672e-04 - val_mean_squared_error: 3.2672e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5456e-04 - mean_squared_error: 3.5456e-04 - val_loss: 3.3239e-04 - val_mean_squared_error: 3.3239e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5401e-04 - mean_squared_error: 3.5401e-04 - val_loss: 3.3006e-04 - val_mean_squared_error: 3.3006e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.5419e-04 - mean_squared_error: 3.5419e-04 - val_loss: 3.7082e-04 - val_mean_squared_error: 3.7082e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.5329e-04 - mean_squared_error: 3.5329e-04 - val_loss: 3.8671e-04 - val_mean_squared_error: 3.8671e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.5245e-04 - mean_squared_error: 3.5245e-04 - val_loss: 3.5852e-04 - val_mean_squared_error: 3.5852e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.5315e-04 - mean_squared_error: 3.5315e-04 - val_loss: 3.8893e-04 - val_mean_squared_error: 3.8893e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.5291e-04 - mean_squared_error: 3.5291e-04 - val_loss: 3.5268e-04 - val_mean_squared_error: 3.5268e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5157e-04 - mean_squared_error: 3.5157e-04 - val_loss: 3.2387e-04 - val_mean_squared_error: 3.2387e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5202e-04 - mean_squared_error: 3.5202e-04 - val_loss: 3.5788e-04 - val_mean_squared_error: 3.5788e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5112e-04 - mean_squared_error: 3.5112e-04 - val_loss: 3.4608e-04 - val_mean_squared_error: 3.4608e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5178e-04 - mean_squared_error: 3.5178e-04 - val_loss: 3.1489e-04 - val_mean_squared_error: 3.1489e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5043e-04 - mean_squared_error: 3.5043e-04 - val_loss: 3.3620e-04 - val_mean_squared_error: 3.3620e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5102e-04 - mean_squared_error: 3.5102e-04 - val_loss: 3.2716e-04 - val_mean_squared_error: 3.2716e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5021e-04 - mean_squared_error: 3.5021e-04 - val_loss: 4.1074e-04 - val_mean_squared_error: 4.1074e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5034e-04 - mean_squared_error: 3.5034e-04 - val_loss: 3.3947e-04 - val_mean_squared_error: 3.3947e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4993e-04 - mean_squared_error: 3.4993e-04 - val_loss: 2.7957e-04 - val_mean_squared_error: 2.7957e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4950e-04 - mean_squared_error: 3.4950e-04 - val_loss: 3.3437e-04 - val_mean_squared_error: 3.3437e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4956e-04 - mean_squared_error: 3.4956e-04 - val_loss: 3.4836e-04 - val_mean_squared_error: 3.4836e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4925e-04 - mean_squared_error: 3.4925e-04 - val_loss: 3.7142e-04 - val_mean_squared_error: 3.7142e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4875e-04 - mean_squared_error: 3.4875e-04 - val_loss: 3.7345e-04 - val_mean_squared_error: 3.7345e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4881e-04 - mean_squared_error: 3.4881e-04 - val_loss: 3.1292e-04 - val_mean_squared_error: 3.1292e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4775e-04 - mean_squared_error: 3.4775e-04 - val_loss: 3.6293e-04 - val_mean_squared_error: 3.6293e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.4821e-04 - mean_squared_error: 3.4821e-04 - val_loss: 3.4392e-04 - val_mean_squared_error: 3.4392e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4783e-04 - mean_squared_error: 3.4783e-04 - val_loss: 3.4076e-04 - val_mean_squared_error: 3.4076e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4708e-04 - mean_squared_error: 3.4708e-04 - val_loss: 3.6979e-04 - val_mean_squared_error: 3.6979e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4715e-04 - mean_squared_error: 3.4715e-04 - val_loss: 3.0797e-04 - val_mean_squared_error: 3.0797e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.4557e-04 - mean_squared_error: 3.4557e-04 - val_loss: 3.9960e-04 - val_mean_squared_error: 3.9960e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.4714e-04 - mean_squared_error: 3.4714e-04 - val_loss: 3.1634e-04 - val_mean_squared_error: 3.1634e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.4612e-04 - mean_squared_error: 3.4612e-04 - val_loss: 3.2458e-04 - val_mean_squared_error: 3.2458e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4582e-04 - mean_squared_error: 3.4582e-04 - val_loss: 3.4114e-04 - val_mean_squared_error: 3.4114e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4623e-04 - mean_squared_error: 3.4623e-04 - val_loss: 3.2852e-04 - val_mean_squared_error: 3.2852e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4547e-04 - mean_squared_error: 3.4547e-04 - val_loss: 3.3214e-04 - val_mean_squared_error: 3.3214e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4490e-04 - mean_squared_error: 3.4490e-04 - val_loss: 3.1437e-04 - val_mean_squared_error: 3.1437e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.4459e-04 - mean_squared_error: 3.4459e-04 - val_loss: 3.3537e-04 - val_mean_squared_error: 3.3537e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4515e-04 - mean_squared_error: 3.4515e-04 - val_loss: 3.1754e-04 - val_mean_squared_error: 3.1754e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4443e-04 - mean_squared_error: 3.4443e-04 - val_loss: 3.9434e-04 - val_mean_squared_error: 3.9434e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4345e-04 - mean_squared_error: 3.4345e-04 - val_loss: 3.9947e-04 - val_mean_squared_error: 3.9947e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4367e-04 - mean_squared_error: 3.4367e-04 - val_loss: 3.1197e-04 - val_mean_squared_error: 3.1197e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4382e-04 - mean_squared_error: 3.4382e-04 - val_loss: 3.1314e-04 - val_mean_squared_error: 3.1314e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4244e-04 - mean_squared_error: 3.4244e-04 - val_loss: 3.5226e-04 - val_mean_squared_error: 3.5226e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.4292e-04 - mean_squared_error: 3.4292e-04 - val_loss: 3.5481e-04 - val_mean_squared_error: 3.5481e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4229e-04 - mean_squared_error: 3.4229e-04 - val_loss: 3.5349e-04 - val_mean_squared_error: 3.5349e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4153e-04 - mean_squared_error: 3.4153e-04 - val_loss: 3.1598e-04 - val_mean_squared_error: 3.1598e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4262e-04 - mean_squared_error: 3.4262e-04 - val_loss: 3.2200e-04 - val_mean_squared_error: 3.2200e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4237e-04 - mean_squared_error: 3.4237e-04 - val_loss: 4.2337e-04 - val_mean_squared_error: 4.2337e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4220e-04 - mean_squared_error: 3.4220e-04 - val_loss: 3.9444e-04 - val_mean_squared_error: 3.9444e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4121e-04 - mean_squared_error: 3.4121e-04 - val_loss: 3.3082e-04 - val_mean_squared_error: 3.3082e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4026e-04 - mean_squared_error: 3.4026e-04 - val_loss: 3.4876e-04 - val_mean_squared_error: 3.4876e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4113e-04 - mean_squared_error: 3.4113e-04 - val_loss: 3.2108e-04 - val_mean_squared_error: 3.2108e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4047e-04 - mean_squared_error: 3.4047e-04 - val_loss: 3.7123e-04 - val_mean_squared_error: 3.7123e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4124e-04 - mean_squared_error: 3.4124e-04 - val_loss: 3.1338e-04 - val_mean_squared_error: 3.1338e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3962e-04 - mean_squared_error: 3.3962e-04 - val_loss: 3.6202e-04 - val_mean_squared_error: 3.6202e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4037e-04 - mean_squared_error: 3.4037e-04 - val_loss: 3.7994e-04 - val_mean_squared_error: 3.7994e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4044e-04 - mean_squared_error: 3.4044e-04 - val_loss: 3.1995e-04 - val_mean_squared_error: 3.1995e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3865e-04 - mean_squared_error: 3.3865e-04 - val_loss: 3.1946e-04 - val_mean_squared_error: 3.1946e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3914e-04 - mean_squared_error: 3.3914e-04 - val_loss: 3.7031e-04 - val_mean_squared_error: 3.7031e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3811e-04 - mean_squared_error: 3.3811e-04 - val_loss: 3.5295e-04 - val_mean_squared_error: 3.5295e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3871e-04 - mean_squared_error: 3.3871e-04 - val_loss: 3.2072e-04 - val_mean_squared_error: 3.2072e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3853e-04 - mean_squared_error: 3.3853e-04 - val_loss: 3.4086e-04 - val_mean_squared_error: 3.4086e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3788e-04 - mean_squared_error: 3.3788e-04 - val_loss: 3.2632e-04 - val_mean_squared_error: 3.2632e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3785e-04 - mean_squared_error: 3.3785e-04 - val_loss: 3.4988e-04 - val_mean_squared_error: 3.4988e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3805e-04 - mean_squared_error: 3.3805e-04 - val_loss: 3.3947e-04 - val_mean_squared_error: 3.3947e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3797e-04 - mean_squared_error: 3.3797e-04 - val_loss: 2.8605e-04 - val_mean_squared_error: 2.8605e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3757e-04 - mean_squared_error: 3.3757e-04 - val_loss: 3.3023e-04 - val_mean_squared_error: 3.3023e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.3681e-04 - mean_squared_error: 3.3681e-04 - val_loss: 3.2517e-04 - val_mean_squared_error: 3.2517e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.3627e-04 - mean_squared_error: 3.3627e-04 - val_loss: 3.5053e-04 - val_mean_squared_error: 3.5053e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.3669e-04 - mean_squared_error: 3.3669e-04 - val_loss: 3.2836e-04 - val_mean_squared_error: 3.2836e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3634e-04 - mean_squared_error: 3.3634e-04 - val_loss: 3.4322e-04 - val_mean_squared_error: 3.4322e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3634e-04 - mean_squared_error: 3.3634e-04 - val_loss: 3.8345e-04 - val_mean_squared_error: 3.8345e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3554e-04 - mean_squared_error: 3.3554e-04 - val_loss: 2.8520e-04 - val_mean_squared_error: 2.8520e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.3617e-04 - mean_squared_error: 3.3617e-04 - val_loss: 3.4127e-04 - val_mean_squared_error: 3.4127e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3398e-04 - mean_squared_error: 3.3398e-04 - val_loss: 3.8574e-04 - val_mean_squared_error: 3.8574e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3643e-04 - mean_squared_error: 3.3643e-04 - val_loss: 3.0769e-04 - val_mean_squared_error: 3.0769e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3400e-04 - mean_squared_error: 3.3400e-04 - val_loss: 3.3169e-04 - val_mean_squared_error: 3.3169e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3562e-04 - mean_squared_error: 3.3562e-04 - val_loss: 3.5840e-04 - val_mean_squared_error: 3.5840e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3342e-04 - mean_squared_error: 3.3342e-04 - val_loss: 3.6486e-04 - val_mean_squared_error: 3.6486e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3451e-04 - mean_squared_error: 3.3451e-04 - val_loss: 3.6790e-04 - val_mean_squared_error: 3.6790e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3455e-04 - mean_squared_error: 3.3455e-04 - val_loss: 3.4743e-04 - val_mean_squared_error: 3.4743e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3420e-04 - mean_squared_error: 3.3420e-04 - val_loss: 3.3344e-04 - val_mean_squared_error: 3.3344e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3363e-04 - mean_squared_error: 3.3363e-04 - val_loss: 2.7204e-04 - val_mean_squared_error: 2.7204e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3316e-04 - mean_squared_error: 3.3316e-04 - val_loss: 3.5297e-04 - val_mean_squared_error: 3.5297e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3364e-04 - mean_squared_error: 3.3364e-04 - val_loss: 3.6915e-04 - val_mean_squared_error: 3.6915e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3287e-04 - mean_squared_error: 3.3287e-04 - val_loss: 3.2254e-04 - val_mean_squared_error: 3.2254e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3152e-04 - mean_squared_error: 3.3152e-04 - val_loss: 3.1203e-04 - val_mean_squared_error: 3.1203e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3292e-04 - mean_squared_error: 3.3292e-04 - val_loss: 3.6032e-04 - val_mean_squared_error: 3.6032e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3258e-04 - mean_squared_error: 3.3258e-04 - val_loss: 3.0832e-04 - val_mean_squared_error: 3.0832e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3123e-04 - mean_squared_error: 3.3123e-04 - val_loss: 3.9448e-04 - val_mean_squared_error: 3.9448e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3215e-04 - mean_squared_error: 3.3215e-04 - val_loss: 3.4995e-04 - val_mean_squared_error: 3.4995e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3101e-04 - mean_squared_error: 3.3101e-04 - val_loss: 3.5690e-04 - val_mean_squared_error: 3.5690e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3180e-04 - mean_squared_error: 3.3180e-04 - val_loss: 3.3484e-04 - val_mean_squared_error: 3.3484e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3046e-04 - mean_squared_error: 3.3046e-04 - val_loss: 3.3435e-04 - val_mean_squared_error: 3.3435e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3100e-04 - mean_squared_error: 3.3100e-04 - val_loss: 3.3659e-04 - val_mean_squared_error: 3.3659e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3027e-04 - mean_squared_error: 3.3027e-04 - val_loss: 3.0409e-04 - val_mean_squared_error: 3.0409e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3068e-04 - mean_squared_error: 3.3068e-04 - val_loss: 3.9798e-04 - val_mean_squared_error: 3.9798e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3081e-04 - mean_squared_error: 3.3081e-04 - val_loss: 3.2717e-04 - val_mean_squared_error: 3.2717e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2980e-04 - mean_squared_error: 3.2980e-04 - val_loss: 3.3555e-04 - val_mean_squared_error: 3.3555e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3075e-04 - mean_squared_error: 3.3075e-04 - val_loss: 3.0100e-04 - val_mean_squared_error: 3.0100e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2972e-04 - mean_squared_error: 3.2972e-04 - val_loss: 3.1008e-04 - val_mean_squared_error: 3.1008e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3002e-04 - mean_squared_error: 3.3002e-04 - val_loss: 2.9006e-04 - val_mean_squared_error: 2.9006e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.2892e-04 - mean_squared_error: 3.2892e-04 - val_loss: 2.8770e-04 - val_mean_squared_error: 2.8770e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2930e-04 - mean_squared_error: 3.2930e-04 - val_loss: 3.0229e-04 - val_mean_squared_error: 3.0229e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.2861e-04 - mean_squared_error: 3.2861e-04 - val_loss: 3.5906e-04 - val_mean_squared_error: 3.5906e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2790e-04 - mean_squared_error: 3.2790e-04 - val_loss: 2.8627e-04 - val_mean_squared_error: 2.8627e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.2895e-04 - mean_squared_error: 3.2895e-04 - val_loss: 3.0061e-04 - val_mean_squared_error: 3.0061e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.2814e-04 - mean_squared_error: 3.2814e-04 - val_loss: 3.4880e-04 - val_mean_squared_error: 3.4880e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2776e-04 - mean_squared_error: 3.2776e-04 - val_loss: 2.9718e-04 - val_mean_squared_error: 2.9718e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2793e-04 - mean_squared_error: 3.2793e-04 - val_loss: 3.4211e-04 - val_mean_squared_error: 3.4211e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2740e-04 - mean_squared_error: 3.2740e-04 - val_loss: 3.3176e-04 - val_mean_squared_error: 3.3176e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2697e-04 - mean_squared_error: 3.2697e-04 - val_loss: 3.3572e-04 - val_mean_squared_error: 3.3572e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2720e-04 - mean_squared_error: 3.2720e-04 - val_loss: 3.8945e-04 - val_mean_squared_error: 3.8945e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2715e-04 - mean_squared_error: 3.2715e-04 - val_loss: 3.3288e-04 - val_mean_squared_error: 3.3288e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2671e-04 - mean_squared_error: 3.2671e-04 - val_loss: 2.9198e-04 - val_mean_squared_error: 2.9198e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2632e-04 - mean_squared_error: 3.2632e-04 - val_loss: 2.7651e-04 - val_mean_squared_error: 2.7651e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2655e-04 - mean_squared_error: 3.2655e-04 - val_loss: 2.8635e-04 - val_mean_squared_error: 2.8635e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2463e-04 - mean_squared_error: 3.2463e-04 - val_loss: 3.4672e-04 - val_mean_squared_error: 3.4672e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2589e-04 - mean_squared_error: 3.2589e-04 - val_loss: 3.2583e-04 - val_mean_squared_error: 3.2583e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2513e-04 - mean_squared_error: 3.2513e-04 - val_loss: 3.4837e-04 - val_mean_squared_error: 3.4837e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2532e-04 - mean_squared_error: 3.2532e-04 - val_loss: 2.7024e-04 - val_mean_squared_error: 2.7024e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2462e-04 - mean_squared_error: 3.2462e-04 - val_loss: 3.5734e-04 - val_mean_squared_error: 3.5734e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2394e-04 - mean_squared_error: 3.2394e-04 - val_loss: 2.9288e-04 - val_mean_squared_error: 2.9288e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2591e-04 - mean_squared_error: 3.2591e-04 - val_loss: 3.0859e-04 - val_mean_squared_error: 3.0859e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2469e-04 - mean_squared_error: 3.2469e-04 - val_loss: 2.9019e-04 - val_mean_squared_error: 2.9019e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2432e-04 - mean_squared_error: 3.2432e-04 - val_loss: 3.6197e-04 - val_mean_squared_error: 3.6197e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2466e-04 - mean_squared_error: 3.2466e-04 - val_loss: 3.2374e-04 - val_mean_squared_error: 3.2374e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2308e-04 - mean_squared_error: 3.2308e-04 - val_loss: 3.2055e-04 - val_mean_squared_error: 3.2055e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2202e-04 - mean_squared_error: 3.2202e-04 - val_loss: 3.3474e-04 - val_mean_squared_error: 3.3474e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2337e-04 - mean_squared_error: 3.2337e-04 - val_loss: 3.0427e-04 - val_mean_squared_error: 3.0427e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2265e-04 - mean_squared_error: 3.2265e-04 - val_loss: 3.2239e-04 - val_mean_squared_error: 3.2239e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2348e-04 - mean_squared_error: 3.2348e-04 - val_loss: 3.5458e-04 - val_mean_squared_error: 3.5458e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2216e-04 - mean_squared_error: 3.2216e-04 - val_loss: 3.9331e-04 - val_mean_squared_error: 3.9331e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2295e-04 - mean_squared_error: 3.2295e-04 - val_loss: 2.6944e-04 - val_mean_squared_error: 2.6944e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2280e-04 - mean_squared_error: 3.2280e-04 - val_loss: 3.2443e-04 - val_mean_squared_error: 3.2443e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2291e-04 - mean_squared_error: 3.2291e-04 - val_loss: 2.8481e-04 - val_mean_squared_error: 2.8481e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2130e-04 - mean_squared_error: 3.2130e-04 - val_loss: 3.8172e-04 - val_mean_squared_error: 3.8172e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2255e-04 - mean_squared_error: 3.2255e-04 - val_loss: 3.1815e-04 - val_mean_squared_error: 3.1815e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2080e-04 - mean_squared_error: 3.2080e-04 - val_loss: 2.8946e-04 - val_mean_squared_error: 2.8946e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2155e-04 - mean_squared_error: 3.2155e-04 - val_loss: 3.2206e-04 - val_mean_squared_error: 3.2206e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2122e-04 - mean_squared_error: 3.2122e-04 - val_loss: 2.9969e-04 - val_mean_squared_error: 2.9969e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2075e-04 - mean_squared_error: 3.2075e-04 - val_loss: 3.7495e-04 - val_mean_squared_error: 3.7495e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1987e-04 - mean_squared_error: 3.1987e-04 - val_loss: 3.7088e-04 - val_mean_squared_error: 3.7088e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2078e-04 - mean_squared_error: 3.2078e-04 - val_loss: 2.8679e-04 - val_mean_squared_error: 2.8679e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2042e-04 - mean_squared_error: 3.2042e-04 - val_loss: 2.7091e-04 - val_mean_squared_error: 2.7091e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1980e-04 - mean_squared_error: 3.1980e-04 - val_loss: 2.9491e-04 - val_mean_squared_error: 2.9491e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2064e-04 - mean_squared_error: 3.2064e-04 - val_loss: 3.0232e-04 - val_mean_squared_error: 3.0232e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.1889e-04 - mean_squared_error: 3.1889e-04 - val_loss: 2.9776e-04 - val_mean_squared_error: 2.9776e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1981e-04 - mean_squared_error: 3.1981e-04 - val_loss: 3.4548e-04 - val_mean_squared_error: 3.4548e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1974e-04 - mean_squared_error: 3.1974e-04 - val_loss: 3.1492e-04 - val_mean_squared_error: 3.1492e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1891e-04 - mean_squared_error: 3.1891e-04 - val_loss: 3.4622e-04 - val_mean_squared_error: 3.4622e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1882e-04 - mean_squared_error: 3.1882e-04 - val_loss: 3.2506e-04 - val_mean_squared_error: 3.2506e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1883e-04 - mean_squared_error: 3.1883e-04 - val_loss: 2.8867e-04 - val_mean_squared_error: 2.8867e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1888e-04 - mean_squared_error: 3.1888e-04 - val_loss: 3.5402e-04 - val_mean_squared_error: 3.5402e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1802e-04 - mean_squared_error: 3.1802e-04 - val_loss: 3.9201e-04 - val_mean_squared_error: 3.9201e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1826e-04 - mean_squared_error: 3.1826e-04 - val_loss: 3.2563e-04 - val_mean_squared_error: 3.2563e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1794e-04 - mean_squared_error: 3.1794e-04 - val_loss: 2.8860e-04 - val_mean_squared_error: 2.8860e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1815e-04 - mean_squared_error: 3.1815e-04 - val_loss: 2.6474e-04 - val_mean_squared_error: 2.6474e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1727e-04 - mean_squared_error: 3.1727e-04 - val_loss: 2.6029e-04 - val_mean_squared_error: 2.6029e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1806e-04 - mean_squared_error: 3.1806e-04 - val_loss: 2.8140e-04 - val_mean_squared_error: 2.8140e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1757e-04 - mean_squared_error: 3.1757e-04 - val_loss: 3.3804e-04 - val_mean_squared_error: 3.3804e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1747e-04 - mean_squared_error: 3.1747e-04 - val_loss: 2.9588e-04 - val_mean_squared_error: 2.9588e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1644e-04 - mean_squared_error: 3.1644e-04 - val_loss: 2.8868e-04 - val_mean_squared_error: 2.8868e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1687e-04 - mean_squared_error: 3.1687e-04 - val_loss: 2.8838e-04 - val_mean_squared_error: 2.8838e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1653e-04 - mean_squared_error: 3.1653e-04 - val_loss: 3.4196e-04 - val_mean_squared_error: 3.4196e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1665e-04 - mean_squared_error: 3.1665e-04 - val_loss: 3.3588e-04 - val_mean_squared_error: 3.3588e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1618e-04 - mean_squared_error: 3.1618e-04 - val_loss: 2.7508e-04 - val_mean_squared_error: 2.7508e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1586e-04 - mean_squared_error: 3.1586e-04 - val_loss: 3.0872e-04 - val_mean_squared_error: 3.0872e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1577e-04 - mean_squared_error: 3.1577e-04 - val_loss: 3.2050e-04 - val_mean_squared_error: 3.2050e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1642e-04 - mean_squared_error: 3.1642e-04 - val_loss: 3.3565e-04 - val_mean_squared_error: 3.3565e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1544e-04 - mean_squared_error: 3.1544e-04 - val_loss: 2.9768e-04 - val_mean_squared_error: 2.9768e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1537e-04 - mean_squared_error: 3.1537e-04 - val_loss: 3.0503e-04 - val_mean_squared_error: 3.0503e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1506e-04 - mean_squared_error: 3.1506e-04 - val_loss: 3.2608e-04 - val_mean_squared_error: 3.2608e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1469e-04 - mean_squared_error: 3.1469e-04 - val_loss: 3.2566e-04 - val_mean_squared_error: 3.2566e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1506e-04 - mean_squared_error: 3.1506e-04 - val_loss: 3.0416e-04 - val_mean_squared_error: 3.0416e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1422e-04 - mean_squared_error: 3.1422e-04 - val_loss: 2.8120e-04 - val_mean_squared_error: 2.8120e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1400e-04 - mean_squared_error: 3.1400e-04 - val_loss: 3.1688e-04 - val_mean_squared_error: 3.1688e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1440e-04 - mean_squared_error: 3.1440e-04 - val_loss: 2.7343e-04 - val_mean_squared_error: 2.7343e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1378e-04 - mean_squared_error: 3.1378e-04 - val_loss: 2.7132e-04 - val_mean_squared_error: 2.7132e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1374e-04 - mean_squared_error: 3.1374e-04 - val_loss: 3.2183e-04 - val_mean_squared_error: 3.2183e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1389e-04 - mean_squared_error: 3.1389e-04 - val_loss: 3.1632e-04 - val_mean_squared_error: 3.1632e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1415e-04 - mean_squared_error: 3.1415e-04 - val_loss: 3.1006e-04 - val_mean_squared_error: 3.1006e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1265e-04 - mean_squared_error: 3.1265e-04 - val_loss: 2.6778e-04 - val_mean_squared_error: 2.6778e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1330e-04 - mean_squared_error: 3.1330e-04 - val_loss: 3.2670e-04 - val_mean_squared_error: 3.2670e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1234e-04 - mean_squared_error: 3.1234e-04 - val_loss: 3.3950e-04 - val_mean_squared_error: 3.3950e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1361e-04 - mean_squared_error: 3.1361e-04 - val_loss: 2.4289e-04 - val_mean_squared_error: 2.4289e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1281e-04 - mean_squared_error: 3.1281e-04 - val_loss: 2.8198e-04 - val_mean_squared_error: 2.8198e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1226e-04 - mean_squared_error: 3.1226e-04 - val_loss: 3.0212e-04 - val_mean_squared_error: 3.0212e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1279e-04 - mean_squared_error: 3.1279e-04 - val_loss: 3.4465e-04 - val_mean_squared_error: 3.4465e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1264e-04 - mean_squared_error: 3.1264e-04 - val_loss: 3.2014e-04 - val_mean_squared_error: 3.2014e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1273e-04 - mean_squared_error: 3.1273e-04 - val_loss: 2.9035e-04 - val_mean_squared_error: 2.9035e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1293e-04 - mean_squared_error: 3.1293e-04 - val_loss: 2.8799e-04 - val_mean_squared_error: 2.8799e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 3.1148e-04 - mean_squared_error: 3.1148e-04 - val_loss: 3.4442e-04 - val_mean_squared_error: 3.4442e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1155e-04 - mean_squared_error: 3.1155e-04 - val_loss: 3.1005e-04 - val_mean_squared_error: 3.1005e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1227e-04 - mean_squared_error: 3.1227e-04 - val_loss: 3.0267e-04 - val_mean_squared_error: 3.0267e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1155e-04 - mean_squared_error: 3.1155e-04 - val_loss: 3.1233e-04 - val_mean_squared_error: 3.1233e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1131e-04 - mean_squared_error: 3.1131e-04 - val_loss: 2.6921e-04 - val_mean_squared_error: 2.6921e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1086e-04 - mean_squared_error: 3.1086e-04 - val_loss: 2.9104e-04 - val_mean_squared_error: 2.9104e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1053e-04 - mean_squared_error: 3.1053e-04 - val_loss: 3.2159e-04 - val_mean_squared_error: 3.2159e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1047e-04 - mean_squared_error: 3.1047e-04 - val_loss: 3.3020e-04 - val_mean_squared_error: 3.3020e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1129e-04 - mean_squared_error: 3.1129e-04 - val_loss: 2.8588e-04 - val_mean_squared_error: 2.8588e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1039e-04 - mean_squared_error: 3.1039e-04 - val_loss: 3.3558e-04 - val_mean_squared_error: 3.3558e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0929e-04 - mean_squared_error: 3.0929e-04 - val_loss: 3.2346e-04 - val_mean_squared_error: 3.2346e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1057e-04 - mean_squared_error: 3.1057e-04 - val_loss: 3.0853e-04 - val_mean_squared_error: 3.0853e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0994e-04 - mean_squared_error: 3.0994e-04 - val_loss: 2.8715e-04 - val_mean_squared_error: 2.8715e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0951e-04 - mean_squared_error: 3.0951e-04 - val_loss: 2.9128e-04 - val_mean_squared_error: 2.9128e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0968e-04 - mean_squared_error: 3.0968e-04 - val_loss: 4.0415e-04 - val_mean_squared_error: 4.0415e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0946e-04 - mean_squared_error: 3.0946e-04 - val_loss: 2.9635e-04 - val_mean_squared_error: 2.9635e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0946e-04 - mean_squared_error: 3.0946e-04 - val_loss: 2.8350e-04 - val_mean_squared_error: 2.8350e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0888e-04 - mean_squared_error: 3.0888e-04 - val_loss: 3.4933e-04 - val_mean_squared_error: 3.4933e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0839e-04 - mean_squared_error: 3.0839e-04 - val_loss: 3.0946e-04 - val_mean_squared_error: 3.0946e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0914e-04 - mean_squared_error: 3.0914e-04 - val_loss: 2.8218e-04 - val_mean_squared_error: 2.8218e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0844e-04 - mean_squared_error: 3.0844e-04 - val_loss: 2.7512e-04 - val_mean_squared_error: 2.7512e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0862e-04 - mean_squared_error: 3.0862e-04 - val_loss: 2.3541e-04 - val_mean_squared_error: 2.3541e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0828e-04 - mean_squared_error: 3.0828e-04 - val_loss: 3.0107e-04 - val_mean_squared_error: 3.0107e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0715e-04 - mean_squared_error: 3.0715e-04 - val_loss: 2.9643e-04 - val_mean_squared_error: 2.9643e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0771e-04 - mean_squared_error: 3.0771e-04 - val_loss: 3.1912e-04 - val_mean_squared_error: 3.1912e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0830e-04 - mean_squared_error: 3.0830e-04 - val_loss: 3.6200e-04 - val_mean_squared_error: 3.6200e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0740e-04 - mean_squared_error: 3.0740e-04 - val_loss: 3.5772e-04 - val_mean_squared_error: 3.5772e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0742e-04 - mean_squared_error: 3.0742e-04 - val_loss: 3.4488e-04 - val_mean_squared_error: 3.4488e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0751e-04 - mean_squared_error: 3.0751e-04 - val_loss: 2.7877e-04 - val_mean_squared_error: 2.7877e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0697e-04 - mean_squared_error: 3.0697e-04 - val_loss: 2.9658e-04 - val_mean_squared_error: 2.9658e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0715e-04 - mean_squared_error: 3.0715e-04 - val_loss: 2.8328e-04 - val_mean_squared_error: 2.8328e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0610e-04 - mean_squared_error: 3.0610e-04 - val_loss: 3.1161e-04 - val_mean_squared_error: 3.1161e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0728e-04 - mean_squared_error: 3.0728e-04 - val_loss: 2.6192e-04 - val_mean_squared_error: 2.6192e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0609e-04 - mean_squared_error: 3.0609e-04 - val_loss: 3.1670e-04 - val_mean_squared_error: 3.1670e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0702e-04 - mean_squared_error: 3.0702e-04 - val_loss: 2.7795e-04 - val_mean_squared_error: 2.7795e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0588e-04 - mean_squared_error: 3.0588e-04 - val_loss: 3.0499e-04 - val_mean_squared_error: 3.0499e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0659e-04 - mean_squared_error: 3.0659e-04 - val_loss: 3.1859e-04 - val_mean_squared_error: 3.1859e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0587e-04 - mean_squared_error: 3.0587e-04 - val_loss: 2.8902e-04 - val_mean_squared_error: 2.8902e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0549e-04 - mean_squared_error: 3.0549e-04 - val_loss: 2.8456e-04 - val_mean_squared_error: 2.8456e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0560e-04 - mean_squared_error: 3.0560e-04 - val_loss: 3.1967e-04 - val_mean_squared_error: 3.1967e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0558e-04 - mean_squared_error: 3.0558e-04 - val_loss: 2.8688e-04 - val_mean_squared_error: 2.8688e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0436e-04 - mean_squared_error: 3.0436e-04 - val_loss: 3.7122e-04 - val_mean_squared_error: 3.7122e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0520e-04 - mean_squared_error: 3.0520e-04 - val_loss: 3.0827e-04 - val_mean_squared_error: 3.0827e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0450e-04 - mean_squared_error: 3.0450e-04 - val_loss: 3.3072e-04 - val_mean_squared_error: 3.3072e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0515e-04 - mean_squared_error: 3.0515e-04 - val_loss: 3.0809e-04 - val_mean_squared_error: 3.0809e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0436e-04 - mean_squared_error: 3.0436e-04 - val_loss: 3.1398e-04 - val_mean_squared_error: 3.1398e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0435e-04 - mean_squared_error: 3.0435e-04 - val_loss: 2.8853e-04 - val_mean_squared_error: 2.8853e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0399e-04 - mean_squared_error: 3.0399e-04 - val_loss: 3.1435e-04 - val_mean_squared_error: 3.1435e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0447e-04 - mean_squared_error: 3.0447e-04 - val_loss: 3.7432e-04 - val_mean_squared_error: 3.7432e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0358e-04 - mean_squared_error: 3.0358e-04 - val_loss: 3.0048e-04 - val_mean_squared_error: 3.0048e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0340e-04 - mean_squared_error: 3.0340e-04 - val_loss: 3.0380e-04 - val_mean_squared_error: 3.0380e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0343e-04 - mean_squared_error: 3.0343e-04 - val_loss: 3.6007e-04 - val_mean_squared_error: 3.6007e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0424e-04 - mean_squared_error: 3.0424e-04 - val_loss: 2.6297e-04 - val_mean_squared_error: 2.6297e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0359e-04 - mean_squared_error: 3.0359e-04 - val_loss: 2.9841e-04 - val_mean_squared_error: 2.9841e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0341e-04 - mean_squared_error: 3.0341e-04 - val_loss: 3.0558e-04 - val_mean_squared_error: 3.0558e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0352e-04 - mean_squared_error: 3.0352e-04 - val_loss: 2.8540e-04 - val_mean_squared_error: 2.8540e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0296e-04 - mean_squared_error: 3.0296e-04 - val_loss: 2.7225e-04 - val_mean_squared_error: 2.7225e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0234e-04 - mean_squared_error: 3.0234e-04 - val_loss: 2.8479e-04 - val_mean_squared_error: 2.8479e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0266e-04 - mean_squared_error: 3.0266e-04 - val_loss: 2.7121e-04 - val_mean_squared_error: 2.7121e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0271e-04 - mean_squared_error: 3.0271e-04 - val_loss: 2.9285e-04 - val_mean_squared_error: 2.9285e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0186e-04 - mean_squared_error: 3.0186e-04 - val_loss: 4.1866e-04 - val_mean_squared_error: 4.1866e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0286e-04 - mean_squared_error: 3.0286e-04 - val_loss: 3.4105e-04 - val_mean_squared_error: 3.4105e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0197e-04 - mean_squared_error: 3.0197e-04 - val_loss: 2.8201e-04 - val_mean_squared_error: 2.8201e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0207e-04 - mean_squared_error: 3.0207e-04 - val_loss: 2.7316e-04 - val_mean_squared_error: 2.7316e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0206e-04 - mean_squared_error: 3.0206e-04 - val_loss: 3.0689e-04 - val_mean_squared_error: 3.0689e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0193e-04 - mean_squared_error: 3.0193e-04 - val_loss: 2.7799e-04 - val_mean_squared_error: 2.7799e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0088e-04 - mean_squared_error: 3.0088e-04 - val_loss: 3.3636e-04 - val_mean_squared_error: 3.3636e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0090e-04 - mean_squared_error: 3.0090e-04 - val_loss: 3.0334e-04 - val_mean_squared_error: 3.0334e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0071e-04 - mean_squared_error: 3.0071e-04 - val_loss: 2.6900e-04 - val_mean_squared_error: 2.6900e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0110e-04 - mean_squared_error: 3.0110e-04 - val_loss: 2.5629e-04 - val_mean_squared_error: 2.5629e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0111e-04 - mean_squared_error: 3.0111e-04 - val_loss: 2.8510e-04 - val_mean_squared_error: 2.8510e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0093e-04 - mean_squared_error: 3.0093e-04 - val_loss: 3.3079e-04 - val_mean_squared_error: 3.3079e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0099e-04 - mean_squared_error: 3.0099e-04 - val_loss: 3.0427e-04 - val_mean_squared_error: 3.0427e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0002e-04 - mean_squared_error: 3.0002e-04 - val_loss: 2.8284e-04 - val_mean_squared_error: 2.8284e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0018e-04 - mean_squared_error: 3.0018e-04 - val_loss: 2.8781e-04 - val_mean_squared_error: 2.8781e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0064e-04 - mean_squared_error: 3.0064e-04 - val_loss: 2.9100e-04 - val_mean_squared_error: 2.9100e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0028e-04 - mean_squared_error: 3.0028e-04 - val_loss: 3.2714e-04 - val_mean_squared_error: 3.2714e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9987e-04 - mean_squared_error: 2.9987e-04 - val_loss: 2.6350e-04 - val_mean_squared_error: 2.6350e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9912e-04 - mean_squared_error: 2.9912e-04 - val_loss: 3.1704e-04 - val_mean_squared_error: 3.1704e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 2.9937e-04 - mean_squared_error: 2.9937e-04 - val_loss: 2.7318e-04 - val_mean_squared_error: 2.7318e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9974e-04 - mean_squared_error: 2.9974e-04 - val_loss: 2.8145e-04 - val_mean_squared_error: 2.8145e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9895e-04 - mean_squared_error: 2.9895e-04 - val_loss: 2.8219e-04 - val_mean_squared_error: 2.8219e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9959e-04 - mean_squared_error: 2.9959e-04 - val_loss: 2.9718e-04 - val_mean_squared_error: 2.9718e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9876e-04 - mean_squared_error: 2.9876e-04 - val_loss: 3.0275e-04 - val_mean_squared_error: 3.0275e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9873e-04 - mean_squared_error: 2.9873e-04 - val_loss: 3.6354e-04 - val_mean_squared_error: 3.6354e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9889e-04 - mean_squared_error: 2.9889e-04 - val_loss: 3.1889e-04 - val_mean_squared_error: 3.1889e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9876e-04 - mean_squared_error: 2.9876e-04 - val_loss: 2.6370e-04 - val_mean_squared_error: 2.6370e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9865e-04 - mean_squared_error: 2.9865e-04 - val_loss: 3.0045e-04 - val_mean_squared_error: 3.0045e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9859e-04 - mean_squared_error: 2.9859e-04 - val_loss: 3.0473e-04 - val_mean_squared_error: 3.0473e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9839e-04 - mean_squared_error: 2.9839e-04 - val_loss: 3.2689e-04 - val_mean_squared_error: 3.2689e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9783e-04 - mean_squared_error: 2.9783e-04 - val_loss: 2.6601e-04 - val_mean_squared_error: 2.6601e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9812e-04 - mean_squared_error: 2.9812e-04 - val_loss: 3.0213e-04 - val_mean_squared_error: 3.0213e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9781e-04 - mean_squared_error: 2.9781e-04 - val_loss: 2.5834e-04 - val_mean_squared_error: 2.5834e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9775e-04 - mean_squared_error: 2.9775e-04 - val_loss: 2.5732e-04 - val_mean_squared_error: 2.5732e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9784e-04 - mean_squared_error: 2.9784e-04 - val_loss: 3.3086e-04 - val_mean_squared_error: 3.3086e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9674e-04 - mean_squared_error: 2.9674e-04 - val_loss: 2.7226e-04 - val_mean_squared_error: 2.7226e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9725e-04 - mean_squared_error: 2.9725e-04 - val_loss: 3.3476e-04 - val_mean_squared_error: 3.3476e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9742e-04 - mean_squared_error: 2.9742e-04 - val_loss: 3.1064e-04 - val_mean_squared_error: 3.1064e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9692e-04 - mean_squared_error: 2.9692e-04 - val_loss: 2.5376e-04 - val_mean_squared_error: 2.5376e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9693e-04 - mean_squared_error: 2.9693e-04 - val_loss: 2.8983e-04 - val_mean_squared_error: 2.8983e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9660e-04 - mean_squared_error: 2.9660e-04 - val_loss: 3.4108e-04 - val_mean_squared_error: 3.4108e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9679e-04 - mean_squared_error: 2.9679e-04 - val_loss: 2.7573e-04 - val_mean_squared_error: 2.7573e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9592e-04 - mean_squared_error: 2.9592e-04 - val_loss: 2.8966e-04 - val_mean_squared_error: 2.8966e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9595e-04 - mean_squared_error: 2.9595e-04 - val_loss: 3.0787e-04 - val_mean_squared_error: 3.0787e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9606e-04 - mean_squared_error: 2.9606e-04 - val_loss: 2.8134e-04 - val_mean_squared_error: 2.8134e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9592e-04 - mean_squared_error: 2.9592e-04 - val_loss: 3.2904e-04 - val_mean_squared_error: 3.2904e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9624e-04 - mean_squared_error: 2.9624e-04 - val_loss: 2.9571e-04 - val_mean_squared_error: 2.9571e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9544e-04 - mean_squared_error: 2.9544e-04 - val_loss: 2.6563e-04 - val_mean_squared_error: 2.6563e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9544e-04 - mean_squared_error: 2.9544e-04 - val_loss: 2.6761e-04 - val_mean_squared_error: 2.6761e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9642e-04 - mean_squared_error: 2.9642e-04 - val_loss: 2.8652e-04 - val_mean_squared_error: 2.8652e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9406e-04 - mean_squared_error: 2.9406e-04 - val_loss: 3.1694e-04 - val_mean_squared_error: 3.1694e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9509e-04 - mean_squared_error: 2.9509e-04 - val_loss: 3.4850e-04 - val_mean_squared_error: 3.4850e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9503e-04 - mean_squared_error: 2.9503e-04 - val_loss: 3.0168e-04 - val_mean_squared_error: 3.0168e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9524e-04 - mean_squared_error: 2.9524e-04 - val_loss: 2.6584e-04 - val_mean_squared_error: 2.6584e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9460e-04 - mean_squared_error: 2.9460e-04 - val_loss: 2.6684e-04 - val_mean_squared_error: 2.6684e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9358e-04 - mean_squared_error: 2.9358e-04 - val_loss: 3.0993e-04 - val_mean_squared_error: 3.0993e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9527e-04 - mean_squared_error: 2.9527e-04 - val_loss: 2.8535e-04 - val_mean_squared_error: 2.8535e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9451e-04 - mean_squared_error: 2.9451e-04 - val_loss: 2.5223e-04 - val_mean_squared_error: 2.5223e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9357e-04 - mean_squared_error: 2.9357e-04 - val_loss: 3.1517e-04 - val_mean_squared_error: 3.1517e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9443e-04 - mean_squared_error: 2.9443e-04 - val_loss: 2.9549e-04 - val_mean_squared_error: 2.9549e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9432e-04 - mean_squared_error: 2.9432e-04 - val_loss: 2.2385e-04 - val_mean_squared_error: 2.2385e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9363e-04 - mean_squared_error: 2.9363e-04 - val_loss: 3.1468e-04 - val_mean_squared_error: 3.1468e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9394e-04 - mean_squared_error: 2.9394e-04 - val_loss: 2.8684e-04 - val_mean_squared_error: 2.8684e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9356e-04 - mean_squared_error: 2.9356e-04 - val_loss: 2.6896e-04 - val_mean_squared_error: 2.6896e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9338e-04 - mean_squared_error: 2.9338e-04 - val_loss: 2.7214e-04 - val_mean_squared_error: 2.7214e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9314e-04 - mean_squared_error: 2.9314e-04 - val_loss: 2.5764e-04 - val_mean_squared_error: 2.5764e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9327e-04 - mean_squared_error: 2.9327e-04 - val_loss: 3.0423e-04 - val_mean_squared_error: 3.0423e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9322e-04 - mean_squared_error: 2.9322e-04 - val_loss: 2.9315e-04 - val_mean_squared_error: 2.9315e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9253e-04 - mean_squared_error: 2.9253e-04 - val_loss: 2.9763e-04 - val_mean_squared_error: 2.9763e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9338e-04 - mean_squared_error: 2.9338e-04 - val_loss: 3.2172e-04 - val_mean_squared_error: 3.2172e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9250e-04 - mean_squared_error: 2.9250e-04 - val_loss: 3.3161e-04 - val_mean_squared_error: 3.3161e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9286e-04 - mean_squared_error: 2.9286e-04 - val_loss: 2.9245e-04 - val_mean_squared_error: 2.9245e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9259e-04 - mean_squared_error: 2.9259e-04 - val_loss: 2.6781e-04 - val_mean_squared_error: 2.6781e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9210e-04 - mean_squared_error: 2.9210e-04 - val_loss: 2.7855e-04 - val_mean_squared_error: 2.7855e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9295e-04 - mean_squared_error: 2.9295e-04 - val_loss: 2.4404e-04 - val_mean_squared_error: 2.4404e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9161e-04 - mean_squared_error: 2.9161e-04 - val_loss: 3.1811e-04 - val_mean_squared_error: 3.1811e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9207e-04 - mean_squared_error: 2.9207e-04 - val_loss: 2.9955e-04 - val_mean_squared_error: 2.9955e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9175e-04 - mean_squared_error: 2.9175e-04 - val_loss: 3.5264e-04 - val_mean_squared_error: 3.5264e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9227e-04 - mean_squared_error: 2.9227e-04 - val_loss: 2.7921e-04 - val_mean_squared_error: 2.7921e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9167e-04 - mean_squared_error: 2.9167e-04 - val_loss: 3.5930e-04 - val_mean_squared_error: 3.5930e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9124e-04 - mean_squared_error: 2.9124e-04 - val_loss: 2.5239e-04 - val_mean_squared_error: 2.5239e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9149e-04 - mean_squared_error: 2.9149e-04 - val_loss: 3.5810e-04 - val_mean_squared_error: 3.5810e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9140e-04 - mean_squared_error: 2.9140e-04 - val_loss: 2.8984e-04 - val_mean_squared_error: 2.8984e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9061e-04 - mean_squared_error: 2.9061e-04 - val_loss: 3.4960e-04 - val_mean_squared_error: 3.4960e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9024e-04 - mean_squared_error: 2.9024e-04 - val_loss: 2.9765e-04 - val_mean_squared_error: 2.9765e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9129e-04 - mean_squared_error: 2.9129e-04 - val_loss: 2.6573e-04 - val_mean_squared_error: 2.6573e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9044e-04 - mean_squared_error: 2.9044e-04 - val_loss: 3.0652e-04 - val_mean_squared_error: 3.0652e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9064e-04 - mean_squared_error: 2.9064e-04 - val_loss: 2.9800e-04 - val_mean_squared_error: 2.9800e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9040e-04 - mean_squared_error: 2.9040e-04 - val_loss: 3.1943e-04 - val_mean_squared_error: 3.1943e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9098e-04 - mean_squared_error: 2.9098e-04 - val_loss: 3.1212e-04 - val_mean_squared_error: 3.1212e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8996e-04 - mean_squared_error: 2.8996e-04 - val_loss: 2.6275e-04 - val_mean_squared_error: 2.6275e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9056e-04 - mean_squared_error: 2.9056e-04 - val_loss: 2.8905e-04 - val_mean_squared_error: 2.8905e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9015e-04 - mean_squared_error: 2.9015e-04 - val_loss: 2.5447e-04 - val_mean_squared_error: 2.5447e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9037e-04 - mean_squared_error: 2.9037e-04 - val_loss: 2.3497e-04 - val_mean_squared_error: 2.3497e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8887e-04 - mean_squared_error: 2.8887e-04 - val_loss: 2.5621e-04 - val_mean_squared_error: 2.5621e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8984e-04 - mean_squared_error: 2.8984e-04 - val_loss: 2.9958e-04 - val_mean_squared_error: 2.9958e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8923e-04 - mean_squared_error: 2.8923e-04 - val_loss: 2.9202e-04 - val_mean_squared_error: 2.9202e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8936e-04 - mean_squared_error: 2.8936e-04 - val_loss: 3.2114e-04 - val_mean_squared_error: 3.2114e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8880e-04 - mean_squared_error: 2.8880e-04 - val_loss: 3.2625e-04 - val_mean_squared_error: 3.2625e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8927e-04 - mean_squared_error: 2.8927e-04 - val_loss: 2.8530e-04 - val_mean_squared_error: 2.8530e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8902e-04 - mean_squared_error: 2.8902e-04 - val_loss: 2.7939e-04 - val_mean_squared_error: 2.7939e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8853e-04 - mean_squared_error: 2.8853e-04 - val_loss: 2.7253e-04 - val_mean_squared_error: 2.7253e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8877e-04 - mean_squared_error: 2.8877e-04 - val_loss: 2.5860e-04 - val_mean_squared_error: 2.5860e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8830e-04 - mean_squared_error: 2.8830e-04 - val_loss: 2.9834e-04 - val_mean_squared_error: 2.9834e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8888e-04 - mean_squared_error: 2.8888e-04 - val_loss: 2.8378e-04 - val_mean_squared_error: 2.8378e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8868e-04 - mean_squared_error: 2.8868e-04 - val_loss: 2.5118e-04 - val_mean_squared_error: 2.5118e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8750e-04 - mean_squared_error: 2.8750e-04 - val_loss: 2.5631e-04 - val_mean_squared_error: 2.5631e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8803e-04 - mean_squared_error: 2.8803e-04 - val_loss: 2.9297e-04 - val_mean_squared_error: 2.9297e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8792e-04 - mean_squared_error: 2.8792e-04 - val_loss: 2.6450e-04 - val_mean_squared_error: 2.6450e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8762e-04 - mean_squared_error: 2.8762e-04 - val_loss: 3.2751e-04 - val_mean_squared_error: 3.2751e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8830e-04 - mean_squared_error: 2.8830e-04 - val_loss: 3.1595e-04 - val_mean_squared_error: 3.1595e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8735e-04 - mean_squared_error: 2.8735e-04 - val_loss: 2.6086e-04 - val_mean_squared_error: 2.6086e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8789e-04 - mean_squared_error: 2.8789e-04 - val_loss: 2.6283e-04 - val_mean_squared_error: 2.6283e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8680e-04 - mean_squared_error: 2.8680e-04 - val_loss: 2.8358e-04 - val_mean_squared_error: 2.8358e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8706e-04 - mean_squared_error: 2.8706e-04 - val_loss: 2.8793e-04 - val_mean_squared_error: 2.8793e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8734e-04 - mean_squared_error: 2.8734e-04 - val_loss: 2.4315e-04 - val_mean_squared_error: 2.4315e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8738e-04 - mean_squared_error: 2.8738e-04 - val_loss: 2.8413e-04 - val_mean_squared_error: 2.8413e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8683e-04 - mean_squared_error: 2.8683e-04 - val_loss: 2.5495e-04 - val_mean_squared_error: 2.5495e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8705e-04 - mean_squared_error: 2.8705e-04 - val_loss: 2.7329e-04 - val_mean_squared_error: 2.7329e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8642e-04 - mean_squared_error: 2.8642e-04 - val_loss: 3.0160e-04 - val_mean_squared_error: 3.0160e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8539e-04 - mean_squared_error: 2.8539e-04 - val_loss: 3.2623e-04 - val_mean_squared_error: 3.2623e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8680e-04 - mean_squared_error: 2.8680e-04 - val_loss: 2.7566e-04 - val_mean_squared_error: 2.7566e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8667e-04 - mean_squared_error: 2.8667e-04 - val_loss: 2.5716e-04 - val_mean_squared_error: 2.5716e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8566e-04 - mean_squared_error: 2.8566e-04 - val_loss: 3.3829e-04 - val_mean_squared_error: 3.3829e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8603e-04 - mean_squared_error: 2.8603e-04 - val_loss: 2.3903e-04 - val_mean_squared_error: 2.3903e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8612e-04 - mean_squared_error: 2.8612e-04 - val_loss: 2.9992e-04 - val_mean_squared_error: 2.9992e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8550e-04 - mean_squared_error: 2.8550e-04 - val_loss: 2.5346e-04 - val_mean_squared_error: 2.5346e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8525e-04 - mean_squared_error: 2.8525e-04 - val_loss: 2.8873e-04 - val_mean_squared_error: 2.8873e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8581e-04 - mean_squared_error: 2.8581e-04 - val_loss: 2.5317e-04 - val_mean_squared_error: 2.5317e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8579e-04 - mean_squared_error: 2.8579e-04 - val_loss: 3.1567e-04 - val_mean_squared_error: 3.1567e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8561e-04 - mean_squared_error: 2.8561e-04 - val_loss: 3.3200e-04 - val_mean_squared_error: 3.3200e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8498e-04 - mean_squared_error: 2.8498e-04 - val_loss: 2.8074e-04 - val_mean_squared_error: 2.8074e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8450e-04 - mean_squared_error: 2.8450e-04 - val_loss: 2.9880e-04 - val_mean_squared_error: 2.9880e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8501e-04 - mean_squared_error: 2.8501e-04 - val_loss: 2.5795e-04 - val_mean_squared_error: 2.5795e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8506e-04 - mean_squared_error: 2.8506e-04 - val_loss: 3.3049e-04 - val_mean_squared_error: 3.3049e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 2.8448e-04 - mean_squared_error: 2.8448e-04 - val_loss: 2.7284e-04 - val_mean_squared_error: 2.7284e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8425e-04 - mean_squared_error: 2.8425e-04 - val_loss: 2.4736e-04 - val_mean_squared_error: 2.4736e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8463e-04 - mean_squared_error: 2.8463e-04 - val_loss: 2.7463e-04 - val_mean_squared_error: 2.7463e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8448e-04 - mean_squared_error: 2.8448e-04 - val_loss: 2.7008e-04 - val_mean_squared_error: 2.7008e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8453e-04 - mean_squared_error: 2.8453e-04 - val_loss: 2.7770e-04 - val_mean_squared_error: 2.7770e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8416e-04 - mean_squared_error: 2.8416e-04 - val_loss: 2.8094e-04 - val_mean_squared_error: 2.8094e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8320e-04 - mean_squared_error: 2.8320e-04 - val_loss: 3.1511e-04 - val_mean_squared_error: 3.1511e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8402e-04 - mean_squared_error: 2.8402e-04 - val_loss: 2.8318e-04 - val_mean_squared_error: 2.8318e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8349e-04 - mean_squared_error: 2.8349e-04 - val_loss: 2.8908e-04 - val_mean_squared_error: 2.8908e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8383e-04 - mean_squared_error: 2.8383e-04 - val_loss: 3.1755e-04 - val_mean_squared_error: 3.1755e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8319e-04 - mean_squared_error: 2.8319e-04 - val_loss: 3.4432e-04 - val_mean_squared_error: 3.4432e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8367e-04 - mean_squared_error: 2.8367e-04 - val_loss: 3.2317e-04 - val_mean_squared_error: 3.2317e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8394e-04 - mean_squared_error: 2.8394e-04 - val_loss: 2.3371e-04 - val_mean_squared_error: 2.3371e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8257e-04 - mean_squared_error: 2.8257e-04 - val_loss: 3.0905e-04 - val_mean_squared_error: 3.0905e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8377e-04 - mean_squared_error: 2.8377e-04 - val_loss: 3.2357e-04 - val_mean_squared_error: 3.2357e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8342e-04 - mean_squared_error: 2.8342e-04 - val_loss: 2.8250e-04 - val_mean_squared_error: 2.8250e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8251e-04 - mean_squared_error: 2.8251e-04 - val_loss: 2.7957e-04 - val_mean_squared_error: 2.7957e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8214e-04 - mean_squared_error: 2.8214e-04 - val_loss: 2.8173e-04 - val_mean_squared_error: 2.8173e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8286e-04 - mean_squared_error: 2.8286e-04 - val_loss: 2.7266e-04 - val_mean_squared_error: 2.7266e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8238e-04 - mean_squared_error: 2.8238e-04 - val_loss: 2.8616e-04 - val_mean_squared_error: 2.8616e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8248e-04 - mean_squared_error: 2.8248e-04 - val_loss: 2.7140e-04 - val_mean_squared_error: 2.7140e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8271e-04 - mean_squared_error: 2.8271e-04 - val_loss: 2.5378e-04 - val_mean_squared_error: 2.5378e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8189e-04 - mean_squared_error: 2.8189e-04 - val_loss: 2.8913e-04 - val_mean_squared_error: 2.8913e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8180e-04 - mean_squared_error: 2.8180e-04 - val_loss: 2.8729e-04 - val_mean_squared_error: 2.8729e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8187e-04 - mean_squared_error: 2.8187e-04 - val_loss: 2.9122e-04 - val_mean_squared_error: 2.9122e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8231e-04 - mean_squared_error: 2.8231e-04 - val_loss: 2.5196e-04 - val_mean_squared_error: 2.5196e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8118e-04 - mean_squared_error: 2.8118e-04 - val_loss: 2.8054e-04 - val_mean_squared_error: 2.8054e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 4s - loss: 2.8183e-04 - mean_squared_error: 2.8183e-04 - val_loss: 2.8881e-04 - val_mean_squared_error: 2.8881e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8098e-04 - mean_squared_error: 2.8098e-04 - val_loss: 2.4621e-04 - val_mean_squared_error: 2.4621e-04\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8066e-04 - mean_squared_error: 2.8066e-04 - val_loss: 2.9302e-04 - val_mean_squared_error: 2.9302e-04\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17576cee3c8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "for foo in np.arange(1, 1000):\n",
    "    \n",
    "    # # fit model without regularization, and save history and weights at each timestep\n",
    "    history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 1, verbose = 2, \n",
    "                            batch_size=2**14, validation_split = 0.3)\n",
    "\n",
    "\n",
    "    # save history\n",
    "    historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "    historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "    \n",
    "    wts = model.get_weights().copy()\n",
    "    \n",
    "    \n",
    "    #  save model\n",
    "    model.save(os.path.join(figDir,tmpFolder,  modelName + '_notPruned.h5'))\n",
    "\n",
    "    # save weights\n",
    "    wts = model.get_weights().copy()\n",
    "\n",
    "    wtsFile = str(ctr).zfill(4) + modelName + '_wts.pkl'\n",
    "    pickle.dump(wts, open(os.path.join(figDir, tmpFolder, wtsFile), 'wb'))\n",
    "\n",
    "    # save history\n",
    "    histName = modelName + '_history.pkl'\n",
    "    pickle.dump(historyDict, open(os.path.join(figDir,tmpFolder, histName), 'wb'))\n",
    "\n",
    "#     if np.mod(foo, 3) == 0:\n",
    "    saveWeightImages(model, ctr)\n",
    "    ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make movie:\n",
    "\n",
    "# make into video\n",
    "os.chdir(os.path.join(figDir, tmpFolder))\n",
    "\n",
    "os.system('ffmpeg -start_number 0 -r 10 -i %04d_Opt_rmsprop__Dro_0__Num_20_20_16__Wei_0_2019_06_03__13_54_40.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y 0000000_WeightUpdates.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "999"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(historyDict[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1763940a198>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "tmpDir = os.path.join(figDir, tmpFolder)\n",
    "ctr2 = 0 \n",
    "\n",
    "fig, axs = plt.subplots(1,1,figsize=np.array([30, 10])/2)\n",
    "\n",
    "for dictLen in np.arange(0, len(historyDict[\"mean_squared_error\"])):\n",
    "    if dictLen > 0:    \n",
    "        axs.plot([dictLen -1, dictLen],\n",
    "                 historyDict['mean_squared_error'][dictLen-1:dictLen+1], c= \"C0\")\n",
    "        axs.plot([dictLen -1, dictLen],\n",
    "                 historyDict['val_mean_squared_error'][dictLen-1:dictLen+1], c= \"C1\")\n",
    "    else:    \n",
    "        axs.plot(0,\n",
    "                 historyDict['mean_squared_error'][0],marker='o', markersize=5, c= \"C0\")\n",
    "        axs.plot(0,\n",
    "                 historyDict['val_mean_squared_error'][0],marker='o',markersize=5, c= \"C1\")\n",
    "    axs.set_title('Model MSE = '+ str(format_e(historyDict['val_mean_squared_error'][dictLen])))\n",
    "    axs.set_ylabel('mean squared error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.legend(['train', 'val'], loc='lower left')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "\n",
    "    plt.ylim([0.0001, 0.05])\n",
    "#     fig.savefig(os.path.join(tmpDir, str(dictLen).zfill(4)+ \".png\"), dpi = 120,  pad_inches = 0.5)\n",
    "    #plt.close()\n",
    "    #plt.show()\n",
    "    \n",
    "#     if np.mod(dictLen, 3) == 0:\n",
    "    print(dictLen)\n",
    "    fig.savefig(os.path.join(tmpDir, str(ctr2).zfill(4)+ \".png\"), dpi = 120,  pad_inches = 0.5)\n",
    "    ctr2 += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make into video\n",
    "os.chdir(os.path.join(figDir, tmpFolder))\n",
    "\n",
    "os.system('ffmpeg -start_number 0 -r 10 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y 0000000_HistoryUpdates.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "999\n"
     ]
    }
   ],
   "source": [
    "## refref:  Next step pruning\n",
    "\n",
    "# reload model and wts and history\n",
    "from keras.models import load_model\n",
    "modelFile = r\"D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019\\smallNetworkTraingingPruning\\Opt_rmsprop__Dro_0__Num_20_20_16__Wei_0_2019_06_03__14_47_14_notPruned.h5\"\n",
    "model = load_model(modelFile)\n",
    "\n",
    "histFile = r\"D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019\\smallNetworkTraingingPruning\\Opt_rmsprop__Dro_0__Num_20_20_16__Wei_0_2019_06_03__14_47_14_history.pkl\"\n",
    "\n",
    "historyDict =  pickle.load(open(os.path.join(dataOutput, histFile), 'rb'))\n",
    "\n",
    "print(len(historyDict[\"mean_squared_error\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8181e-04 - mean_squared_error: 2.8181e-04 - val_loss: 2.4545e-04 - val_mean_squared_error: 2.4545e-04\n",
      "1095 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8064e-04 - mean_squared_error: 2.8064e-04 - val_loss: 2.9188e-04 - val_mean_squared_error: 2.9188e-04\n",
      "1095 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8093e-04 - mean_squared_error: 2.8093e-04 - val_loss: 2.8355e-04 - val_mean_squared_error: 2.8355e-04\n",
      "1095 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8068e-04 - mean_squared_error: 2.8068e-04 - val_loss: 2.6557e-04 - val_mean_squared_error: 2.6557e-04\n",
      "1095 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8070e-04 - mean_squared_error: 2.8070e-04 - val_loss: 3.1499e-04 - val_mean_squared_error: 3.1499e-04\n",
      "1095 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8037e-04 - mean_squared_error: 2.8037e-04 - val_loss: 2.9873e-04 - val_mean_squared_error: 2.9873e-04\n",
      "1095 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8022e-04 - mean_squared_error: 2.8022e-04 - val_loss: 2.9700e-04 - val_mean_squared_error: 2.9700e-04\n",
      "1095 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8099e-04 - mean_squared_error: 2.8099e-04 - val_loss: 2.5999e-04 - val_mean_squared_error: 2.5999e-04\n",
      "1095 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8040e-04 - mean_squared_error: 2.8040e-04 - val_loss: 2.8679e-04 - val_mean_squared_error: 2.8679e-04\n",
      "1095 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.7996e-04 - mean_squared_error: 2.7996e-04 - val_loss: 3.1258e-04 - val_mean_squared_error: 3.1258e-04\n",
      "1095 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.7957e-04 - mean_squared_error: 2.7957e-04 - val_loss: 3.0545e-04 - val_mean_squared_error: 3.0545e-04\n",
      "1095 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.7984e-04 - mean_squared_error: 2.7984e-04 - val_loss: 2.4146e-04 - val_mean_squared_error: 2.4146e-04\n",
      "1095 of 1095 weights retained\n",
      "change in log loss: -0.0011185700992197845\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.7975e-04 - mean_squared_error: 2.7975e-04 - val_loss: 2.4914e-04 - val_mean_squared_error: 2.4914e-04\n",
      "1095 of 1095 weights retained\n",
      "change in log loss: -0.0005089823143649141\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.7992e-04 - mean_squared_error: 2.7992e-04 - val_loss: 2.7639e-04 - val_mean_squared_error: 2.7639e-04\n",
      "1095 of 1095 weights retained\n",
      "change in log loss: 3.284272020254164e-05\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.7998e-04 - mean_squared_error: 2.7998e-04 - val_loss: 2.5537e-04 - val_mean_squared_error: 2.5537e-04\n",
      "920 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.8760e-04 - mean_squared_error: 3.8760e-04 - val_loss: 3.4760e-04 - val_mean_squared_error: 3.4760e-04\n",
      "920 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9968e-04 - mean_squared_error: 2.9968e-04 - val_loss: 3.2888e-04 - val_mean_squared_error: 3.2888e-04\n",
      "920 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9208e-04 - mean_squared_error: 2.9208e-04 - val_loss: 2.4690e-04 - val_mean_squared_error: 2.4690e-04\n",
      "920 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9040e-04 - mean_squared_error: 2.9040e-04 - val_loss: 2.9523e-04 - val_mean_squared_error: 2.9523e-04\n",
      "920 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8903e-04 - mean_squared_error: 2.8903e-04 - val_loss: 3.0757e-04 - val_mean_squared_error: 3.0757e-04\n",
      "920 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8816e-04 - mean_squared_error: 2.8816e-04 - val_loss: 2.5623e-04 - val_mean_squared_error: 2.5623e-04\n",
      "920 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8723e-04 - mean_squared_error: 2.8723e-04 - val_loss: 2.5159e-04 - val_mean_squared_error: 2.5159e-04\n",
      "920 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8595e-04 - mean_squared_error: 2.8595e-04 - val_loss: 2.4545e-04 - val_mean_squared_error: 2.4545e-04\n",
      "920 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8651e-04 - mean_squared_error: 2.8651e-04 - val_loss: 2.7768e-04 - val_mean_squared_error: 2.7768e-04\n",
      "920 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8527e-04 - mean_squared_error: 2.8527e-04 - val_loss: 2.5903e-04 - val_mean_squared_error: 2.5903e-04\n",
      "920 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8507e-04 - mean_squared_error: 2.8507e-04 - val_loss: 3.0002e-04 - val_mean_squared_error: 3.0002e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.0017484715802544848\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8535e-04 - mean_squared_error: 2.8535e-04 - val_loss: 3.1642e-04 - val_mean_squared_error: 3.1642e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.0009212090150809704\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8449e-04 - mean_squared_error: 2.8449e-04 - val_loss: 2.5115e-04 - val_mean_squared_error: 2.5115e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.0013848762288273253\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8398e-04 - mean_squared_error: 2.8398e-04 - val_loss: 2.8956e-04 - val_mean_squared_error: 2.8956e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.001112081119764019\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8393e-04 - mean_squared_error: 2.8393e-04 - val_loss: 2.7589e-04 - val_mean_squared_error: 2.7589e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.001285016110367021\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8329e-04 - mean_squared_error: 2.8329e-04 - val_loss: 2.6547e-04 - val_mean_squared_error: 2.6547e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.0016486520471974409\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8363e-04 - mean_squared_error: 2.8363e-04 - val_loss: 2.9338e-04 - val_mean_squared_error: 2.9338e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.0008491966430899112\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8235e-04 - mean_squared_error: 2.8235e-04 - val_loss: 3.2538e-04 - val_mean_squared_error: 3.2538e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.0012548133116729865\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8348e-04 - mean_squared_error: 2.8348e-04 - val_loss: 2.5529e-04 - val_mean_squared_error: 2.5529e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.0006491398112076219\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8208e-04 - mean_squared_error: 2.8208e-04 - val_loss: 2.8741e-04 - val_mean_squared_error: 2.8741e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.0009075976479351322\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8291e-04 - mean_squared_error: 2.8291e-04 - val_loss: 2.8765e-04 - val_mean_squared_error: 2.8765e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.000601633717369543\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8217e-04 - mean_squared_error: 2.8217e-04 - val_loss: 2.8538e-04 - val_mean_squared_error: 2.8538e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.0003274726991586707\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8158e-04 - mean_squared_error: 2.8158e-04 - val_loss: 2.6383e-04 - val_mean_squared_error: 2.6383e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.0013137790817832062\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8175e-04 - mean_squared_error: 2.8175e-04 - val_loss: 3.1141e-04 - val_mean_squared_error: 3.1141e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.0007090867323691352\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8163e-04 - mean_squared_error: 2.8163e-04 - val_loss: 2.6113e-04 - val_mean_squared_error: 2.6113e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.0010533030477606342\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8159e-04 - mean_squared_error: 2.8159e-04 - val_loss: 2.6025e-04 - val_mean_squared_error: 2.6025e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.0003907953718900181\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8107e-04 - mean_squared_error: 2.8107e-04 - val_loss: 3.0898e-04 - val_mean_squared_error: 3.0898e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.0004185254436905872\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8165e-04 - mean_squared_error: 2.8165e-04 - val_loss: 2.8256e-04 - val_mean_squared_error: 2.8256e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.0002711262911792023\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8110e-04 - mean_squared_error: 2.8110e-04 - val_loss: 2.3331e-04 - val_mean_squared_error: 2.3331e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.00035455328476285963\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8031e-04 - mean_squared_error: 2.8031e-04 - val_loss: 2.4795e-04 - val_mean_squared_error: 2.4795e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.0008972366418489308\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.7971e-04 - mean_squared_error: 2.7971e-04 - val_loss: 2.7360e-04 - val_mean_squared_error: 2.7360e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.0014459143807710184\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8100e-04 - mean_squared_error: 2.8100e-04 - val_loss: 2.3386e-04 - val_mean_squared_error: 2.3386e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.0009603641924631479\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8023e-04 - mean_squared_error: 2.8023e-04 - val_loss: 2.6129e-04 - val_mean_squared_error: 2.6129e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -0.000377342711314288\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8020e-04 - mean_squared_error: 2.8020e-04 - val_loss: 3.4667e-04 - val_mean_squared_error: 3.4667e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: 0.00010283661635512864\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.8007e-04 - mean_squared_error: 2.8007e-04 - val_loss: 2.7003e-04 - val_mean_squared_error: 2.7003e-04\n",
      "920 of 1095 weights retained\n",
      "change in log loss: -3.1067960236663694e-05\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.7966e-04 - mean_squared_error: 2.7966e-04 - val_loss: 2.7855e-04 - val_mean_squared_error: 2.7855e-04\n",
      "760 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.6775e-04 - mean_squared_error: 7.6775e-04 - val_loss: 3.2145e-04 - val_mean_squared_error: 3.2145e-04\n",
      "760 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6975e-04 - mean_squared_error: 3.6975e-04 - val_loss: 2.8387e-04 - val_mean_squared_error: 2.8387e-04\n",
      "760 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3355e-04 - mean_squared_error: 3.3355e-04 - val_loss: 2.8396e-04 - val_mean_squared_error: 2.8396e-04\n",
      "760 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2417e-04 - mean_squared_error: 3.2417e-04 - val_loss: 2.8620e-04 - val_mean_squared_error: 2.8620e-04\n",
      "760 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1858e-04 - mean_squared_error: 3.1858e-04 - val_loss: 4.0038e-04 - val_mean_squared_error: 4.0038e-04\n",
      "760 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1642e-04 - mean_squared_error: 3.1642e-04 - val_loss: 2.9163e-04 - val_mean_squared_error: 2.9163e-04\n",
      "760 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1377e-04 - mean_squared_error: 3.1377e-04 - val_loss: 2.8045e-04 - val_mean_squared_error: 2.8045e-04\n",
      "760 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1065e-04 - mean_squared_error: 3.1065e-04 - val_loss: 2.9076e-04 - val_mean_squared_error: 2.9076e-04\n",
      "760 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1108e-04 - mean_squared_error: 3.1108e-04 - val_loss: 3.2746e-04 - val_mean_squared_error: 3.2746e-04\n",
      "760 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0894e-04 - mean_squared_error: 3.0894e-04 - val_loss: 2.7601e-04 - val_mean_squared_error: 2.7601e-04\n",
      "760 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0680e-04 - mean_squared_error: 3.0680e-04 - val_loss: 3.0217e-04 - val_mean_squared_error: 3.0217e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.005040923999469316\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0660e-04 - mean_squared_error: 3.0660e-04 - val_loss: 2.7293e-04 - val_mean_squared_error: 2.7293e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.004007327963479579\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0546e-04 - mean_squared_error: 3.0546e-04 - val_loss: 3.5206e-04 - val_mean_squared_error: 3.5206e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.004406411046568692\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0449e-04 - mean_squared_error: 3.0449e-04 - val_loss: 3.1875e-04 - val_mean_squared_error: 3.1875e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.0033433316960740367\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0512e-04 - mean_squared_error: 3.0512e-04 - val_loss: 2.9014e-04 - val_mean_squared_error: 2.9014e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.001794771947785101\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0288e-04 - mean_squared_error: 3.0288e-04 - val_loss: 3.5750e-04 - val_mean_squared_error: 3.5750e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.002557703089225649\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0185e-04 - mean_squared_error: 3.0185e-04 - val_loss: 2.8559e-04 - val_mean_squared_error: 2.8559e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.002907872479900764\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0178e-04 - mean_squared_error: 3.0178e-04 - val_loss: 3.4385e-04 - val_mean_squared_error: 3.4385e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.002863971965046508\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0170e-04 - mean_squared_error: 3.0170e-04 - val_loss: 2.7773e-04 - val_mean_squared_error: 2.7773e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.00261522628862898\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0190e-04 - mean_squared_error: 3.0190e-04 - val_loss: 2.7146e-04 - val_mean_squared_error: 2.7146e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.0006937400241382452\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0090e-04 - mean_squared_error: 3.0090e-04 - val_loss: 2.9406e-04 - val_mean_squared_error: 2.9406e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.0005893196136275147\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0041e-04 - mean_squared_error: 3.0041e-04 - val_loss: 2.5128e-04 - val_mean_squared_error: 2.5128e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.0011737873058799142\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0012e-04 - mean_squared_error: 3.0012e-04 - val_loss: 2.6199e-04 - val_mean_squared_error: 2.6199e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.0015422043659905071\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.0003e-04 - mean_squared_error: 3.0003e-04 - val_loss: 3.1338e-04 - val_mean_squared_error: 3.1338e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.001500461281748855\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9994e-04 - mean_squared_error: 2.9994e-04 - val_loss: 3.0132e-04 - val_mean_squared_error: 3.0132e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.0007616127841645337\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9990e-04 - mean_squared_error: 2.9990e-04 - val_loss: 2.5771e-04 - val_mean_squared_error: 2.5771e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.00039954888696680513\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9891e-04 - mean_squared_error: 2.9891e-04 - val_loss: 2.8852e-04 - val_mean_squared_error: 2.8852e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.0008547599542769735\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9861e-04 - mean_squared_error: 2.9861e-04 - val_loss: 2.9992e-04 - val_mean_squared_error: 2.9992e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.0012944237001442094\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9851e-04 - mean_squared_error: 2.9851e-04 - val_loss: 2.4604e-04 - val_mean_squared_error: 2.4604e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.0013911880729833292\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9746e-04 - mean_squared_error: 2.9746e-04 - val_loss: 3.2209e-04 - val_mean_squared_error: 3.2209e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.0017679943434212309\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9772e-04 - mean_squared_error: 2.9772e-04 - val_loss: 2.6590e-04 - val_mean_squared_error: 2.6590e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.0011834631748453006\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9782e-04 - mean_squared_error: 2.9782e-04 - val_loss: 3.0868e-04 - val_mean_squared_error: 3.0868e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.0007967874113798956\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9638e-04 - mean_squared_error: 2.9638e-04 - val_loss: 3.1117e-04 - val_mean_squared_error: 3.1117e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.0013129021303390775\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9612e-04 - mean_squared_error: 2.9612e-04 - val_loss: 3.1169e-04 - val_mean_squared_error: 3.1169e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.0013605060899735122\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9657e-04 - mean_squared_error: 2.9657e-04 - val_loss: 2.9911e-04 - val_mean_squared_error: 2.9911e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.0013466677964608653\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9615e-04 - mean_squared_error: 2.9615e-04 - val_loss: 2.8817e-04 - val_mean_squared_error: 2.8817e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.0010610028067183919\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9581e-04 - mean_squared_error: 2.9581e-04 - val_loss: 2.6058e-04 - val_mean_squared_error: 2.6058e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.0003707442188674026\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9378e-04 - mean_squared_error: 2.9378e-04 - val_loss: 2.8482e-04 - val_mean_squared_error: 2.8482e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.001841388826714807\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9515e-04 - mean_squared_error: 2.9515e-04 - val_loss: 3.7928e-04 - val_mean_squared_error: 3.7928e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.0017634174767444666\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9442e-04 - mean_squared_error: 2.9442e-04 - val_loss: 3.2040e-04 - val_mean_squared_error: 3.2040e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -0.0013941765433695963\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9546e-04 - mean_squared_error: 2.9546e-04 - val_loss: 2.9562e-04 - val_mean_squared_error: 2.9562e-04\n",
      "760 of 1095 weights retained\n",
      "change in log loss: -2.3340440244101757e-05\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 2.9370e-04 - mean_squared_error: 2.9370e-04 - val_loss: 2.6209e-04 - val_mean_squared_error: 2.6209e-04\n",
      "612 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 4.9782e-04 - val_mean_squared_error: 4.9782e-04\n",
      "612 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.0055e-04 - mean_squared_error: 8.0055e-04 - val_loss: 3.9189e-04 - val_mean_squared_error: 3.9189e-04\n",
      "612 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.6470e-04 - mean_squared_error: 5.6470e-04 - val_loss: 5.6328e-04 - val_mean_squared_error: 5.6328e-04\n",
      "612 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.9079e-04 - mean_squared_error: 4.9079e-04 - val_loss: 3.5455e-04 - val_mean_squared_error: 3.5455e-04\n",
      "612 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.5565e-04 - mean_squared_error: 4.5565e-04 - val_loss: 3.1246e-04 - val_mean_squared_error: 3.1246e-04\n",
      "612 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3288e-04 - mean_squared_error: 4.3288e-04 - val_loss: 3.8853e-04 - val_mean_squared_error: 3.8853e-04\n",
      "612 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.1956e-04 - mean_squared_error: 4.1956e-04 - val_loss: 3.8606e-04 - val_mean_squared_error: 3.8606e-04\n",
      "612 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.0661e-04 - mean_squared_error: 4.0661e-04 - val_loss: 3.7095e-04 - val_mean_squared_error: 3.7095e-04\n",
      "612 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.9731e-04 - mean_squared_error: 3.9731e-04 - val_loss: 3.6803e-04 - val_mean_squared_error: 3.6803e-04\n",
      "612 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.9209e-04 - mean_squared_error: 3.9209e-04 - val_loss: 3.2342e-04 - val_mean_squared_error: 3.2342e-04\n",
      "612 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.8586e-04 - mean_squared_error: 3.8586e-04 - val_loss: 4.3444e-04 - val_mean_squared_error: 4.3444e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.020384669162725855\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.8299e-04 - mean_squared_error: 3.8299e-04 - val_loss: 3.4769e-04 - val_mean_squared_error: 3.4769e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.014897735835151193\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7635e-04 - mean_squared_error: 3.7635e-04 - val_loss: 3.7835e-04 - val_mean_squared_error: 3.7835e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.01319020372925328\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7159e-04 - mean_squared_error: 3.7159e-04 - val_loss: 3.4816e-04 - val_mean_squared_error: 3.4816e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.01323528019327358\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6872e-04 - mean_squared_error: 3.6872e-04 - val_loss: 3.5751e-04 - val_mean_squared_error: 3.5751e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.012109031217653055\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6577e-04 - mean_squared_error: 3.6577e-04 - val_loss: 3.7856e-04 - val_mean_squared_error: 3.7856e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.011250711270829994\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6379e-04 - mean_squared_error: 3.6379e-04 - val_loss: 3.2276e-04 - val_mean_squared_error: 3.2276e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.008368794108438937\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6130e-04 - mean_squared_error: 3.6130e-04 - val_loss: 2.9212e-04 - val_mean_squared_error: 2.9212e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.006963807136655342\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5625e-04 - mean_squared_error: 3.5625e-04 - val_loss: 3.4067e-04 - val_mean_squared_error: 3.4067e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0081095935839135\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5639e-04 - mean_squared_error: 3.5639e-04 - val_loss: 3.3523e-04 - val_mean_squared_error: 3.3523e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.007286210776397795\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5463e-04 - mean_squared_error: 3.5463e-04 - val_loss: 3.3867e-04 - val_mean_squared_error: 3.3867e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.006463246815197721\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5305e-04 - mean_squared_error: 3.5305e-04 - val_loss: 2.9808e-04 - val_mean_squared_error: 2.9808e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.005073086772277913\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5157e-04 - mean_squared_error: 3.5157e-04 - val_loss: 3.6553e-04 - val_mean_squared_error: 3.6553e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.003587221264752305\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5037e-04 - mean_squared_error: 3.5037e-04 - val_loss: 3.0289e-04 - val_mean_squared_error: 3.0289e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.004274853881724994\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4790e-04 - mean_squared_error: 3.4790e-04 - val_loss: 3.5290e-04 - val_mean_squared_error: 3.5290e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.004597113020976984\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4727e-04 - mean_squared_error: 3.4727e-04 - val_loss: 4.1343e-04 - val_mean_squared_error: 4.1343e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.004352881312232881\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4642e-04 - mean_squared_error: 3.4642e-04 - val_loss: 3.2611e-04 - val_mean_squared_error: 3.2611e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0038410108481665706\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4512e-04 - mean_squared_error: 3.4512e-04 - val_loss: 3.1620e-04 - val_mean_squared_error: 3.1620e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0034478712004823997\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4462e-04 - mean_squared_error: 3.4462e-04 - val_loss: 3.2907e-04 - val_mean_squared_error: 3.2907e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.002511075950006214\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4201e-04 - mean_squared_error: 3.4201e-04 - val_loss: 3.1838e-04 - val_mean_squared_error: 3.1838e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0035687452507278117\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4279e-04 - mean_squared_error: 3.4279e-04 - val_loss: 3.2321e-04 - val_mean_squared_error: 3.2321e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.003009121321371655\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4020e-04 - mean_squared_error: 3.4020e-04 - val_loss: 2.8944e-04 - val_mean_squared_error: 2.8944e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.00340185483860167\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4049e-04 - mean_squared_error: 3.4049e-04 - val_loss: 2.8808e-04 - val_mean_squared_error: 2.8808e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0029443202889307685\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3948e-04 - mean_squared_error: 3.3948e-04 - val_loss: 2.9407e-04 - val_mean_squared_error: 2.9407e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.002158834421444933\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3832e-04 - mean_squared_error: 3.3832e-04 - val_loss: 3.7403e-04 - val_mean_squared_error: 3.7403e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.002835837638721639\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3779e-04 - mean_squared_error: 3.3779e-04 - val_loss: 3.5017e-04 - val_mean_squared_error: 3.5017e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.002058463247267772\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3707e-04 - mean_squared_error: 3.3707e-04 - val_loss: 3.6458e-04 - val_mean_squared_error: 3.6458e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0025163692745262534\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3680e-04 - mean_squared_error: 3.3680e-04 - val_loss: 3.5529e-04 - val_mean_squared_error: 3.5529e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0019554956239982157\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3445e-04 - mean_squared_error: 3.3445e-04 - val_loss: 3.3327e-04 - val_mean_squared_error: 3.3327e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0025996285272777975\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3472e-04 - mean_squared_error: 3.3472e-04 - val_loss: 2.7930e-04 - val_mean_squared_error: 2.7930e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0026081982447316854\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3335e-04 - mean_squared_error: 3.3335e-04 - val_loss: 3.3943e-04 - val_mean_squared_error: 3.3943e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.002842123283118614\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3351e-04 - mean_squared_error: 3.3351e-04 - val_loss: 3.7588e-04 - val_mean_squared_error: 3.7588e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.002294286879054308\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3255e-04 - mean_squared_error: 3.3255e-04 - val_loss: 3.0903e-04 - val_mean_squared_error: 3.0903e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0015009864589052846\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3184e-04 - mean_squared_error: 3.3184e-04 - val_loss: 3.2714e-04 - val_mean_squared_error: 3.2714e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0019704340928645703\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3063e-04 - mean_squared_error: 3.3063e-04 - val_loss: 2.9798e-04 - val_mean_squared_error: 2.9798e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0021400113073068994\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3023e-04 - mean_squared_error: 3.3023e-04 - val_loss: 3.0882e-04 - val_mean_squared_error: 3.0882e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0025532419342404467\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2942e-04 - mean_squared_error: 3.2942e-04 - val_loss: 3.1809e-04 - val_mean_squared_error: 3.1809e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0023726813058106977\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2907e-04 - mean_squared_error: 3.2907e-04 - val_loss: 2.8306e-04 - val_mean_squared_error: 2.8306e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0020433150825245328\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2864e-04 - mean_squared_error: 3.2864e-04 - val_loss: 2.9639e-04 - val_mean_squared_error: 2.9639e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0015608833597553495\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2635e-04 - mean_squared_error: 3.2635e-04 - val_loss: 3.7276e-04 - val_mean_squared_error: 3.7276e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0026060055155237016\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2583e-04 - mean_squared_error: 3.2583e-04 - val_loss: 3.4784e-04 - val_mean_squared_error: 3.4784e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0030235227761277184\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2544e-04 - mean_squared_error: 3.2544e-04 - val_loss: 3.2019e-04 - val_mean_squared_error: 3.2019e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0030732061850571313\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2549e-04 - mean_squared_error: 3.2549e-04 - val_loss: 3.1213e-04 - val_mean_squared_error: 3.1213e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.002204251236255228\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2494e-04 - mean_squared_error: 3.2494e-04 - val_loss: 4.3917e-04 - val_mean_squared_error: 4.3917e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0009697734279783266\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2473e-04 - mean_squared_error: 3.2473e-04 - val_loss: 2.7136e-04 - val_mean_squared_error: 2.7136e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0008314098562012262\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2392e-04 - mean_squared_error: 3.2392e-04 - val_loss: 2.8022e-04 - val_mean_squared_error: 2.8022e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0011694157193384846\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2466e-04 - mean_squared_error: 3.2466e-04 - val_loss: 2.9303e-04 - val_mean_squared_error: 2.9303e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0008257882634319369\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2315e-04 - mean_squared_error: 3.2315e-04 - val_loss: 4.1276e-04 - val_mean_squared_error: 4.1276e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0011283275125391068\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2169e-04 - mean_squared_error: 3.2169e-04 - val_loss: 2.6203e-04 - val_mean_squared_error: 2.6203e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.002119043452298186\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2207e-04 - mean_squared_error: 3.2207e-04 - val_loss: 3.8086e-04 - val_mean_squared_error: 3.8086e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.002062313963956841\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2182e-04 - mean_squared_error: 3.2182e-04 - val_loss: 2.8275e-04 - val_mean_squared_error: 2.8275e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0020905982498433673\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2005e-04 - mean_squared_error: 3.2005e-04 - val_loss: 2.9276e-04 - val_mean_squared_error: 2.9276e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.001888097449536108\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2115e-04 - mean_squared_error: 3.2115e-04 - val_loss: 2.8426e-04 - val_mean_squared_error: 2.8426e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0009659510079145228\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2025e-04 - mean_squared_error: 3.2025e-04 - val_loss: 2.9019e-04 - val_mean_squared_error: 2.9019e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0013441591051057689\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1822e-04 - mean_squared_error: 3.1822e-04 - val_loss: 2.8990e-04 - val_mean_squared_error: 2.8990e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.002187754046480306\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1983e-04 - mean_squared_error: 3.1983e-04 - val_loss: 3.0323e-04 - val_mean_squared_error: 3.0323e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0010567033758701605\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1804e-04 - mean_squared_error: 3.1804e-04 - val_loss: 3.3654e-04 - val_mean_squared_error: 3.3654e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0020758660931972095\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1828e-04 - mean_squared_error: 3.1828e-04 - val_loss: 2.7770e-04 - val_mean_squared_error: 2.7770e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0012863464191072982\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1738e-04 - mean_squared_error: 3.1738e-04 - val_loss: 3.1580e-04 - val_mean_squared_error: 3.1580e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0010124463003489126\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1724e-04 - mean_squared_error: 3.1724e-04 - val_loss: 3.8855e-04 - val_mean_squared_error: 3.8855e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0018374778580465545\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1737e-04 - mean_squared_error: 3.1737e-04 - val_loss: 3.1652e-04 - val_mean_squared_error: 3.1652e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0007548268641381917\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1744e-04 - mean_squared_error: 3.1744e-04 - val_loss: 3.3840e-04 - val_mean_squared_error: 3.3840e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0005357789077200525\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1472e-04 - mean_squared_error: 3.1472e-04 - val_loss: 2.9691e-04 - val_mean_squared_error: 2.9691e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0016194944859093674\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1487e-04 - mean_squared_error: 3.1487e-04 - val_loss: 3.1103e-04 - val_mean_squared_error: 3.1103e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0023369913349153837\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1523e-04 - mean_squared_error: 3.1523e-04 - val_loss: 2.8061e-04 - val_mean_squared_error: 2.8061e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.002161252441666761\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1443e-04 - mean_squared_error: 3.1443e-04 - val_loss: 2.9112e-04 - val_mean_squared_error: 2.9112e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0017403605383314869\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1331e-04 - mean_squared_error: 3.1331e-04 - val_loss: 3.8722e-04 - val_mean_squared_error: 3.8722e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0010359113268176845\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1417e-04 - mean_squared_error: 3.1417e-04 - val_loss: 2.9196e-04 - val_mean_squared_error: 2.9196e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0010551395232980543\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1349e-04 - mean_squared_error: 3.1349e-04 - val_loss: 2.6776e-04 - val_mean_squared_error: 2.6776e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0011925714925367092\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1225e-04 - mean_squared_error: 3.1225e-04 - val_loss: 3.1807e-04 - val_mean_squared_error: 3.1807e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0013324221280606174\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1236e-04 - mean_squared_error: 3.1236e-04 - val_loss: 3.1733e-04 - val_mean_squared_error: 3.1733e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0012190532816978017\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1198e-04 - mean_squared_error: 3.1198e-04 - val_loss: 2.7447e-04 - val_mean_squared_error: 2.7447e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0017601707549215195\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1210e-04 - mean_squared_error: 3.1210e-04 - val_loss: 3.0944e-04 - val_mean_squared_error: 3.0944e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0009786427410209964\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1026e-04 - mean_squared_error: 3.1026e-04 - val_loss: 2.7818e-04 - val_mean_squared_error: 2.7818e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.001366770430820452\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1160e-04 - mean_squared_error: 3.1160e-04 - val_loss: 3.0300e-04 - val_mean_squared_error: 3.0300e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0010444670094382769\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1144e-04 - mean_squared_error: 3.1144e-04 - val_loss: 2.7450e-04 - val_mean_squared_error: 2.7450e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.00050535642195082\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1093e-04 - mean_squared_error: 3.1093e-04 - val_loss: 3.0593e-04 - val_mean_squared_error: 3.0593e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: -0.0003721602304327387\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1065e-04 - mean_squared_error: 3.1065e-04 - val_loss: 2.5392e-04 - val_mean_squared_error: 2.5392e-04\n",
      "612 of 1095 weights retained\n",
      "change in log loss: 4.052254373454467e-05\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.1088e-04 - mean_squared_error: 3.1088e-04 - val_loss: 3.3517e-04 - val_mean_squared_error: 3.3517e-04\n",
      "484 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0089 - mean_squared_error: 0.0089 - val_loss: 5.5008e-04 - val_mean_squared_error: 5.5008e-04\n",
      "484 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 5.0261e-04 - val_mean_squared_error: 5.0261e-04\n",
      "484 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 3.4630e-04 - val_mean_squared_error: 3.4630e-04\n",
      "484 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 9.1657e-04 - mean_squared_error: 9.1657e-04 - val_loss: 6.0429e-04 - val_mean_squared_error: 6.0429e-04\n",
      "484 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.4810e-04 - mean_squared_error: 7.4810e-04 - val_loss: 5.1006e-04 - val_mean_squared_error: 5.1006e-04\n",
      "484 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.5852e-04 - mean_squared_error: 6.5852e-04 - val_loss: 3.6625e-04 - val_mean_squared_error: 3.6625e-04\n",
      "484 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.0070e-04 - mean_squared_error: 6.0070e-04 - val_loss: 4.0686e-04 - val_mean_squared_error: 4.0686e-04\n",
      "484 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.5299e-04 - mean_squared_error: 5.5299e-04 - val_loss: 4.1737e-04 - val_mean_squared_error: 4.1737e-04\n",
      "484 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.2364e-04 - mean_squared_error: 5.2364e-04 - val_loss: 5.0714e-04 - val_mean_squared_error: 5.0714e-04\n",
      "484 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.0348e-04 - mean_squared_error: 5.0348e-04 - val_loss: 4.2679e-04 - val_mean_squared_error: 4.2679e-04\n",
      "484 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.8831e-04 - mean_squared_error: 4.8831e-04 - val_loss: 4.4103e-04 - val_mean_squared_error: 4.4103e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.050807941573262516\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.7475e-04 - mean_squared_error: 4.7475e-04 - val_loss: 3.7973e-04 - val_mean_squared_error: 3.7973e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.03749447625980218\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.6345e-04 - mean_squared_error: 4.6345e-04 - val_loss: 3.7316e-04 - val_mean_squared_error: 3.7316e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.030296423710275855\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.5389e-04 - mean_squared_error: 4.5389e-04 - val_loss: 3.2958e-04 - val_mean_squared_error: 3.2958e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.025964431727135695\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.4459e-04 - mean_squared_error: 4.4459e-04 - val_loss: 4.3830e-04 - val_mean_squared_error: 4.3830e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.023254884327216896\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3816e-04 - mean_squared_error: 4.3816e-04 - val_loss: 3.6861e-04 - val_mean_squared_error: 3.6861e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.020195918467399654\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3274e-04 - mean_squared_error: 4.3274e-04 - val_loss: 3.0172e-04 - val_mean_squared_error: 3.0172e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.017241420991863654\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2524e-04 - mean_squared_error: 4.2524e-04 - val_loss: 3.5905e-04 - val_mean_squared_error: 3.5905e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0157431489159241\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.1938e-04 - mean_squared_error: 4.1938e-04 - val_loss: 3.2136e-04 - val_mean_squared_error: 3.2136e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.014666582119052807\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.1299e-04 - mean_squared_error: 4.1299e-04 - val_loss: 3.7236e-04 - val_mean_squared_error: 3.7236e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.01496816525574296\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.0921e-04 - mean_squared_error: 4.0921e-04 - val_loss: 3.3189e-04 - val_mean_squared_error: 3.3189e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.014101500590764982\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.0413e-04 - mean_squared_error: 4.0413e-04 - val_loss: 3.2338e-04 - val_mean_squared_error: 3.2338e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.012634404273542232\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.0138e-04 - mean_squared_error: 4.0138e-04 - val_loss: 3.9475e-04 - val_mean_squared_error: 3.9475e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.010941642720562417\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.9697e-04 - mean_squared_error: 3.9697e-04 - val_loss: 3.8150e-04 - val_mean_squared_error: 3.8150e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.009842655443131454\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.9490e-04 - mean_squared_error: 3.9490e-04 - val_loss: 3.1624e-04 - val_mean_squared_error: 3.1624e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.008910146193236379\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.9100e-04 - mean_squared_error: 3.9100e-04 - val_loss: 3.3494e-04 - val_mean_squared_error: 3.3494e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0082387838521365\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.8946e-04 - mean_squared_error: 3.8946e-04 - val_loss: 3.0553e-04 - val_mean_squared_error: 3.0553e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0075490398690909455\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.8739e-04 - mean_squared_error: 3.8739e-04 - val_loss: 4.7735e-04 - val_mean_squared_error: 4.7735e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.006272726387947847\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.8471e-04 - mean_squared_error: 3.8471e-04 - val_loss: 3.5032e-04 - val_mean_squared_error: 3.5032e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.006149596137517754\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.8173e-04 - mean_squared_error: 3.8173e-04 - val_loss: 4.1853e-04 - val_mean_squared_error: 4.1853e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0060217782664167\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.8131e-04 - mean_squared_error: 3.8131e-04 - val_loss: 4.0371e-04 - val_mean_squared_error: 4.0371e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.005701570271281042\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7737e-04 - mean_squared_error: 3.7737e-04 - val_loss: 4.4029e-04 - val_mean_squared_error: 4.4029e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.006131375296209107\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7803e-04 - mean_squared_error: 3.7803e-04 - val_loss: 3.7891e-04 - val_mean_squared_error: 3.7891e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.004654557682103766\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7579e-04 - mean_squared_error: 3.7579e-04 - val_loss: 3.7101e-04 - val_mean_squared_error: 3.7101e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.004002426577120355\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7430e-04 - mean_squared_error: 3.7430e-04 - val_loss: 3.6141e-04 - val_mean_squared_error: 3.6141e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.00413269521150017\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.7233e-04 - mean_squared_error: 3.7233e-04 - val_loss: 3.3353e-04 - val_mean_squared_error: 3.3353e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0036834741158728868\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6909e-04 - mean_squared_error: 3.6909e-04 - val_loss: 4.3625e-04 - val_mean_squared_error: 4.3625e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.005712149649392595\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6997e-04 - mean_squared_error: 3.6997e-04 - val_loss: 3.4787e-04 - val_mean_squared_error: 3.4787e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.004521508311719602\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6839e-04 - mean_squared_error: 3.6839e-04 - val_loss: 2.8747e-04 - val_mean_squared_error: 2.8747e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0038164927240496027\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6809e-04 - mean_squared_error: 3.6809e-04 - val_loss: 3.5746e-04 - val_mean_squared_error: 3.5746e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.002476039328525692\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6617e-04 - mean_squared_error: 3.6617e-04 - val_loss: 3.0923e-04 - val_mean_squared_error: 3.0923e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.002093582688786011\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6577e-04 - mean_squared_error: 3.6577e-04 - val_loss: 3.1253e-04 - val_mean_squared_error: 3.1253e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.002885355774684406\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6394e-04 - mean_squared_error: 3.6394e-04 - val_loss: 3.1886e-04 - val_mean_squared_error: 3.1886e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0030631406435208675\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6334e-04 - mean_squared_error: 3.6334e-04 - val_loss: 3.7647e-04 - val_mean_squared_error: 3.7647e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.003212053031829809\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6102e-04 - mean_squared_error: 3.6102e-04 - val_loss: 3.3034e-04 - val_mean_squared_error: 3.3034e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0035024343623863974\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6130e-04 - mean_squared_error: 3.6130e-04 - val_loss: 3.8411e-04 - val_mean_squared_error: 3.8411e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0032676944341958336\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.6053e-04 - mean_squared_error: 3.6053e-04 - val_loss: 2.9392e-04 - val_mean_squared_error: 2.9392e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.002445087633004217\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5815e-04 - mean_squared_error: 3.5815e-04 - val_loss: 2.8649e-04 - val_mean_squared_error: 2.8649e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0030094366686426177\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5815e-04 - mean_squared_error: 3.5815e-04 - val_loss: 2.7204e-04 - val_mean_squared_error: 2.7204e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.002470746929392975\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5723e-04 - mean_squared_error: 3.5723e-04 - val_loss: 3.9833e-04 - val_mean_squared_error: 3.9833e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0029272715191155374\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5639e-04 - mean_squared_error: 3.5639e-04 - val_loss: 3.1787e-04 - val_mean_squared_error: 3.1787e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.002566376342511223\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5488e-04 - mean_squared_error: 3.5488e-04 - val_loss: 2.7196e-04 - val_mean_squared_error: 2.7196e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0023284343173619604\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5633e-04 - mean_squared_error: 3.5633e-04 - val_loss: 3.2919e-04 - val_mean_squared_error: 3.2919e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0016816653434819084\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5460e-04 - mean_squared_error: 3.5460e-04 - val_loss: 2.8195e-04 - val_mean_squared_error: 2.8195e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.001498312444697003\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5376e-04 - mean_squared_error: 3.5376e-04 - val_loss: 3.6326e-04 - val_mean_squared_error: 3.6326e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0015610568135902003\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5259e-04 - mean_squared_error: 3.5259e-04 - val_loss: 3.3986e-04 - val_mean_squared_error: 3.3986e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.00201814303503256\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5045e-04 - mean_squared_error: 3.5045e-04 - val_loss: 4.0113e-04 - val_mean_squared_error: 4.0113e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0038961768743794867\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.5110e-04 - mean_squared_error: 3.5110e-04 - val_loss: 3.6669e-04 - val_mean_squared_error: 3.6669e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.002925980831019137\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4985e-04 - mean_squared_error: 3.4985e-04 - val_loss: 3.1496e-04 - val_mean_squared_error: 3.1496e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.002649105581839173\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4866e-04 - mean_squared_error: 3.4866e-04 - val_loss: 3.4099e-04 - val_mean_squared_error: 3.4099e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.002411477453309274\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4644e-04 - mean_squared_error: 3.4644e-04 - val_loss: 5.1011e-04 - val_mean_squared_error: 5.1011e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0029944961654628788\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4732e-04 - mean_squared_error: 3.4732e-04 - val_loss: 2.9347e-04 - val_mean_squared_error: 2.9347e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0031416135486752594\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4708e-04 - mean_squared_error: 3.4708e-04 - val_loss: 3.2230e-04 - val_mean_squared_error: 3.2230e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0019731749432325696\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4542e-04 - mean_squared_error: 3.4542e-04 - val_loss: 3.7298e-04 - val_mean_squared_error: 3.7298e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0016842874741440639\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4654e-04 - mean_squared_error: 3.4654e-04 - val_loss: 3.0609e-04 - val_mean_squared_error: 3.0609e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.000495567549775533\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4528e-04 - mean_squared_error: 3.4528e-04 - val_loss: 4.1442e-04 - val_mean_squared_error: 4.1442e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0013374226408389145\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4453e-04 - mean_squared_error: 3.4453e-04 - val_loss: 3.4367e-04 - val_mean_squared_error: 3.4367e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0015142764003543974\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4388e-04 - mean_squared_error: 3.4388e-04 - val_loss: 3.6322e-04 - val_mean_squared_error: 3.6322e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0014740967693374074\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4372e-04 - mean_squared_error: 3.4372e-04 - val_loss: 3.5472e-04 - val_mean_squared_error: 3.5472e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.002038091803180375\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4336e-04 - mean_squared_error: 3.4336e-04 - val_loss: 3.2274e-04 - val_mean_squared_error: 3.2274e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0013488283001734658\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4215e-04 - mean_squared_error: 3.4215e-04 - val_loss: 3.1964e-04 - val_mean_squared_error: 3.1964e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.00153938008567156\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4179e-04 - mean_squared_error: 3.4179e-04 - val_loss: 3.5484e-04 - val_mean_squared_error: 3.5484e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0016745442853833836\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4098e-04 - mean_squared_error: 3.4098e-04 - val_loss: 3.2347e-04 - val_mean_squared_error: 3.2347e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0020560799653557282\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3980e-04 - mean_squared_error: 3.3980e-04 - val_loss: 3.1623e-04 - val_mean_squared_error: 3.1623e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.002425727229194763\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3993e-04 - mean_squared_error: 3.3993e-04 - val_loss: 3.3184e-04 - val_mean_squared_error: 3.3184e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.001885113111809611\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.4025e-04 - mean_squared_error: 3.4025e-04 - val_loss: 3.4709e-04 - val_mean_squared_error: 3.4709e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0012159378315126368\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3875e-04 - mean_squared_error: 3.3875e-04 - val_loss: 2.9789e-04 - val_mean_squared_error: 2.9789e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0011833052557681523\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3853e-04 - mean_squared_error: 3.3853e-04 - val_loss: 2.9721e-04 - val_mean_squared_error: 2.9721e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.001098354701879467\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3828e-04 - mean_squared_error: 3.3828e-04 - val_loss: 2.9574e-04 - val_mean_squared_error: 2.9574e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0014833806434808583\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3872e-04 - mean_squared_error: 3.3872e-04 - val_loss: 3.1154e-04 - val_mean_squared_error: 3.1154e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0010418437113386414\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3662e-04 - mean_squared_error: 3.3662e-04 - val_loss: 3.0514e-04 - val_mean_squared_error: 3.0514e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0012057577135111686\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3712e-04 - mean_squared_error: 3.3712e-04 - val_loss: 3.1602e-04 - val_mean_squared_error: 3.1602e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0013225120752797803\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3625e-04 - mean_squared_error: 3.3625e-04 - val_loss: 2.9557e-04 - val_mean_squared_error: 2.9557e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0016713412904765246\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3683e-04 - mean_squared_error: 3.3683e-04 - val_loss: 2.8881e-04 - val_mean_squared_error: 2.8881e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0012242553200587647\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3536e-04 - mean_squared_error: 3.3536e-04 - val_loss: 3.0659e-04 - val_mean_squared_error: 3.0659e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0008386740967740725\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3542e-04 - mean_squared_error: 3.3542e-04 - val_loss: 4.1256e-04 - val_mean_squared_error: 4.1256e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0012808506152468535\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3494e-04 - mean_squared_error: 3.3494e-04 - val_loss: 3.7705e-04 - val_mean_squared_error: 3.7705e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0012030326848193607\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3569e-04 - mean_squared_error: 3.3569e-04 - val_loss: 2.9383e-04 - val_mean_squared_error: 2.9383e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0008063687970230049\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3315e-04 - mean_squared_error: 3.3315e-04 - val_loss: 4.1652e-04 - val_mean_squared_error: 4.1652e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0012369250210488847\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3439e-04 - mean_squared_error: 3.3439e-04 - val_loss: 3.0421e-04 - val_mean_squared_error: 3.0421e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0011464141181993792\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3342e-04 - mean_squared_error: 3.3342e-04 - val_loss: 2.9486e-04 - val_mean_squared_error: 2.9486e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0012967500678047195\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3280e-04 - mean_squared_error: 3.3280e-04 - val_loss: 3.7853e-04 - val_mean_squared_error: 3.7853e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0016504126995913193\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3287e-04 - mean_squared_error: 3.3287e-04 - val_loss: 3.5516e-04 - val_mean_squared_error: 3.5516e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0006485489726779647\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3189e-04 - mean_squared_error: 3.3189e-04 - val_loss: 3.9877e-04 - val_mean_squared_error: 3.9877e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0016678162230507887\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3116e-04 - mean_squared_error: 3.3116e-04 - val_loss: 3.3114e-04 - val_mean_squared_error: 3.3114e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0016322463076015037\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3112e-04 - mean_squared_error: 3.3112e-04 - val_loss: 3.1032e-04 - val_mean_squared_error: 3.1032e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0015263467692232524\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3172e-04 - mean_squared_error: 3.3172e-04 - val_loss: 2.9756e-04 - val_mean_squared_error: 2.9756e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0009247834244565656\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.3090e-04 - mean_squared_error: 3.3090e-04 - val_loss: 2.9463e-04 - val_mean_squared_error: 2.9463e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.000428500983485014\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2998e-04 - mean_squared_error: 3.2998e-04 - val_loss: 2.5420e-04 - val_mean_squared_error: 2.5420e-04\n",
      "484 of 1095 weights retained\n",
      "change in log loss: -0.0007797537188971582\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 3.2941e-04 - mean_squared_error: 3.2941e-04 - val_loss: 3.6373e-04 - val_mean_squared_error: 3.6373e-04\n",
      "376 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 6.3050e-04 - val_mean_squared_error: 6.3050e-04\n",
      "376 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 4.5473e-04 - val_mean_squared_error: 4.5473e-04\n",
      "376 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 9.2020e-04 - mean_squared_error: 9.2020e-04 - val_loss: 4.7327e-04 - val_mean_squared_error: 4.7327e-04\n",
      "376 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.8899e-04 - mean_squared_error: 7.8899e-04 - val_loss: 6.4274e-04 - val_mean_squared_error: 6.4274e-04\n",
      "376 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.2088e-04 - mean_squared_error: 7.2088e-04 - val_loss: 3.7143e-04 - val_mean_squared_error: 3.7143e-04\n",
      "376 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.8095e-04 - mean_squared_error: 6.8095e-04 - val_loss: 3.9507e-04 - val_mean_squared_error: 3.9507e-04\n",
      "376 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.5196e-04 - mean_squared_error: 6.5196e-04 - val_loss: 3.8436e-04 - val_mean_squared_error: 3.8436e-04\n",
      "376 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.2887e-04 - mean_squared_error: 6.2887e-04 - val_loss: 3.9446e-04 - val_mean_squared_error: 3.9446e-04\n",
      "376 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.1014e-04 - mean_squared_error: 6.1014e-04 - val_loss: 4.3059e-04 - val_mean_squared_error: 4.3059e-04\n",
      "376 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.9354e-04 - mean_squared_error: 5.9354e-04 - val_loss: 4.8800e-04 - val_mean_squared_error: 4.8800e-04\n",
      "376 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.7983e-04 - mean_squared_error: 5.7983e-04 - val_loss: 3.3788e-04 - val_mean_squared_error: 3.3788e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.029231345018685406\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.7001e-04 - mean_squared_error: 5.7001e-04 - val_loss: 3.8123e-04 - val_mean_squared_error: 3.8123e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.02474876909082635\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.5977e-04 - mean_squared_error: 5.5977e-04 - val_loss: 4.2569e-04 - val_mean_squared_error: 4.2569e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.021278736249238595\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.5182e-04 - mean_squared_error: 5.5182e-04 - val_loss: 4.6974e-04 - val_mean_squared_error: 4.6974e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.018097044508248228\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.4357e-04 - mean_squared_error: 5.4357e-04 - val_loss: 3.5555e-04 - val_mean_squared_error: 3.5555e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.016159355352212135\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.3854e-04 - mean_squared_error: 5.3854e-04 - val_loss: 4.0869e-04 - val_mean_squared_error: 4.0869e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.014296281386062537\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.3255e-04 - mean_squared_error: 5.3255e-04 - val_loss: 3.6420e-04 - val_mean_squared_error: 3.6420e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.012406191927695653\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.2680e-04 - mean_squared_error: 5.2680e-04 - val_loss: 5.1263e-04 - val_mean_squared_error: 5.1263e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.011327911081757014\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.2029e-04 - mean_squared_error: 5.2029e-04 - val_loss: 3.9138e-04 - val_mean_squared_error: 3.9138e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.010957771562014607\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.1627e-04 - mean_squared_error: 5.1627e-04 - val_loss: 3.9792e-04 - val_mean_squared_error: 3.9792e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.01077471043936451\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.1197e-04 - mean_squared_error: 5.1197e-04 - val_loss: 3.7192e-04 - val_mean_squared_error: 3.7192e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.00990091413920946\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.0571e-04 - mean_squared_error: 5.0571e-04 - val_loss: 4.2785e-04 - val_mean_squared_error: 4.2785e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.009783450391613657\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 5.0188e-04 - mean_squared_error: 5.0188e-04 - val_loss: 3.9537e-04 - val_mean_squared_error: 3.9537e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.009271714046287904\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.9655e-04 - mean_squared_error: 4.9655e-04 - val_loss: 3.6304e-04 - val_mean_squared_error: 3.6304e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.009779981811356642\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.9555e-04 - mean_squared_error: 4.9555e-04 - val_loss: 3.9710e-04 - val_mean_squared_error: 3.9710e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.008346548378005858\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.9098e-04 - mean_squared_error: 4.9098e-04 - val_loss: 3.9587e-04 - val_mean_squared_error: 3.9587e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.007180749148747889\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.8832e-04 - mean_squared_error: 4.8832e-04 - val_loss: 3.6843e-04 - val_mean_squared_error: 3.6843e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.006606233587168164\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.8543e-04 - mean_squared_error: 4.8543e-04 - val_loss: 3.4380e-04 - val_mean_squared_error: 3.4380e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.006003209718719704\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.8016e-04 - mean_squared_error: 4.8016e-04 - val_loss: 5.1257e-04 - val_mean_squared_error: 5.1257e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.00745078279420075\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.8007e-04 - mean_squared_error: 4.8007e-04 - val_loss: 4.4956e-04 - val_mean_squared_error: 4.4956e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.006179220809181318\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.7886e-04 - mean_squared_error: 4.7886e-04 - val_loss: 3.4364e-04 - val_mean_squared_error: 3.4364e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.005021816280196045\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.7362e-04 - mean_squared_error: 4.7362e-04 - val_loss: 3.6514e-04 - val_mean_squared_error: 3.6514e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.005196871233549061\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.7301e-04 - mean_squared_error: 4.7301e-04 - val_loss: 3.5966e-04 - val_mean_squared_error: 3.5966e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.004351322442117667\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.7119e-04 - mean_squared_error: 4.7119e-04 - val_loss: 4.3323e-04 - val_mean_squared_error: 4.3323e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.004963349909295811\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.6848e-04 - mean_squared_error: 4.6848e-04 - val_loss: 3.9017e-04 - val_mean_squared_error: 3.9017e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.004894474806626192\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.6695e-04 - mean_squared_error: 4.6695e-04 - val_loss: 3.6550e-04 - val_mean_squared_error: 3.6550e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.003797866048808718\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.6615e-04 - mean_squared_error: 4.6615e-04 - val_loss: 3.4823e-04 - val_mean_squared_error: 3.4823e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0038262712020111778\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.6368e-04 - mean_squared_error: 4.6368e-04 - val_loss: 3.7035e-04 - val_mean_squared_error: 3.7035e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.003712561485796906\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.6229e-04 - mean_squared_error: 4.6229e-04 - val_loss: 3.7890e-04 - val_mean_squared_error: 3.7890e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0033649565090179134\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.6139e-04 - mean_squared_error: 4.6139e-04 - val_loss: 3.3164e-04 - val_mean_squared_error: 3.3164e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.003225367048850236\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.5971e-04 - mean_squared_error: 4.5971e-04 - val_loss: 3.5189e-04 - val_mean_squared_error: 3.5189e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0032784282772349016\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.5630e-04 - mean_squared_error: 4.5630e-04 - val_loss: 3.6935e-04 - val_mean_squared_error: 3.6935e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0037696164606932925\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.5601e-04 - mean_squared_error: 4.5601e-04 - val_loss: 3.7836e-04 - val_mean_squared_error: 3.7836e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.003844603471558017\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.5518e-04 - mean_squared_error: 4.5518e-04 - val_loss: 3.5130e-04 - val_mean_squared_error: 3.5130e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0035191025620289196\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.5317e-04 - mean_squared_error: 4.5317e-04 - val_loss: 3.6450e-04 - val_mean_squared_error: 3.6450e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.003109364534806369\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.5301e-04 - mean_squared_error: 4.5301e-04 - val_loss: 3.6886e-04 - val_mean_squared_error: 3.6886e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.002069061930166205\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.5189e-04 - mean_squared_error: 4.5189e-04 - val_loss: 3.8521e-04 - val_mean_squared_error: 3.8521e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0022933969386089714\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.4928e-04 - mean_squared_error: 4.4928e-04 - val_loss: 3.5670e-04 - val_mean_squared_error: 3.5670e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.00289395804633652\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.4792e-04 - mean_squared_error: 4.4792e-04 - val_loss: 3.6718e-04 - val_mean_squared_error: 3.6718e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0031602705044411206\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.4775e-04 - mean_squared_error: 4.4775e-04 - val_loss: 3.8278e-04 - val_mean_squared_error: 3.8278e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.003219178111289578\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.4827e-04 - mean_squared_error: 4.4827e-04 - val_loss: 3.2455e-04 - val_mean_squared_error: 3.2455e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0019492928808952925\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.4606e-04 - mean_squared_error: 4.4606e-04 - val_loss: 3.7819e-04 - val_mean_squared_error: 3.7819e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0013587918654496267\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.4534e-04 - mean_squared_error: 4.4534e-04 - val_loss: 3.8820e-04 - val_mean_squared_error: 3.8820e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0015344428772938734\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.4410e-04 - mean_squared_error: 4.4410e-04 - val_loss: 3.5976e-04 - val_mean_squared_error: 3.5976e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.002293713936121211\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.4392e-04 - mean_squared_error: 4.4392e-04 - val_loss: 3.6989e-04 - val_mean_squared_error: 3.6989e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.002388624292039454\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.4284e-04 - mean_squared_error: 4.4284e-04 - val_loss: 3.9592e-04 - val_mean_squared_error: 3.9592e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0017680999418878685\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.4309e-04 - mean_squared_error: 4.4309e-04 - val_loss: 3.7800e-04 - val_mean_squared_error: 3.7800e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.00129537183846673\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.4003e-04 - mean_squared_error: 4.4003e-04 - val_loss: 3.3115e-04 - val_mean_squared_error: 3.3115e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.002026492672584368\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3824e-04 - mean_squared_error: 4.3824e-04 - val_loss: 3.1204e-04 - val_mean_squared_error: 3.1204e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0032110731590364594\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3814e-04 - mean_squared_error: 4.3814e-04 - val_loss: 3.4542e-04 - val_mean_squared_error: 3.4542e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0032336538048700625\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3713e-04 - mean_squared_error: 4.3713e-04 - val_loss: 3.4712e-04 - val_mean_squared_error: 3.4712e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0031417857700248852\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3643e-04 - mean_squared_error: 4.3643e-04 - val_loss: 4.3804e-04 - val_mean_squared_error: 4.3804e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0018994834754353374\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3504e-04 - mean_squared_error: 4.3504e-04 - val_loss: 3.4358e-04 - val_mean_squared_error: 3.4358e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0018561296838639496\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3549e-04 - mean_squared_error: 4.3549e-04 - val_loss: 3.6519e-04 - val_mean_squared_error: 3.6519e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0016925017725129\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3488e-04 - mean_squared_error: 4.3488e-04 - val_loss: 3.6275e-04 - val_mean_squared_error: 3.6275e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0012464751720420164\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3330e-04 - mean_squared_error: 4.3330e-04 - val_loss: 3.6585e-04 - val_mean_squared_error: 3.6585e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0014783507403377527\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3431e-04 - mean_squared_error: 4.3431e-04 - val_loss: 2.9390e-04 - val_mean_squared_error: 2.9390e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0008412628732437089\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3240e-04 - mean_squared_error: 4.3240e-04 - val_loss: 3.3890e-04 - val_mean_squared_error: 3.3890e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0015560333941151416\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3349e-04 - mean_squared_error: 4.3349e-04 - val_loss: 3.4971e-04 - val_mean_squared_error: 3.4971e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0008501407551375628\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3276e-04 - mean_squared_error: 4.3276e-04 - val_loss: 3.5961e-04 - val_mean_squared_error: 3.5961e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.000438694224485614\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3121e-04 - mean_squared_error: 4.3121e-04 - val_loss: 3.7221e-04 - val_mean_squared_error: 3.7221e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0013506592126684147\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3137e-04 - mean_squared_error: 4.3137e-04 - val_loss: 3.8127e-04 - val_mean_squared_error: 3.8127e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0010012581392464526\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3187e-04 - mean_squared_error: 4.3187e-04 - val_loss: 3.2078e-04 - val_mean_squared_error: 3.2078e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.001067991054990003\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3090e-04 - mean_squared_error: 4.3090e-04 - val_loss: 3.5685e-04 - val_mean_squared_error: 3.5685e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0007088791295559727\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.3003e-04 - mean_squared_error: 4.3003e-04 - val_loss: 3.7631e-04 - val_mean_squared_error: 3.7631e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0006593406642008137\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2874e-04 - mean_squared_error: 4.2874e-04 - val_loss: 4.3885e-04 - val_mean_squared_error: 4.3885e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0016528046449717504\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2896e-04 - mean_squared_error: 4.2896e-04 - val_loss: 3.6801e-04 - val_mean_squared_error: 3.6801e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0018531512878663392\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2818e-04 - mean_squared_error: 4.2818e-04 - val_loss: 4.3800e-04 - val_mean_squared_error: 4.3800e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0015124313166916536\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2837e-04 - mean_squared_error: 4.2837e-04 - val_loss: 3.8251e-04 - val_mean_squared_error: 3.8251e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0009028409788371938\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2781e-04 - mean_squared_error: 4.2781e-04 - val_loss: 3.2641e-04 - val_mean_squared_error: 3.2641e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0005725185685547807\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2718e-04 - mean_squared_error: 4.2718e-04 - val_loss: 2.8259e-04 - val_mean_squared_error: 2.8259e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.000917604659256277\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2619e-04 - mean_squared_error: 4.2619e-04 - val_loss: 3.5505e-04 - val_mean_squared_error: 3.5505e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0012081788124140846\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2569e-04 - mean_squared_error: 4.2569e-04 - val_loss: 3.4991e-04 - val_mean_squared_error: 3.4991e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0016352043485921008\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2427e-04 - mean_squared_error: 4.2427e-04 - val_loss: 3.0545e-04 - val_mean_squared_error: 3.0545e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0020112875905760053\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2539e-04 - mean_squared_error: 4.2539e-04 - val_loss: 3.0303e-04 - val_mean_squared_error: 3.0303e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0012925087628432586\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2509e-04 - mean_squared_error: 4.2509e-04 - val_loss: 3.5049e-04 - val_mean_squared_error: 3.5049e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0005872218580846855\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2242e-04 - mean_squared_error: 4.2242e-04 - val_loss: 3.0525e-04 - val_mean_squared_error: 3.0525e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0013495861409609233\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2395e-04 - mean_squared_error: 4.2395e-04 - val_loss: 3.3233e-04 - val_mean_squared_error: 3.3233e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0008544594341977074\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2240e-04 - mean_squared_error: 4.2240e-04 - val_loss: 3.4015e-04 - val_mean_squared_error: 3.4015e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.001679969445566698\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2302e-04 - mean_squared_error: 4.2302e-04 - val_loss: 3.3833e-04 - val_mean_squared_error: 3.3833e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0009797586918496304\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2216e-04 - mean_squared_error: 4.2216e-04 - val_loss: 3.2442e-04 - val_mean_squared_error: 3.2442e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0003415610446180217\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2158e-04 - mean_squared_error: 4.2158e-04 - val_loss: 4.0913e-04 - val_mean_squared_error: 4.0913e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0011755170385847613\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2137e-04 - mean_squared_error: 4.2137e-04 - val_loss: 3.6919e-04 - val_mean_squared_error: 3.6919e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0008283243516991057\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2121e-04 - mean_squared_error: 4.2121e-04 - val_loss: 3.9204e-04 - val_mean_squared_error: 3.9204e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.001046515132474779\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.1998e-04 - mean_squared_error: 4.1998e-04 - val_loss: 3.5073e-04 - val_mean_squared_error: 3.5073e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0011221758468684673\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2099e-04 - mean_squared_error: 4.2099e-04 - val_loss: 3.5768e-04 - val_mean_squared_error: 3.5768e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0006128759799184369\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.2003e-04 - mean_squared_error: 4.2003e-04 - val_loss: 3.7199e-04 - val_mean_squared_error: 3.7199e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0006884344908530959\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.1881e-04 - mean_squared_error: 4.1881e-04 - val_loss: 3.1541e-04 - val_mean_squared_error: 3.1541e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.0011325034356997055\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.1942e-04 - mean_squared_error: 4.1942e-04 - val_loss: 3.5130e-04 - val_mean_squared_error: 3.5130e-04\n",
      "376 of 1095 weights retained\n",
      "change in log loss: -0.000786460729478744\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 4.1921e-04 - mean_squared_error: 4.1921e-04 - val_loss: 3.1411e-04 - val_mean_squared_error: 3.1411e-04\n",
      "286 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "286 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 8.2656e-04 - val_mean_squared_error: 8.2656e-04\n",
      "286 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 9.3028e-04 - val_mean_squared_error: 9.3028e-04\n",
      "286 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 6.4747e-04 - val_mean_squared_error: 6.4747e-04\n",
      "286 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 6.7048e-04 - val_mean_squared_error: 6.7048e-04\n",
      "286 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 6.5285e-04 - val_mean_squared_error: 6.5285e-04\n",
      "286 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 6.0201e-04 - val_mean_squared_error: 6.0201e-04\n",
      "286 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 5.7842e-04 - val_mean_squared_error: 5.7842e-04\n",
      "286 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 6.6155e-04 - val_mean_squared_error: 6.6155e-04\n",
      "286 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 5.6254e-04 - val_mean_squared_error: 5.6254e-04\n",
      "286 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 7.5165e-04 - val_mean_squared_error: 7.5165e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.03209388376420286\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 6.5905e-04 - val_mean_squared_error: 6.5905e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.028839444587159813\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 6.3137e-04 - val_mean_squared_error: 6.3137e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.026592003952803367\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0011 - mean_squared_error: 0.0011 - val_loss: 6.0954e-04 - val_mean_squared_error: 6.0954e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.024529492060722857\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 5.7949e-04 - val_mean_squared_error: 5.7949e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.02196100659169331\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0010 - mean_squared_error: 0.0010 - val_loss: 6.2648e-04 - val_mean_squared_error: 6.2648e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.01982928688022012\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 9.9959e-04 - mean_squared_error: 9.9959e-04 - val_loss: 6.4579e-04 - val_mean_squared_error: 6.4579e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.01784526668960007\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 9.8902e-04 - mean_squared_error: 9.8902e-04 - val_loss: 6.7178e-04 - val_mean_squared_error: 6.7178e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.01588116401085693\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 9.7538e-04 - mean_squared_error: 9.7538e-04 - val_loss: 6.7033e-04 - val_mean_squared_error: 6.7033e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.014863682158483105\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 9.6479e-04 - mean_squared_error: 9.6479e-04 - val_loss: 5.8613e-04 - val_mean_squared_error: 5.8613e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.013146958659568053\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 9.5200e-04 - mean_squared_error: 9.5200e-04 - val_loss: 5.3349e-04 - val_mean_squared_error: 5.3349e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.012236272801841919\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 9.4174e-04 - mean_squared_error: 9.4174e-04 - val_loss: 6.0120e-04 - val_mean_squared_error: 6.0120e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.012222543036504385\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 9.3214e-04 - mean_squared_error: 9.3214e-04 - val_loss: 6.7816e-04 - val_mean_squared_error: 6.7816e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.011486122596760406\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 9.2340e-04 - mean_squared_error: 9.2340e-04 - val_loss: 5.0839e-04 - val_mean_squared_error: 5.0839e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.01087822157193341\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 9.1356e-04 - mean_squared_error: 9.1356e-04 - val_loss: 5.7656e-04 - val_mean_squared_error: 5.7656e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.010211813695348182\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 9.0280e-04 - mean_squared_error: 9.0280e-04 - val_loss: 8.1755e-04 - val_mean_squared_error: 8.1755e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.010461090693561381\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.9669e-04 - mean_squared_error: 8.9669e-04 - val_loss: 5.0898e-04 - val_mean_squared_error: 5.0898e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.010010512873357191\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.8905e-04 - mean_squared_error: 8.8905e-04 - val_loss: 5.4993e-04 - val_mean_squared_error: 5.4993e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.009444417601891297\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.8384e-04 - mean_squared_error: 8.8384e-04 - val_loss: 6.7370e-04 - val_mean_squared_error: 6.7370e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.008147560784147245\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.8043e-04 - mean_squared_error: 8.8043e-04 - val_loss: 5.4272e-04 - val_mean_squared_error: 5.4272e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.00645995179816361\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.7238e-04 - mean_squared_error: 8.7238e-04 - val_loss: 5.8512e-04 - val_mean_squared_error: 5.8512e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.006472487243039282\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.6718e-04 - mean_squared_error: 8.6718e-04 - val_loss: 6.1744e-04 - val_mean_squared_error: 6.1744e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.006286116343564352\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.6085e-04 - mean_squared_error: 8.6085e-04 - val_loss: 5.8297e-04 - val_mean_squared_error: 5.8297e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.006787770487661771\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.5556e-04 - mean_squared_error: 8.5556e-04 - val_loss: 5.5635e-04 - val_mean_squared_error: 5.5635e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.007060676663758425\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.5469e-04 - mean_squared_error: 8.5469e-04 - val_loss: 6.0509e-04 - val_mean_squared_error: 6.0509e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.005445239929950496\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.4897e-04 - mean_squared_error: 8.4897e-04 - val_loss: 5.9117e-04 - val_mean_squared_error: 5.9117e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.004963227964708272\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.4508e-04 - mean_squared_error: 8.4508e-04 - val_loss: 6.0895e-04 - val_mean_squared_error: 6.0895e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.004472691746048252\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.4346e-04 - mean_squared_error: 8.4346e-04 - val_loss: 5.2256e-04 - val_mean_squared_error: 5.2256e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.003980260651012424\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.3958e-04 - mean_squared_error: 8.3958e-04 - val_loss: 4.9527e-04 - val_mean_squared_error: 4.9527e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.004220090876238869\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.3563e-04 - mean_squared_error: 8.3563e-04 - val_loss: 5.9557e-04 - val_mean_squared_error: 5.9557e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.003821426843350517\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.3413e-04 - mean_squared_error: 8.3413e-04 - val_loss: 5.5273e-04 - val_mean_squared_error: 5.5273e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.003540738536778054\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.3014e-04 - mean_squared_error: 8.3014e-04 - val_loss: 5.8330e-04 - val_mean_squared_error: 5.8330e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0038337881610239766\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.2907e-04 - mean_squared_error: 8.2907e-04 - val_loss: 7.8300e-04 - val_mean_squared_error: 7.8300e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.003177125889334498\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.2532e-04 - mean_squared_error: 8.2532e-04 - val_loss: 4.6918e-04 - val_mean_squared_error: 4.6918e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0030917682880486907\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.2328e-04 - mean_squared_error: 8.2328e-04 - val_loss: 5.4841e-04 - val_mean_squared_error: 5.4841e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0032004313176070553\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.2353e-04 - mean_squared_error: 8.2353e-04 - val_loss: 5.3487e-04 - val_mean_squared_error: 5.3487e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.002300147447380718\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.1856e-04 - mean_squared_error: 8.1856e-04 - val_loss: 6.7859e-04 - val_mean_squared_error: 6.7859e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.002767592820451137\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.1700e-04 - mean_squared_error: 8.1700e-04 - val_loss: 5.2507e-04 - val_mean_squared_error: 5.2507e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0026007430255958752\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.1623e-04 - mean_squared_error: 8.1623e-04 - val_loss: 5.3520e-04 - val_mean_squared_error: 5.3520e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.002515828059376224\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.1442e-04 - mean_squared_error: 8.1442e-04 - val_loss: 5.4115e-04 - val_mean_squared_error: 5.4115e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.002509596645153378\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.1230e-04 - mean_squared_error: 8.1230e-04 - val_loss: 5.2249e-04 - val_mean_squared_error: 5.2249e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0018528750615600664\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.0883e-04 - mean_squared_error: 8.0883e-04 - val_loss: 5.0963e-04 - val_mean_squared_error: 5.0963e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0024927861181076594\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 8.0791e-04 - mean_squared_error: 8.0791e-04 - val_loss: 5.3328e-04 - val_mean_squared_error: 5.3328e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.002737375191007807\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.9274e-04 - mean_squared_error: 7.9274e-04 - val_loss: 5.4068e-04 - val_mean_squared_error: 5.4068e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0059381590871634415\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.8788e-04 - mean_squared_error: 7.8788e-04 - val_loss: 5.6959e-04 - val_mean_squared_error: 5.6959e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.008113725186256637\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.8221e-04 - mean_squared_error: 7.8221e-04 - val_loss: 5.3349e-04 - val_mean_squared_error: 5.3349e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.00920486176766433\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.7994e-04 - mean_squared_error: 7.7994e-04 - val_loss: 5.0661e-04 - val_mean_squared_error: 5.0661e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.008385351468337854\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.7615e-04 - mean_squared_error: 7.7615e-04 - val_loss: 5.3423e-04 - val_mean_squared_error: 5.3423e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0052438561682144336\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.7516e-04 - mean_squared_error: 7.7516e-04 - val_loss: 5.7062e-04 - val_mean_squared_error: 5.7062e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.004034146850946385\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.7207e-04 - mean_squared_error: 7.7207e-04 - val_loss: 5.5012e-04 - val_mean_squared_error: 5.5012e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.003223444481393445\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.6768e-04 - mean_squared_error: 7.6768e-04 - val_loss: 4.9742e-04 - val_mean_squared_error: 4.9742e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.003693981204769603\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.6387e-04 - mean_squared_error: 7.6387e-04 - val_loss: 5.6726e-04 - val_mean_squared_error: 5.6726e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.00415878226427413\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.6387e-04 - mean_squared_error: 7.6387e-04 - val_loss: 5.3939e-04 - val_mean_squared_error: 5.3939e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.004003359954375174\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.5955e-04 - mean_squared_error: 7.5955e-04 - val_loss: 4.8380e-04 - val_mean_squared_error: 4.8380e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.003767964046546002\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.5702e-04 - mean_squared_error: 7.5702e-04 - val_loss: 6.4344e-04 - val_mean_squared_error: 6.4344e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.003363359882824435\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.5713e-04 - mean_squared_error: 7.5713e-04 - val_loss: 5.3403e-04 - val_mean_squared_error: 5.3403e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.002672683711151258\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.5247e-04 - mean_squared_error: 7.5247e-04 - val_loss: 5.0460e-04 - val_mean_squared_error: 5.0460e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0033273378549496524\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.5026e-04 - mean_squared_error: 7.5026e-04 - val_loss: 5.7792e-04 - val_mean_squared_error: 5.7792e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.003063423192635195\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.4983e-04 - mean_squared_error: 7.4983e-04 - val_loss: 4.8652e-04 - val_mean_squared_error: 4.8652e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0028206361271956304\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.4589e-04 - mean_squared_error: 7.4589e-04 - val_loss: 5.3431e-04 - val_mean_squared_error: 5.3431e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.003342366870666247\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.4546e-04 - mean_squared_error: 7.4546e-04 - val_loss: 4.8508e-04 - val_mean_squared_error: 4.8508e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0024564792396040147\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.4497e-04 - mean_squared_error: 7.4497e-04 - val_loss: 5.6383e-04 - val_mean_squared_error: 5.6383e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.001999846261668603\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.3999e-04 - mean_squared_error: 7.3999e-04 - val_loss: 6.2234e-04 - val_mean_squared_error: 6.2234e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.002764088144858734\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.3999e-04 - mean_squared_error: 7.3999e-04 - val_loss: 4.8338e-04 - val_mean_squared_error: 4.8338e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.002325440245407151\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.3823e-04 - mean_squared_error: 7.3823e-04 - val_loss: 5.5192e-04 - val_mean_squared_error: 5.5192e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0026197139391024304\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.3398e-04 - mean_squared_error: 7.3398e-04 - val_loss: 6.0823e-04 - val_mean_squared_error: 6.0823e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0032120102143162743\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.2903e-04 - mean_squared_error: 7.2903e-04 - val_loss: 4.9699e-04 - val_mean_squared_error: 4.9699e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.003799783363060971\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.2689e-04 - mean_squared_error: 7.2689e-04 - val_loss: 4.4424e-04 - val_mean_squared_error: 4.4424e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.004826302258184256\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.2761e-04 - mean_squared_error: 7.2761e-04 - val_loss: 5.2201e-04 - val_mean_squared_error: 5.2201e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.003870303302706324\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.2478e-04 - mean_squared_error: 7.2478e-04 - val_loss: 5.4983e-04 - val_mean_squared_error: 5.4983e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.002717368254188557\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.2346e-04 - mean_squared_error: 7.2346e-04 - val_loss: 4.7164e-04 - val_mean_squared_error: 4.7164e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0018229832942338042\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.2107e-04 - mean_squared_error: 7.2107e-04 - val_loss: 4.8787e-04 - val_mean_squared_error: 4.8787e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.002178706987724155\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.2374e-04 - mean_squared_error: 7.2374e-04 - val_loss: 4.9097e-04 - val_mean_squared_error: 4.9097e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0015784683199207006\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.2006e-04 - mean_squared_error: 7.2006e-04 - val_loss: 5.3963e-04 - val_mean_squared_error: 5.3963e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0012677813426431594\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.1655e-04 - mean_squared_error: 7.1655e-04 - val_loss: 5.0837e-04 - val_mean_squared_error: 5.0837e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0020590595361327235\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.1582e-04 - mean_squared_error: 7.1582e-04 - val_loss: 4.5628e-04 - val_mean_squared_error: 4.5628e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.002458705279155593\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.1373e-04 - mean_squared_error: 7.1373e-04 - val_loss: 4.5489e-04 - val_mean_squared_error: 4.5489e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.003375631546600477\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.1192e-04 - mean_squared_error: 7.1192e-04 - val_loss: 4.6833e-04 - val_mean_squared_error: 4.6833e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0026679887186549234\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.1137e-04 - mean_squared_error: 7.1137e-04 - val_loss: 4.8657e-04 - val_mean_squared_error: 4.8657e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0019983167165056326\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.0864e-04 - mean_squared_error: 7.0864e-04 - val_loss: 5.4537e-04 - val_mean_squared_error: 5.4537e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.002347393801499731\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.0766e-04 - mean_squared_error: 7.0766e-04 - val_loss: 5.4869e-04 - val_mean_squared_error: 5.4869e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0021706831285175365\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 7.0224e-04 - mean_squared_error: 7.0224e-04 - val_loss: 5.7033e-04 - val_mean_squared_error: 5.7033e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0032614907741082\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.9995e-04 - mean_squared_error: 6.9995e-04 - val_loss: 4.6004e-04 - val_mean_squared_error: 4.6004e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.004144996519273025\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.9847e-04 - mean_squared_error: 6.9847e-04 - val_loss: 5.1883e-04 - val_mean_squared_error: 5.1883e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0039879394468136375\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.9482e-04 - mean_squared_error: 6.9482e-04 - val_loss: 6.1471e-04 - val_mean_squared_error: 6.1471e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.004199992217338355\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.9538e-04 - mean_squared_error: 6.9538e-04 - val_loss: 4.6876e-04 - val_mean_squared_error: 4.6876e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0026975419384740462\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.9281e-04 - mean_squared_error: 6.9281e-04 - val_loss: 4.8620e-04 - val_mean_squared_error: 4.8620e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0024924745175136653\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.9346e-04 - mean_squared_error: 6.9346e-04 - val_loss: 5.4489e-04 - val_mean_squared_error: 5.4489e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.0017297303163767985\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.9078e-04 - mean_squared_error: 6.9078e-04 - val_loss: 5.3983e-04 - val_mean_squared_error: 5.3983e-04\n",
      "286 of 1095 weights retained\n",
      "change in log loss: -0.001444359903200132\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 6.9275e-04 - mean_squared_error: 6.9275e-04 - val_loss: 4.5004e-04 - val_mean_squared_error: 4.5004e-04\n",
      "216 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0381 - mean_squared_error: 0.0381 - val_loss: 0.0078 - val_mean_squared_error: 0.0078\n",
      "216 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0276 - mean_squared_error: 0.0276 - val_loss: 0.0041 - val_mean_squared_error: 0.0041\n",
      "216 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0218 - mean_squared_error: 0.0218 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "216 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0183 - mean_squared_error: 0.0183 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "216 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0143 - mean_squared_error: 0.0143 - val_loss: 0.0024 - val_mean_squared_error: 0.0024\n",
      "216 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0114 - mean_squared_error: 0.0114 - val_loss: 0.0022 - val_mean_squared_error: 0.0022\n",
      "216 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0093 - mean_squared_error: 0.0093 - val_loss: 0.0023 - val_mean_squared_error: 0.0023\n",
      "216 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "216 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0021 - val_mean_squared_error: 0.0021\n",
      "216 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "216 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.16668620743918394\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0042 - mean_squared_error: 0.0042 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.15001513878902495\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0038 - mean_squared_error: 0.0038 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.1312804576994131\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0035 - mean_squared_error: 0.0035 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.11008693333599862\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0033 - mean_squared_error: 0.0033 - val_loss: 0.0016 - val_mean_squared_error: 0.0016\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.09137033783102644\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.07384817369512331\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0030 - mean_squared_error: 0.0030 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.0607738589794633\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.05254727666322778\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.045756717463022234\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.04135262226669223\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.037366241202611006\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.034726549794979134\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.032537343823393794\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.03088930797836187\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.029007724937289092\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.026866644231830605\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.025556804294115887\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.024344028933919848\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.02313956012701146\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.0222947089458414\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.021806509364152626\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.021615328020241797\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.02096408301984032\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.02075851459342104\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.02009153646635964\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.018261299293919953\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.016505639105583114\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.01484301136142352\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.014616749581000787\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.016444960242556705\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.017376790225427152\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.017211016810019242\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.015875807164118516\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 9.9330e-04 - val_mean_squared_error: 9.9330e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.013289470637643408\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.01242609449370602\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.012110077410622422\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0016 - mean_squared_error: 0.0016 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.011355746924304633\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.011199058084818247\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.010891345414750564\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 9.8318e-04 - val_mean_squared_error: 9.8318e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.010984269734579666\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.011149161838533095\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 9.4887e-04 - val_mean_squared_error: 9.4887e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.010355050155258283\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 9.7671e-04 - val_mean_squared_error: 9.7671e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.009852353535633851\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0015 - mean_squared_error: 0.0015 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.009191952013198446\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 9.3776e-04 - val_mean_squared_error: 9.3776e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.008633684073371839\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 9.5544e-04 - val_mean_squared_error: 9.5544e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.007910629085960519\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 9.1535e-04 - val_mean_squared_error: 9.1535e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.007246784851197674\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 9.4632e-04 - val_mean_squared_error: 9.4632e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.007133267582742908\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.006957202426832287\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 9.8339e-04 - val_mean_squared_error: 9.8339e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.00730402382848605\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 9.5584e-04 - val_mean_squared_error: 9.5584e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.007473006735570387\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 9.8203e-04 - val_mean_squared_error: 9.8203e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.007134350447619342\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 8.8029e-04 - val_mean_squared_error: 8.8029e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.00653593213649617\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.005746384079712286\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0014 - mean_squared_error: 0.0014 - val_loss: 8.8541e-04 - val_mean_squared_error: 8.8541e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.005029703176243183\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 9.8246e-04 - val_mean_squared_error: 9.8246e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.005191463835617194\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 8.1835e-04 - val_mean_squared_error: 8.1835e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.004876874767612893\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 8.7262e-04 - val_mean_squared_error: 8.7262e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.005105971081865501\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 8.3078e-04 - val_mean_squared_error: 8.3078e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.005337102689876083\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.005381442050763852\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 9.2664e-04 - val_mean_squared_error: 9.2664e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.005406474293705221\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 9.5497e-04 - val_mean_squared_error: 9.5497e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.004766941498938415\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 9.5040e-04 - val_mean_squared_error: 9.5040e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.004470496515090794\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 8.4813e-04 - val_mean_squared_error: 8.4813e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.004132088224517272\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 9.3134e-04 - val_mean_squared_error: 9.3134e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.003611248920435184\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 9.2110e-04 - val_mean_squared_error: 9.2110e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.003581123855940005\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 8.3225e-04 - val_mean_squared_error: 8.3225e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.0036299052724446668\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 7.6436e-04 - val_mean_squared_error: 7.6436e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.003914133633362571\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 8.7350e-04 - val_mean_squared_error: 8.7350e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.004664023078333246\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 9.4154e-04 - val_mean_squared_error: 9.4154e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.004908977859843455\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 8.8284e-04 - val_mean_squared_error: 8.8284e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.0050541430843482615\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0013 - mean_squared_error: 0.0013 - val_loss: 8.6543e-04 - val_mean_squared_error: 8.6543e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.004800448648772715\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 9.0325e-04 - val_mean_squared_error: 9.0325e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.0045591229724453175\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 8.1135e-04 - val_mean_squared_error: 8.1135e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.004126532839134667\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 8.0058e-04 - val_mean_squared_error: 8.0058e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.004317800986592513\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 8.4477e-04 - val_mean_squared_error: 8.4477e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.003982153525345922\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 7.7771e-04 - val_mean_squared_error: 7.7771e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.0028914258711587593\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 8.5219e-04 - val_mean_squared_error: 8.5219e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.0028923513497951525\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 7.3815e-04 - val_mean_squared_error: 7.3815e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.00201450862664454\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 6.8997e-04 - val_mean_squared_error: 6.8997e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.002132384936110787\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 7.9207e-04 - val_mean_squared_error: 7.9207e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.0023274662651897593\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 8.3169e-04 - val_mean_squared_error: 8.3169e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.002168310180020283\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 7.4460e-04 - val_mean_squared_error: 7.4460e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.0023124834742724865\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 9.1843e-04 - val_mean_squared_error: 9.1843e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.002551512395317035\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 8.4958e-04 - val_mean_squared_error: 8.4958e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.0029171270663668203\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 8.0395e-04 - val_mean_squared_error: 8.0395e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.0034164431591743316\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 7.5431e-04 - val_mean_squared_error: 7.5431e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.0045496576478594175\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 8.3067e-04 - val_mean_squared_error: 8.3067e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.007209256317861401\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 8.1890e-04 - val_mean_squared_error: 8.1890e-04\n",
      "216 of 1095 weights retained\n",
      "change in log loss: -0.009006427179718779\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0012 - mean_squared_error: 0.0012 - val_loss: 9.1476e-04 - val_mean_squared_error: 9.1476e-04\n",
      "164 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0146 - mean_squared_error: 0.0146 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "164 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0094 - mean_squared_error: 0.0094 - val_loss: 0.0019 - val_mean_squared_error: 0.0019\n",
      "164 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0071 - mean_squared_error: 0.0071 - val_loss: 0.0017 - val_mean_squared_error: 0.0017\n",
      "164 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "164 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0047 - mean_squared_error: 0.0047 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "164 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0043 - mean_squared_error: 0.0043 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "164 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0039 - mean_squared_error: 0.0039 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "164 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0036 - mean_squared_error: 0.0036 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "164 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0034 - mean_squared_error: 0.0034 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "164 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0032 - mean_squared_error: 0.0032 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0031 - mean_squared_error: 0.0031 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.058175314396928135\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.050115295047601816\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0029 - mean_squared_error: 0.0029 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0436567391772662\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0028 - mean_squared_error: 0.0028 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.037702939452576745\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0027 - mean_squared_error: 0.0027 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.034764611141308244\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0026 - mean_squared_error: 0.0026 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.03145731546884001\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.02923916102716828\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0249310341237845\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0025 - mean_squared_error: 0.0025 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.02025637647739198\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.017380483454878304\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.014212619108298963\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0024 - mean_squared_error: 0.0024 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.013231026329588724\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.011985059434573175\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.011513622755245034\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.011368099340658855\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.010742885127556834\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0023 - mean_squared_error: 0.0023 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.009481750336552297\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.008525983221916222\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.007719150321725099\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.00718187818994287\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.007970073397110866\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.006980484961175426\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.005439466455858133\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.00442047519508959\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0022 - mean_squared_error: 0.0022 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0039080302633540676\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0015 - val_mean_squared_error: 0.0015\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.003935533021603765\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.004593118956919051\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.004446094120391875\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.003793354237399349\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.003767054965926553\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0026636468859246865\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0033033833836895177\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0037849997695420523\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0027737213556213725\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0027125158630911805\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0022832979585862834\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0023917140719760255\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0035157029914307802\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0031409425400128477\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0021 - mean_squared_error: 0.0021 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0027407209055227977\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0029491213420824725\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0014 - val_mean_squared_error: 0.0014\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0022585874409664086\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.002323336326019998\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0028811897218110616\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 9.8137e-04 - val_mean_squared_error: 9.8137e-04\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.002004903005354608\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.002237430877353175\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.002270657863759906\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.005703823784338313\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0020 - mean_squared_error: 0.0020 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.01007806543068357\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.011744613591559538\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.011495754986775353\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.008790841278645711\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.006497430259365\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0037570613505035766\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.002357869199472784\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0007636410212732425\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.001054475960873269\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0016670934257221326\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0005763528583626609\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0008219950699390743\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0009464296408838724\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0017266611003168286\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 9.7491e-04 - val_mean_squared_error: 9.7491e-04\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.00222969836682152\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.002264035091839922\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0016925238463840753\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0012758957901723988\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 9.6927e-04 - val_mean_squared_error: 9.6927e-04\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.002206134738833354\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0015106399636466428\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.002408826730792013\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.002221331962455775\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0017073247688950133\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 8s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0023273337799489813\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0019 - mean_squared_error: 0.0019 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0015489163927764338\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0018952104155400828\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0016941893638924288\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0016809038557334954\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.002045179764719407\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.005886755626390627\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.008550148280700443\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.009639177944187782\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.008326777379298544\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.004407683189629363\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.00350863595136941\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0012 - val_mean_squared_error: 0.0012\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0027008116460922604\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 9.9481e-04 - val_mean_squared_error: 9.9481e-04\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.002169563836756927\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0013001493495023997\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0017821080607363093\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0018 - mean_squared_error: 0.0018 - val_loss: 0.0013 - val_mean_squared_error: 0.0013\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.001502697256185348\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0010 - val_mean_squared_error: 0.0010\n",
      "164 of 1095 weights retained\n",
      "change in log loss: -0.0014609445428028778\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0017 - mean_squared_error: 0.0017 - val_loss: 0.0011 - val_mean_squared_error: 0.0011\n",
      "124 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0101 - mean_squared_error: 0.0101 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "124 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0088 - mean_squared_error: 0.0088 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "124 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0081 - mean_squared_error: 0.0081 - val_loss: 0.0039 - val_mean_squared_error: 0.0039\n",
      "124 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0077 - mean_squared_error: 0.0077 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
      "124 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0074 - mean_squared_error: 0.0074 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "124 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0072 - mean_squared_error: 0.0072 - val_loss: 0.0037 - val_mean_squared_error: 0.0037\n",
      "124 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0069 - mean_squared_error: 0.0069 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "124 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0067 - mean_squared_error: 0.0067 - val_loss: 0.0036 - val_mean_squared_error: 0.0036\n",
      "124 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0065 - mean_squared_error: 0.0065 - val_loss: 0.0038 - val_mean_squared_error: 0.0038\n",
      "124 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0064 - mean_squared_error: 0.0064 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "124 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0063 - mean_squared_error: 0.0063 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.02434503474023353\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0062 - mean_squared_error: 0.0062 - val_loss: 0.0035 - val_mean_squared_error: 0.0035\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.01901334479772332\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0061 - mean_squared_error: 0.0061 - val_loss: 0.0034 - val_mean_squared_error: 0.0034\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.01811957753128257\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0060 - mean_squared_error: 0.0060 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.01630988928244448\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0059 - mean_squared_error: 0.0059 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.015506034778458133\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0033 - val_mean_squared_error: 0.0033\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.014157427618475271\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0058 - mean_squared_error: 0.0058 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.013009503810511136\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0057 - mean_squared_error: 0.0057 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.012849691220162107\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.01264002823460375\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0056 - mean_squared_error: 0.0056 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.01182834140723843\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.009796245898350708\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0055 - mean_squared_error: 0.0055 - val_loss: 0.0032 - val_mean_squared_error: 0.0032\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.007885474995657615\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.007296068518978016\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.006794579994646277\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0054 - mean_squared_error: 0.0054 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.007854805661595687\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.007930439123339239\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.007799328851020304\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0053 - mean_squared_error: 0.0053 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.007549323239935513\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.006459471551101492\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0052 - mean_squared_error: 0.0052 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.0073095468479347225\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.008301703583274866\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.008553082975729653\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.007378269317296349\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.004639885928364951\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0051 - mean_squared_error: 0.0051 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.0031535354328491305\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.00330861740962618\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.003921718533386631\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.0047713901230199696\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.0036375568183812934\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.002345795650025684\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.0016804535348327043\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.0012209379944314591\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.0024132966147747403\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0050 - mean_squared_error: 0.0050 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.0011374439400504421\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.0009005231330130314\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.001179756309493074\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.0011256304159721342\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0031 - val_mean_squared_error: 0.0031\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.0031126655117343915\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.0020390565565189256\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.0021246997934620815\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.0015862615354762521\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0028 - val_mean_squared_error: 0.0028\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.0014684841933652049\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.0016148972337379774\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0049 - mean_squared_error: 0.0049 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.0009885134710612142\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0030 - val_mean_squared_error: 0.0030\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.002301605809047702\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.002074188393724974\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0029 - val_mean_squared_error: 0.0029\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.002468665069328191\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 6s - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.002814200823217261\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.001402108711248795\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0025 - val_mean_squared_error: 0.0025\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.0013764294022053924\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -0.000722609074709224\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0027 - val_mean_squared_error: 0.0027\n",
      "124 of 1095 weights retained\n",
      "change in log loss: 0.0007601313591538705\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "124 of 1095 weights retained\n",
      "change in log loss: -4.2283214191085605e-05\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "************************************************ PRUNING ********************************************************\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0048 - mean_squared_error: 0.0048 - val_loss: 0.0026 - val_mean_squared_error: 0.0026\n",
      "92 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0305 - mean_squared_error: 0.0305 - val_loss: 0.0102 - val_mean_squared_error: 0.0102\n",
      "92 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0308 - mean_squared_error: 0.0308 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
      "92 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0300 - mean_squared_error: 0.0300 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
      "92 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0310 - mean_squared_error: 0.0310 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
      "92 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0324 - mean_squared_error: 0.0324 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
      "92 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0336 - mean_squared_error: 0.0336 - val_loss: 0.0107 - val_mean_squared_error: 0.0107\n",
      "92 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0346 - mean_squared_error: 0.0346 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
      "92 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0364 - mean_squared_error: 0.0364 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
      "92 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0369 - mean_squared_error: 0.0369 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
      "92 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0383 - mean_squared_error: 0.0383 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
      "92 of 1095 weights retained\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0382 - mean_squared_error: 0.0382 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
      "92 of 1095 weights retained\n",
      "change in log loss: 0.025167040223533665\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0379 - mean_squared_error: 0.0379 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
      "92 of 1095 weights retained\n",
      "change in log loss: 0.011900102391274037\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
      "92 of 1095 weights retained\n",
      "change in log loss: 0.0024083814735300635\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0378 - mean_squared_error: 0.0378 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.004388910353460895\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.00329246792904625\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0126 - val_mean_squared_error: 0.0126\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.0025365061583977333\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0125 - val_mean_squared_error: 0.0125\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.0033487242296074138\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0122 - val_mean_squared_error: 0.0122\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.0033542430778877863\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.0003589243685165888\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0375 - mean_squared_error: 0.0375 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "92 of 1095 weights retained\n",
      "change in log loss: 0.0020245236857389104\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0374 - mean_squared_error: 0.0374 - val_loss: 0.0117 - val_mean_squared_error: 0.0117\n",
      "92 of 1095 weights retained\n",
      "change in log loss: 0.0018606885308702914\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0377 - mean_squared_error: 0.0377 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "92 of 1095 weights retained\n",
      "change in log loss: 0.0008507064611940063\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0373 - mean_squared_error: 0.0373 - val_loss: 0.0123 - val_mean_squared_error: 0.0123\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.0007085221778356798\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0376 - mean_squared_error: 0.0376 - val_loss: 0.0100 - val_mean_squared_error: 0.0100\n",
      "92 of 1095 weights retained\n",
      "change in log loss: 0.00036970092764632145\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0363 - mean_squared_error: 0.0363 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.006397965795939209\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0371 - mean_squared_error: 0.0371 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.006129432712163374\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0360 - mean_squared_error: 0.0360 - val_loss: 0.0120 - val_mean_squared_error: 0.0120\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.008838253236553184\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0358 - mean_squared_error: 0.0358 - val_loss: 0.0116 - val_mean_squared_error: 0.0116\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.010663753221932248\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0354 - mean_squared_error: 0.0354 - val_loss: 0.0119 - val_mean_squared_error: 0.0119\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.008297627871617252\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.012076829574166559\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.0080032252841169\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0349 - mean_squared_error: 0.0349 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.006500944774465278\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0110 - val_mean_squared_error: 0.0110\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.0066198265910921705\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0343 - mean_squared_error: 0.0343 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.006310096616885086\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0339 - mean_squared_error: 0.0339 - val_loss: 0.0106 - val_mean_squared_error: 0.0106\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.007419827715992144\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0337 - mean_squared_error: 0.0337 - val_loss: 0.0108 - val_mean_squared_error: 0.0108\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.008505645385194716\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0333 - mean_squared_error: 0.0333 - val_loss: 0.0103 - val_mean_squared_error: 0.0103\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.008440202241622452\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0324 - mean_squared_error: 0.0324 - val_loss: 0.0097 - val_mean_squared_error: 0.0097\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.013679798270657018\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0325 - mean_squared_error: 0.0325 - val_loss: 0.0098 - val_mean_squared_error: 0.0098\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.012151916072714486\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0389 - mean_squared_error: 0.0389 - val_loss: 0.0097 - val_mean_squared_error: 0.0097\n",
      "92 of 1095 weights retained\n",
      "change in log loss: 0.026757911786815747\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0372 - mean_squared_error: 0.0372 - val_loss: 0.0094 - val_mean_squared_error: 0.0094\n",
      "92 of 1095 weights retained\n",
      "change in log loss: 0.040635710086682875\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0352 - mean_squared_error: 0.0352 - val_loss: 0.0097 - val_mean_squared_error: 0.0097\n",
      "92 of 1095 weights retained\n",
      "change in log loss: 0.029960340614244796\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0344 - mean_squared_error: 0.0344 - val_loss: 0.0104 - val_mean_squared_error: 0.0104\n",
      "92 of 1095 weights retained\n",
      "change in log loss: 0.0011223785887556348\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0324 - mean_squared_error: 0.0324 - val_loss: 0.0096 - val_mean_squared_error: 0.0096\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.04450841094101832\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0312 - mean_squared_error: 0.0312 - val_loss: 0.0100 - val_mean_squared_error: 0.0100\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.043521706805508154\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0308 - mean_squared_error: 0.0308 - val_loss: 0.0102 - val_mean_squared_error: 0.0102\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.03676832313287215\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0293 - mean_squared_error: 0.0293 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.03720599734054586\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0280 - mean_squared_error: 0.0280 - val_loss: 0.0099 - val_mean_squared_error: 0.0099\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.035264996748227806\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0277 - mean_squared_error: 0.0277 - val_loss: 0.0103 - val_mean_squared_error: 0.0103\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.03330435314931535\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0273 - mean_squared_error: 0.0273 - val_loss: 0.0107 - val_mean_squared_error: 0.0107\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.02980420079056101\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0268 - mean_squared_error: 0.0268 - val_loss: 0.0101 - val_mean_squared_error: 0.0101\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.020426198621472325\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0262 - mean_squared_error: 0.0262 - val_loss: 0.0100 - val_mean_squared_error: 0.0100\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.016716749803199704\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0253 - mean_squared_error: 0.0253 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.02193764747721838\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0256 - mean_squared_error: 0.0256 - val_loss: 0.0101 - val_mean_squared_error: 0.0101\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.018668993556311464\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0252 - mean_squared_error: 0.0252 - val_loss: 0.0104 - val_mean_squared_error: 0.0104\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.01447662175160036\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0254 - mean_squared_error: 0.0254 - val_loss: 0.0108 - val_mean_squared_error: 0.0108\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.006056890670415593\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0245 - mean_squared_error: 0.0245 - val_loss: 0.0104 - val_mean_squared_error: 0.0104\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.0075861813721667115\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0239 - mean_squared_error: 0.0239 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.01674108557488818\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0104 - val_mean_squared_error: 0.0104\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.012725154624225854\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0245 - mean_squared_error: 0.0245 - val_loss: 0.0105 - val_mean_squared_error: 0.0105\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.007854691649130108\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0235 - mean_squared_error: 0.0235 - val_loss: 0.0108 - val_mean_squared_error: 0.0108\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.0052927369807934666\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0242 - mean_squared_error: 0.0242 - val_loss: 0.0108 - val_mean_squared_error: 0.0108\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.0010192291415436205\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0244 - mean_squared_error: 0.0244 - val_loss: 0.0109 - val_mean_squared_error: 0.0109\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.0014678858064659517\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0234 - mean_squared_error: 0.0234 - val_loss: 0.0104 - val_mean_squared_error: 0.0104\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.005119470631538947\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0232 - mean_squared_error: 0.0232 - val_loss: 0.0106 - val_mean_squared_error: 0.0106\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.006508934124371812\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0229 - mean_squared_error: 0.0229 - val_loss: 0.0107 - val_mean_squared_error: 0.0107\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.01657959563496092\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0227 - mean_squared_error: 0.0227 - val_loss: 0.0115 - val_mean_squared_error: 0.0115\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.017033555257379263\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0226 - mean_squared_error: 0.0226 - val_loss: 0.0107 - val_mean_squared_error: 0.0107\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.009921144054781172\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0223 - mean_squared_error: 0.0223 - val_loss: 0.0107 - val_mean_squared_error: 0.0107\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.009306874989724379\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0221 - mean_squared_error: 0.0221 - val_loss: 0.0118 - val_mean_squared_error: 0.0118\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.008494722328474036\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.007600209809588421\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0220 - mean_squared_error: 0.0220 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.005516567533825678\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0219 - mean_squared_error: 0.0219 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.003124568122131688\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0217 - mean_squared_error: 0.0217 - val_loss: 0.0114 - val_mean_squared_error: 0.0114\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.003994564880566154\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0215 - mean_squared_error: 0.0215 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.006147191549836228\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.0113 - val_mean_squared_error: 0.0113\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.007579157657622293\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0213 - mean_squared_error: 0.0213 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.0075439727547619295\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0214 - mean_squared_error: 0.0214 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.004549600713606439\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.0106 - val_mean_squared_error: 0.0106\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.006152034792984096\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0211 - mean_squared_error: 0.0211 - val_loss: 0.0112 - val_mean_squared_error: 0.0112\n",
      "92 of 1095 weights retained\n",
      "change in log loss: -0.0050175124129162585\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0209 - mean_squared_error: 0.0209 - val_loss: 0.0111 - val_mean_squared_error: 0.0111\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-148-45a2805519bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m                             verbose = 2, batch_size=2**14, epochs = 1)\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 27\u001b[1;33m         \u001b[0msaveWeightImages\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     28\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     29\u001b[0m         \u001b[0mctr\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-136-36eea1388611>\u001b[0m in \u001b[0;36msaveWeightImages\u001b[1;34m(model, ctr)\u001b[0m\n\u001b[0;32m     71\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m     \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigDir\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtmpFolder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mctr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mmodelName\u001b[0m  \u001b[1;33m+\u001b[0m \u001b[1;34m\".png\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m120\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox_inches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'tight'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpad_inches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\pyplot.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    699\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    700\u001b[0m     \u001b[0mfig\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgcf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 701\u001b[1;33m     \u001b[0mres\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    702\u001b[0m     \u001b[0mfig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_idle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m   \u001b[1;31m# need this if 'transparent=True' to reset colors\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mres\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36msavefig\u001b[1;34m(self, fname, **kwargs)\u001b[0m\n\u001b[0;32m   1832\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_frameon\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mframeon\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1833\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1834\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_figure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1835\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1836\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mframeon\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\backend_bases.py\u001b[0m in \u001b[0;36mprint_figure\u001b[1;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, **kwargs)\u001b[0m\n\u001b[0;32m   2214\u001b[0m                     \u001b[0morientation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morientation\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2215\u001b[0m                     \u001b[0mdryrun\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2216\u001b[1;33m                     **kwargs)\n\u001b[0m\u001b[0;32m   2217\u001b[0m                 \u001b[0mrenderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cachedRenderer\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2218\u001b[0m                 \u001b[0mbbox_inches\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tightbbox\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mprint_png\u001b[1;34m(self, filename_or_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    506\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mprint_png\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilename_or_obj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 507\u001b[1;33m         \u001b[0mFigureCanvasAgg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    508\u001b[0m         \u001b[0mrenderer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_renderer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m         \u001b[0moriginal_dpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdpi\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\backends\\backend_agg.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    428\u001b[0m             \u001b[1;31m# if toolbar:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    429\u001b[0m             \u001b[1;31m#     toolbar.set_cursor(cursors.WAIT)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 430\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    431\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    432\u001b[0m             \u001b[1;31m# if toolbar:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\figure.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer)\u001b[0m\n\u001b[0;32m   1297\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1298\u001b[0m             mimage._draw_list_compositing_images(\n\u001b[1;32m-> 1299\u001b[1;33m                 renderer, self, artists, self.suppressComposite)\n\u001b[0m\u001b[0;32m   1300\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1301\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'figure'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\axes\\_base.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, inframe)\u001b[0m\n\u001b[0;32m   2435\u001b[0m             \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_rasterizing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2436\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2437\u001b[1;33m         \u001b[0mmimage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_draw_list_compositing_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2438\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2439\u001b[0m         \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclose_group\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'axes'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_draw_list_compositing_images\u001b[1;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnot_composite\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mhas_images\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    137\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0ma\u001b[0m \u001b[1;32min\u001b[0m \u001b[0martists\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 138\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    139\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m         \u001b[1;31m# Composite any adjacent images together\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\artist.py\u001b[0m in \u001b[0;36mdraw_wrapper\u001b[1;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m     53\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstart_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mdraw\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0martist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0martist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_agg_filter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mdraw\u001b[1;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[0;32m    564\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    565\u001b[0m             im, l, b, trans = self.make_image(\n\u001b[1;32m--> 566\u001b[1;33m                 renderer, renderer.get_image_magnification())\n\u001b[0m\u001b[0;32m    567\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    568\u001b[0m                 \u001b[0mrenderer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdraw_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0ml\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36mmake_image\u001b[1;34m(self, renderer, magnification, unsampled)\u001b[0m\n\u001b[0;32m    791\u001b[0m         return self._make_image(\n\u001b[0;32m    792\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_A\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtransformed_bbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maxes\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbbox\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmagnification\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 793\u001b[1;33m             unsampled=unsampled)\n\u001b[0m\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_unsampled_image\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrenderer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\matplotlib\\image.py\u001b[0m in \u001b[0;36m_make_image\u001b[1;34m(self, A, in_bbox, out_bbox, clip_bbox, magnification, unsampled, round_to_pixel_border)\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[0mA_scaled\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m0.1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    403\u001b[0m                 A_resampled = np.zeros((out_height, out_width),\n\u001b[1;32m--> 404\u001b[1;33m                                        dtype=A_scaled.dtype)\n\u001b[0m\u001b[0;32m    405\u001b[0m                 \u001b[1;31m# resample the input data to the correct resolution and shape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m                 _image.resample(A_scaled, A_resampled,\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x175d3ddf7f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def prune_percent_updater(x):\n",
    "    logit = np.exp(x*8) / (np.exp(x*8) + 1)\n",
    "    return((logit - 0.5)*2*50)\n",
    "\n",
    "\n",
    "# cuts a smaller portion as the percent gets closer to 100%\n",
    "cutPercent = prune_percent_updater(np.linspace(0, 1, 26))\n",
    "numCuts = 0\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "while True:   \n",
    "    \n",
    "\n",
    "    \n",
    "    for numEpocs in range(100):\n",
    "        \n",
    "        MSE_tmp = []\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1)\n",
    "        \n",
    "        saveWeightImages(model, ctr)\n",
    "    \n",
    "        ctr += 1\n",
    "        \n",
    "      \n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "\n",
    "        #  save model\n",
    "        model.save(os.path.join(figDir, tmpFolder,  modelName + '_Pruned.h5'))\n",
    "\n",
    "        # save weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        wtsFile = str(ctr).zfill(4) + modelName + '_wts.pkl'\n",
    "        pickle.dump(wts, open(os.path.join(figDir, tmpFolder, wtsFile), 'wb'))\n",
    "\n",
    "        # save history\n",
    "        histName = modelName + 'pruned_history.pkl'\n",
    "        pickle.dump(historyDict, open(os.path.join(figDir,tmpFolder, histName), 'wb'))\n",
    "\n",
    "        \n",
    "        # local MSE\n",
    "        MSE_tmp.append(history.history[\"mean_squared_error\"][0])\n",
    "\n",
    "        # set weights close to 0 to 0 \n",
    "        for ii in np.arange(0, len(wts), 1):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent[numCuts], 50 + cutPercent[numCuts]), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        \n",
    "        # check the change in mean squared error, and if it's not changing much, then cut out more data\n",
    "        # calculate slope of loss, based on previous 5 data points\n",
    "        if numEpocs > 10:\n",
    "            inputData = historyDict[\"mean_squared_error\"][-5:]\n",
    "\n",
    "            m = np.shape(inputData)\n",
    "            X = np.matrix([np.ones(m), np.arange(0, len(inputData))]).T\n",
    "            y = np.matrix(np.log(inputData)).T\n",
    "\n",
    "            # Solve for projection matrix\n",
    "            intercept, slope = np.array(np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)).reshape(-1,)\n",
    "            print(\"change in log loss:\", slope)\n",
    "    \n",
    "            # break if slope has stopped changing or if the overall min has been surpassed\n",
    "            # in the first training, it will automatically prune after 5 epochs, because the min will be passed\n",
    "            if (np.abs(slope) < 0.0001) or (history.history[\"mean_squared_error\"][0] < np.min(historyDict[\"mean_squared_error\"][:-1])): \n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                model.save(os.path.join(figDir,  modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'))\n",
    "                break\n",
    "               \n",
    "    numCuts += 1\n",
    "    if numCuts >= len(cutPercent):\n",
    "        break\n",
    "\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1825"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ctr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x175f66b9208>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PRGn = cm.get_cmap('PRGn', 256)\n",
    "newcolors = PRGn(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2-3:256//2 + 4, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "# set weights close to 0 to 0 \n",
    "for ii in np.arange(0, len(wts), 1):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent[numCuts], 50 + cutPercent[numCuts]), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "model.set_weights(wts)\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "saveWeightImages(model, ctr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# make into video\n",
    "os.chdir(os.path.join(figDir, tmpFolder))\n",
    "\n",
    "os.system('ffmpeg -start_number 0 -r 60 -i %04d_Opt_rmsprop__Dro_0__Num_20_20_16__Wei_0_2019_06_03__14_47_14.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y 0000000_WeightUpdates.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n",
      "100\n",
      "101\n",
      "102\n",
      "103\n",
      "104\n",
      "105\n",
      "106\n",
      "107\n",
      "108\n",
      "109\n",
      "110\n",
      "111\n",
      "112\n",
      "113\n",
      "114\n",
      "115\n",
      "116\n",
      "117\n",
      "118\n",
      "119\n",
      "120\n",
      "121\n",
      "122\n",
      "123\n",
      "124\n",
      "125\n",
      "126\n",
      "127\n",
      "128\n",
      "129\n",
      "130\n",
      "131\n",
      "132\n",
      "133\n",
      "134\n",
      "135\n",
      "136\n",
      "137\n",
      "138\n",
      "139\n",
      "140\n",
      "141\n",
      "142\n",
      "143\n",
      "144\n",
      "145\n",
      "146\n",
      "147\n",
      "148\n",
      "149\n",
      "150\n",
      "151\n",
      "152\n",
      "153\n",
      "154\n",
      "155\n",
      "156\n",
      "157\n",
      "158\n",
      "159\n",
      "160\n",
      "161\n",
      "162\n",
      "163\n",
      "164\n",
      "165\n",
      "166\n",
      "167\n",
      "168\n",
      "169\n",
      "170\n",
      "171\n",
      "172\n",
      "173\n",
      "174\n",
      "175\n",
      "176\n",
      "177\n",
      "178\n",
      "179\n",
      "180\n",
      "181\n",
      "182\n",
      "183\n",
      "184\n",
      "185\n",
      "186\n",
      "187\n",
      "188\n",
      "189\n",
      "190\n",
      "191\n",
      "192\n",
      "193\n",
      "194\n",
      "195\n",
      "196\n",
      "197\n",
      "198\n",
      "199\n",
      "200\n",
      "201\n",
      "202\n",
      "203\n",
      "204\n",
      "205\n",
      "206\n",
      "207\n",
      "208\n",
      "209\n",
      "210\n",
      "211\n",
      "212\n",
      "213\n",
      "214\n",
      "215\n",
      "216\n",
      "217\n",
      "218\n",
      "219\n",
      "220\n",
      "221\n",
      "222\n",
      "223\n",
      "224\n",
      "225\n",
      "226\n",
      "227\n",
      "228\n",
      "229\n",
      "230\n",
      "231\n",
      "232\n",
      "233\n",
      "234\n",
      "235\n",
      "236\n",
      "237\n",
      "238\n",
      "239\n",
      "240\n",
      "241\n",
      "242\n",
      "243\n",
      "244\n",
      "245\n",
      "246\n",
      "247\n",
      "248\n",
      "249\n",
      "250\n",
      "251\n",
      "252\n",
      "253\n",
      "254\n",
      "255\n",
      "256\n",
      "257\n",
      "258\n",
      "259\n",
      "260\n",
      "261\n",
      "262\n",
      "263\n",
      "264\n",
      "265\n",
      "266\n",
      "267\n",
      "268\n",
      "269\n",
      "270\n",
      "271\n",
      "272\n",
      "273\n",
      "274\n",
      "275\n",
      "276\n",
      "277\n",
      "278\n",
      "279\n",
      "280\n",
      "281\n",
      "282\n",
      "283\n",
      "284\n",
      "285\n",
      "286\n",
      "287\n",
      "288\n",
      "289\n",
      "290\n",
      "291\n",
      "292\n",
      "293\n",
      "294\n",
      "295\n",
      "296\n",
      "297\n",
      "298\n",
      "299\n",
      "300\n",
      "301\n",
      "302\n",
      "303\n",
      "304\n",
      "305\n",
      "306\n",
      "307\n",
      "308\n",
      "309\n",
      "310\n",
      "311\n",
      "312\n",
      "313\n",
      "314\n",
      "315\n",
      "316\n",
      "317\n",
      "318\n",
      "319\n",
      "320\n",
      "321\n",
      "322\n",
      "323\n",
      "324\n",
      "325\n",
      "326\n",
      "327\n",
      "328\n",
      "329\n",
      "330\n",
      "331\n",
      "332\n",
      "333\n",
      "334\n",
      "335\n",
      "336\n",
      "337\n",
      "338\n",
      "339\n",
      "340\n",
      "341\n",
      "342\n",
      "343\n",
      "344\n",
      "345\n",
      "346\n",
      "347\n",
      "348\n",
      "349\n",
      "350\n",
      "351\n",
      "352\n",
      "353\n",
      "354\n",
      "355\n",
      "356\n",
      "357\n",
      "358\n",
      "359\n",
      "360\n",
      "361\n",
      "362\n",
      "363\n",
      "364\n",
      "365\n",
      "366\n",
      "367\n",
      "368\n",
      "369\n",
      "370\n",
      "371\n",
      "372\n",
      "373\n",
      "374\n",
      "375\n",
      "376\n",
      "377\n",
      "378\n",
      "379\n",
      "380\n",
      "381\n",
      "382\n",
      "383\n",
      "384\n",
      "385\n",
      "386\n",
      "387\n",
      "388\n",
      "389\n",
      "390\n",
      "391\n",
      "392\n",
      "393\n",
      "394\n",
      "395\n",
      "396\n",
      "397\n",
      "398\n",
      "399\n",
      "400\n",
      "401\n",
      "402\n",
      "403\n",
      "404\n",
      "405\n",
      "406\n",
      "407\n",
      "408\n",
      "409\n",
      "410\n",
      "411\n",
      "412\n",
      "413\n",
      "414\n",
      "415\n",
      "416\n",
      "417\n",
      "418\n",
      "419\n",
      "420\n",
      "421\n",
      "422\n",
      "423\n",
      "424\n",
      "425\n",
      "426\n",
      "427\n",
      "428\n",
      "429\n",
      "430\n",
      "431\n",
      "432\n",
      "433\n",
      "434\n",
      "435\n",
      "436\n",
      "437\n",
      "438\n",
      "439\n",
      "440\n",
      "441\n",
      "442\n",
      "443\n",
      "444\n",
      "445\n",
      "446\n",
      "447\n",
      "448\n",
      "449\n",
      "450\n",
      "451\n",
      "452\n",
      "453\n",
      "454\n",
      "455\n",
      "456\n",
      "457\n",
      "458\n",
      "459\n",
      "460\n",
      "461\n",
      "462\n",
      "463\n",
      "464\n",
      "465\n",
      "466\n",
      "467\n",
      "468\n",
      "469\n",
      "470\n",
      "471\n",
      "472\n",
      "473\n",
      "474\n",
      "475\n",
      "476\n",
      "477\n",
      "478\n",
      "479\n",
      "480\n",
      "481\n",
      "482\n",
      "483\n",
      "484\n",
      "485\n",
      "486\n",
      "487\n",
      "488\n",
      "489\n",
      "490\n",
      "491\n",
      "492\n",
      "493\n",
      "494\n",
      "495\n",
      "496\n",
      "497\n",
      "498\n",
      "499\n",
      "500\n",
      "501\n",
      "502\n",
      "503\n",
      "504\n",
      "505\n",
      "506\n",
      "507\n",
      "508\n",
      "509\n",
      "510\n",
      "511\n",
      "512\n",
      "513\n",
      "514\n",
      "515\n",
      "516\n",
      "517\n",
      "518\n",
      "519\n",
      "520\n",
      "521\n",
      "522\n",
      "523\n",
      "524\n",
      "525\n",
      "526\n",
      "527\n",
      "528\n",
      "529\n",
      "530\n",
      "531\n",
      "532\n",
      "533\n",
      "534\n",
      "535\n",
      "536\n",
      "537\n",
      "538\n",
      "539\n",
      "540\n",
      "541\n",
      "542\n",
      "543\n",
      "544\n",
      "545\n",
      "546\n",
      "547\n",
      "548\n",
      "549\n",
      "550\n",
      "551\n",
      "552\n",
      "553\n",
      "554\n",
      "555\n",
      "556\n",
      "557\n",
      "558\n",
      "559\n",
      "560\n",
      "561\n",
      "562\n",
      "563\n",
      "564\n",
      "565\n",
      "566\n",
      "567\n",
      "568\n",
      "569\n",
      "570\n",
      "571\n",
      "572\n",
      "573\n",
      "574\n",
      "575\n",
      "576\n",
      "577\n",
      "578\n",
      "579\n",
      "580\n",
      "581\n",
      "582\n",
      "583\n",
      "584\n",
      "585\n",
      "586\n",
      "587\n",
      "588\n",
      "589\n",
      "590\n",
      "591\n",
      "592\n",
      "593\n",
      "594\n",
      "595\n",
      "596\n",
      "597\n",
      "598\n",
      "599\n",
      "600\n",
      "601\n",
      "602\n",
      "603\n",
      "604\n",
      "605\n",
      "606\n",
      "607\n",
      "608\n",
      "609\n",
      "610\n",
      "611\n",
      "612\n",
      "613\n",
      "614\n",
      "615\n",
      "616\n",
      "617\n",
      "618\n",
      "619\n",
      "620\n",
      "621\n",
      "622\n",
      "623\n",
      "624\n",
      "625\n",
      "626\n",
      "627\n",
      "628\n",
      "629\n",
      "630\n",
      "631\n",
      "632\n",
      "633\n",
      "634\n",
      "635\n",
      "636\n",
      "637\n",
      "638\n",
      "639\n",
      "640\n",
      "641\n",
      "642\n",
      "643\n",
      "644\n",
      "645\n",
      "646\n",
      "647\n",
      "648\n",
      "649\n",
      "650\n",
      "651\n",
      "652\n",
      "653\n",
      "654\n",
      "655\n",
      "656\n",
      "657\n",
      "658\n",
      "659\n",
      "660\n",
      "661\n",
      "662\n",
      "663\n",
      "664\n",
      "665\n",
      "666\n",
      "667\n",
      "668\n",
      "669\n",
      "670\n",
      "671\n",
      "672\n",
      "673\n",
      "674\n",
      "675\n",
      "676\n",
      "677\n",
      "678\n",
      "679\n",
      "680\n",
      "681\n",
      "682\n",
      "683\n",
      "684\n",
      "685\n",
      "686\n",
      "687\n",
      "688\n",
      "689\n",
      "690\n",
      "691\n",
      "692\n",
      "693\n",
      "694\n",
      "695\n",
      "696\n",
      "697\n",
      "698\n",
      "699\n",
      "700\n",
      "701\n",
      "702\n",
      "703\n",
      "704\n",
      "705\n",
      "706\n",
      "707\n",
      "708\n",
      "709\n",
      "710\n",
      "711\n",
      "712\n",
      "713\n",
      "714\n",
      "715\n",
      "716\n",
      "717\n",
      "718\n",
      "719\n",
      "720\n",
      "721\n",
      "722\n",
      "723\n",
      "724\n",
      "725\n",
      "726\n",
      "727\n",
      "728\n",
      "729\n",
      "730\n",
      "731\n",
      "732\n",
      "733\n",
      "734\n",
      "735\n",
      "736\n",
      "737\n",
      "738\n",
      "739\n",
      "740\n",
      "741\n",
      "742\n",
      "743\n",
      "744\n",
      "745\n",
      "746\n",
      "747\n",
      "748\n",
      "749\n",
      "750\n",
      "751\n",
      "752\n",
      "753\n",
      "754\n",
      "755\n",
      "756\n",
      "757\n",
      "758\n",
      "759\n",
      "760\n",
      "761\n",
      "762\n",
      "763\n",
      "764\n",
      "765\n",
      "766\n",
      "767\n",
      "768\n",
      "769\n",
      "770\n",
      "771\n",
      "772\n",
      "773\n",
      "774\n",
      "775\n",
      "776\n",
      "777\n",
      "778\n",
      "779\n",
      "780\n",
      "781\n",
      "782\n",
      "783\n",
      "784\n",
      "785\n",
      "786\n",
      "787\n",
      "788\n",
      "789\n",
      "790\n",
      "791\n",
      "792\n",
      "793\n",
      "794\n",
      "795\n",
      "796\n",
      "797\n",
      "798\n",
      "799\n",
      "800\n",
      "801\n",
      "802\n",
      "803\n",
      "804\n",
      "805\n",
      "806\n",
      "807\n",
      "808\n",
      "809\n",
      "810\n",
      "811\n",
      "812\n",
      "813\n",
      "814\n",
      "815\n",
      "816\n",
      "817\n",
      "818\n",
      "819\n",
      "820\n",
      "821\n",
      "822\n",
      "823\n",
      "824\n",
      "825\n",
      "826\n",
      "827\n",
      "828\n",
      "829\n",
      "830\n",
      "831\n",
      "832\n",
      "833\n",
      "834\n",
      "835\n",
      "836\n",
      "837\n",
      "838\n",
      "839\n",
      "840\n",
      "841\n",
      "842\n",
      "843\n",
      "844\n",
      "845\n",
      "846\n",
      "847\n",
      "848\n",
      "849\n",
      "850\n",
      "851\n",
      "852\n",
      "853\n",
      "854\n",
      "855\n",
      "856\n",
      "857\n",
      "858\n",
      "859\n",
      "860\n",
      "861\n",
      "862\n",
      "863\n",
      "864\n",
      "865\n",
      "866\n",
      "867\n",
      "868\n",
      "869\n",
      "870\n",
      "871\n",
      "872\n",
      "873\n",
      "874\n",
      "875\n",
      "876\n",
      "877\n",
      "878\n",
      "879\n",
      "880\n",
      "881\n",
      "882\n",
      "883\n",
      "884\n",
      "885\n",
      "886\n",
      "887\n",
      "888\n",
      "889\n",
      "890\n",
      "891\n",
      "892\n",
      "893\n",
      "894\n",
      "895\n",
      "896\n",
      "897\n",
      "898\n",
      "899\n",
      "900\n",
      "901\n",
      "902\n",
      "903\n",
      "904\n",
      "905\n",
      "906\n",
      "907\n",
      "908\n",
      "909\n",
      "910\n",
      "911\n",
      "912\n",
      "913\n",
      "914\n",
      "915\n",
      "916\n",
      "917\n",
      "918\n",
      "919\n",
      "920\n",
      "921\n",
      "922\n",
      "923\n",
      "924\n",
      "925\n",
      "926\n",
      "927\n",
      "928\n",
      "929\n",
      "930\n",
      "931\n",
      "932\n",
      "933\n",
      "934\n",
      "935\n",
      "936\n",
      "937\n",
      "938\n",
      "939\n",
      "940\n",
      "941\n",
      "942\n",
      "943\n",
      "944\n",
      "945\n",
      "946\n",
      "947\n",
      "948\n",
      "949\n",
      "950\n",
      "951\n",
      "952\n",
      "953\n",
      "954\n",
      "955\n",
      "956\n",
      "957\n",
      "958\n",
      "959\n",
      "960\n",
      "961\n",
      "962\n",
      "963\n",
      "964\n",
      "965\n",
      "966\n",
      "967\n",
      "968\n",
      "969\n",
      "970\n",
      "971\n",
      "972\n",
      "973\n",
      "974\n",
      "975\n",
      "976\n",
      "977\n",
      "978\n",
      "979\n",
      "980\n",
      "981\n",
      "982\n",
      "983\n",
      "984\n",
      "985\n",
      "986\n",
      "987\n",
      "988\n",
      "989\n",
      "990\n",
      "991\n",
      "992\n",
      "993\n",
      "994\n",
      "995\n",
      "996\n",
      "997\n",
      "998\n",
      "999\n",
      "1000\n",
      "1001\n",
      "1002\n",
      "1003\n",
      "1004\n",
      "1005\n",
      "1006\n",
      "1007\n",
      "1008\n",
      "1009\n",
      "1010\n",
      "1011\n",
      "1012\n",
      "1013\n",
      "1014\n",
      "1015\n",
      "1016\n",
      "1017\n",
      "1018\n",
      "1019\n",
      "1020\n",
      "1021\n",
      "1022\n",
      "1023\n",
      "1024\n",
      "1025\n",
      "1026\n",
      "1027\n",
      "1028\n",
      "1029\n",
      "1030\n",
      "1031\n",
      "1032\n",
      "1033\n",
      "1034\n",
      "1035\n",
      "1036\n",
      "1037\n",
      "1038\n",
      "1039\n",
      "1040\n",
      "1041\n",
      "1042\n",
      "1043\n",
      "1044\n",
      "1045\n",
      "1046\n",
      "1047\n",
      "1048\n",
      "1049\n",
      "1050\n",
      "1051\n",
      "1052\n",
      "1053\n",
      "1054\n",
      "1055\n",
      "1056\n",
      "1057\n",
      "1058\n",
      "1059\n",
      "1060\n",
      "1061\n",
      "1062\n",
      "1063\n",
      "1064\n",
      "1065\n",
      "1066\n",
      "1067\n",
      "1068\n",
      "1069\n",
      "1070\n",
      "1071\n",
      "1072\n",
      "1073\n",
      "1074\n",
      "1075\n",
      "1076\n",
      "1077\n",
      "1078\n",
      "1079\n",
      "1080\n",
      "1081\n",
      "1082\n",
      "1083\n",
      "1084\n",
      "1085\n",
      "1086\n",
      "1087\n",
      "1088\n",
      "1089\n",
      "1090\n",
      "1091\n",
      "1092\n",
      "1093\n",
      "1094\n",
      "1095\n",
      "1096\n",
      "1097\n",
      "1098\n",
      "1099\n",
      "1100\n",
      "1101\n",
      "1102\n",
      "1103\n",
      "1104\n",
      "1105\n",
      "1106\n",
      "1107\n",
      "1108\n",
      "1109\n",
      "1110\n",
      "1111\n",
      "1112\n",
      "1113\n",
      "1114\n",
      "1115\n",
      "1116\n",
      "1117\n",
      "1118\n",
      "1119\n",
      "1120\n",
      "1121\n",
      "1122\n",
      "1123\n",
      "1124\n",
      "1125\n",
      "1126\n",
      "1127\n",
      "1128\n",
      "1129\n",
      "1130\n",
      "1131\n",
      "1132\n",
      "1133\n",
      "1134\n",
      "1135\n",
      "1136\n",
      "1137\n",
      "1138\n",
      "1139\n",
      "1140\n",
      "1141\n",
      "1142\n",
      "1143\n",
      "1144\n",
      "1145\n",
      "1146\n",
      "1147\n",
      "1148\n",
      "1149\n",
      "1150\n",
      "1151\n",
      "1152\n",
      "1153\n",
      "1154\n",
      "1155\n",
      "1156\n",
      "1157\n",
      "1158\n",
      "1159\n",
      "1160\n",
      "1161\n",
      "1162\n",
      "1163\n",
      "1164\n",
      "1165\n",
      "1166\n",
      "1167\n",
      "1168\n",
      "1169\n",
      "1170\n",
      "1171\n",
      "1172\n",
      "1173\n",
      "1174\n",
      "1175\n",
      "1176\n",
      "1177\n",
      "1178\n",
      "1179\n",
      "1180\n",
      "1181\n",
      "1182\n",
      "1183\n",
      "1184\n",
      "1185\n",
      "1186\n",
      "1187\n",
      "1188\n",
      "1189\n",
      "1190\n",
      "1191\n",
      "1192\n",
      "1193\n",
      "1194\n",
      "1195\n",
      "1196\n",
      "1197\n",
      "1198\n",
      "1199\n",
      "1200\n",
      "1201\n",
      "1202\n",
      "1203\n",
      "1204\n",
      "1205\n",
      "1206\n",
      "1207\n",
      "1208\n",
      "1209\n",
      "1210\n",
      "1211\n",
      "1212\n",
      "1213\n",
      "1214\n",
      "1215\n",
      "1216\n",
      "1217\n",
      "1218\n",
      "1219\n",
      "1220\n",
      "1221\n",
      "1222\n",
      "1223\n",
      "1224\n",
      "1225\n",
      "1226\n",
      "1227\n",
      "1228\n",
      "1229\n",
      "1230\n",
      "1231\n",
      "1232\n",
      "1233\n",
      "1234\n",
      "1235\n",
      "1236\n",
      "1237\n",
      "1238\n",
      "1239\n",
      "1240\n",
      "1241\n",
      "1242\n",
      "1243\n",
      "1244\n",
      "1245\n",
      "1246\n",
      "1247\n",
      "1248\n",
      "1249\n",
      "1250\n",
      "1251\n",
      "1252\n",
      "1253\n",
      "1254\n",
      "1255\n",
      "1256\n",
      "1257\n",
      "1258\n",
      "1259\n",
      "1260\n",
      "1261\n",
      "1262\n",
      "1263\n",
      "1264\n",
      "1265\n",
      "1266\n",
      "1267\n",
      "1268\n",
      "1269\n",
      "1270\n",
      "1271\n",
      "1272\n",
      "1273\n",
      "1274\n",
      "1275\n",
      "1276\n",
      "1277\n",
      "1278\n",
      "1279\n",
      "1280\n",
      "1281\n",
      "1282\n",
      "1283\n",
      "1284\n",
      "1285\n",
      "1286\n",
      "1287\n",
      "1288\n",
      "1289\n",
      "1290\n",
      "1291\n",
      "1292\n",
      "1293\n",
      "1294\n",
      "1295\n",
      "1296\n",
      "1297\n",
      "1298\n",
      "1299\n",
      "1300\n",
      "1301\n",
      "1302\n",
      "1303\n",
      "1304\n",
      "1305\n",
      "1306\n",
      "1307\n",
      "1308\n",
      "1309\n",
      "1310\n",
      "1311\n",
      "1312\n",
      "1313\n",
      "1314\n",
      "1315\n",
      "1316\n",
      "1317\n",
      "1318\n",
      "1319\n",
      "1320\n",
      "1321\n",
      "1322\n",
      "1323\n",
      "1324\n",
      "1325\n",
      "1326\n",
      "1327\n",
      "1328\n",
      "1329\n",
      "1330\n",
      "1331\n",
      "1332\n",
      "1333\n",
      "1334\n",
      "1335\n",
      "1336\n",
      "1337\n",
      "1338\n",
      "1339\n",
      "1340\n",
      "1341\n",
      "1342\n",
      "1343\n",
      "1344\n",
      "1345\n",
      "1346\n",
      "1347\n",
      "1348\n",
      "1349\n",
      "1350\n",
      "1351\n",
      "1352\n",
      "1353\n",
      "1354\n",
      "1355\n",
      "1356\n",
      "1357\n",
      "1358\n",
      "1359\n",
      "1360\n",
      "1361\n",
      "1362\n",
      "1363\n",
      "1364\n",
      "1365\n",
      "1366\n",
      "1367\n",
      "1368\n",
      "1369\n",
      "1370\n",
      "1371\n",
      "1372\n",
      "1373\n",
      "1374\n",
      "1375\n",
      "1376\n",
      "1377\n",
      "1378\n",
      "1379\n",
      "1380\n",
      "1381\n",
      "1382\n",
      "1383\n",
      "1384\n",
      "1385\n",
      "1386\n",
      "1387\n",
      "1388\n",
      "1389\n",
      "1390\n",
      "1391\n",
      "1392\n",
      "1393\n",
      "1394\n",
      "1395\n",
      "1396\n",
      "1397\n",
      "1398\n",
      "1399\n",
      "1400\n",
      "1401\n",
      "1402\n",
      "1403\n",
      "1404\n",
      "1405\n",
      "1406\n",
      "1407\n",
      "1408\n",
      "1409\n",
      "1410\n",
      "1411\n",
      "1412\n",
      "1413\n",
      "1414\n",
      "1415\n",
      "1416\n",
      "1417\n",
      "1418\n",
      "1419\n",
      "1420\n",
      "1421\n",
      "1422\n",
      "1423\n",
      "1424\n",
      "1425\n",
      "1426\n",
      "1427\n",
      "1428\n",
      "1429\n",
      "1430\n",
      "1431\n",
      "1432\n",
      "1433\n",
      "1434\n",
      "1435\n",
      "1436\n",
      "1437\n",
      "1438\n",
      "1439\n",
      "1440\n",
      "1441\n",
      "1442\n",
      "1443\n",
      "1444\n",
      "1445\n",
      "1446\n",
      "1447\n",
      "1448\n",
      "1449\n",
      "1450\n",
      "1451\n",
      "1452\n",
      "1453\n",
      "1454\n",
      "1455\n",
      "1456\n",
      "1457\n",
      "1458\n",
      "1459\n",
      "1460\n",
      "1461\n",
      "1462\n",
      "1463\n",
      "1464\n",
      "1465\n",
      "1466\n",
      "1467\n",
      "1468\n",
      "1469\n",
      "1470\n",
      "1471\n",
      "1472\n",
      "1473\n",
      "1474\n",
      "1475\n",
      "1476\n",
      "1477\n",
      "1478\n",
      "1479\n",
      "1480\n",
      "1481\n",
      "1482\n",
      "1483\n",
      "1484\n",
      "1485\n",
      "1486\n",
      "1487\n",
      "1488\n",
      "1489\n",
      "1490\n",
      "1491\n",
      "1492\n",
      "1493\n",
      "1494\n",
      "1495\n",
      "1496\n",
      "1497\n",
      "1498\n",
      "1499\n",
      "1500\n",
      "1501\n",
      "1502\n",
      "1503\n",
      "1504\n",
      "1505\n",
      "1506\n",
      "1507\n",
      "1508\n",
      "1509\n",
      "1510\n",
      "1511\n",
      "1512\n",
      "1513\n",
      "1514\n",
      "1515\n",
      "1516\n",
      "1517\n",
      "1518\n",
      "1519\n",
      "1520\n",
      "1521\n",
      "1522\n",
      "1523\n",
      "1524\n",
      "1525\n",
      "1526\n",
      "1527\n",
      "1528\n",
      "1529\n",
      "1530\n",
      "1531\n",
      "1532\n",
      "1533\n",
      "1534\n",
      "1535\n",
      "1536\n",
      "1537\n",
      "1538\n",
      "1539\n",
      "1540\n",
      "1541\n",
      "1542\n",
      "1543\n",
      "1544\n",
      "1545\n",
      "1546\n",
      "1547\n",
      "1548\n",
      "1549\n",
      "1550\n",
      "1551\n",
      "1552\n",
      "1553\n",
      "1554\n",
      "1555\n",
      "1556\n",
      "1557\n",
      "1558\n",
      "1559\n",
      "1560\n",
      "1561\n",
      "1562\n",
      "1563\n",
      "1564\n",
      "1565\n",
      "1566\n",
      "1567\n",
      "1568\n",
      "1569\n",
      "1570\n",
      "1571\n",
      "1572\n",
      "1573\n",
      "1574\n",
      "1575\n",
      "1576\n",
      "1577\n",
      "1578\n",
      "1579\n",
      "1580\n",
      "1581\n",
      "1582\n",
      "1583\n",
      "1584\n",
      "1585\n",
      "1586\n",
      "1587\n",
      "1588\n",
      "1589\n",
      "1590\n",
      "1591\n",
      "1592\n",
      "1593\n",
      "1594\n",
      "1595\n",
      "1596\n",
      "1597\n",
      "1598\n",
      "1599\n",
      "1600\n",
      "1601\n",
      "1602\n",
      "1603\n",
      "1604\n",
      "1605\n",
      "1606\n",
      "1607\n",
      "1608\n",
      "1609\n",
      "1610\n",
      "1611\n",
      "1612\n",
      "1613\n",
      "1614\n",
      "1615\n",
      "1616\n",
      "1617\n",
      "1618\n",
      "1619\n",
      "1620\n",
      "1621\n",
      "1622\n",
      "1623\n",
      "1624\n",
      "1625\n",
      "1626\n",
      "1627\n",
      "1628\n",
      "1629\n",
      "1630\n",
      "1631\n",
      "1632\n",
      "1633\n",
      "1634\n",
      "1635\n",
      "1636\n",
      "1637\n",
      "1638\n",
      "1639\n",
      "1640\n",
      "1641\n",
      "1642\n",
      "1643\n",
      "1644\n",
      "1645\n",
      "1646\n",
      "1647\n",
      "1648\n",
      "1649\n",
      "1650\n",
      "1651\n",
      "1652\n",
      "1653\n",
      "1654\n",
      "1655\n",
      "1656\n",
      "1657\n",
      "1658\n",
      "1659\n",
      "1660\n",
      "1661\n",
      "1662\n",
      "1663\n",
      "1664\n",
      "1665\n",
      "1666\n",
      "1667\n",
      "1668\n",
      "1669\n",
      "1670\n",
      "1671\n",
      "1672\n",
      "1673\n",
      "1674\n",
      "1675\n",
      "1676\n",
      "1677\n",
      "1678\n",
      "1679\n",
      "1680\n",
      "1681\n",
      "1682\n",
      "1683\n",
      "1684\n",
      "1685\n",
      "1686\n",
      "1687\n",
      "1688\n",
      "1689\n",
      "1690\n",
      "1691\n",
      "1692\n",
      "1693\n",
      "1694\n",
      "1695\n",
      "1696\n",
      "1697\n",
      "1698\n",
      "1699\n",
      "1700\n",
      "1701\n",
      "1702\n",
      "1703\n",
      "1704\n",
      "1705\n",
      "1706\n",
      "1707\n",
      "1708\n",
      "1709\n",
      "1710\n",
      "1711\n",
      "1712\n",
      "1713\n",
      "1714\n",
      "1715\n",
      "1716\n",
      "1717\n",
      "1718\n",
      "1719\n",
      "1720\n",
      "1721\n",
      "1722\n",
      "1723\n",
      "1724\n",
      "1725\n",
      "1726\n",
      "1727\n",
      "1728\n",
      "1729\n",
      "1730\n",
      "1731\n",
      "1732\n",
      "1733\n",
      "1734\n",
      "1735\n",
      "1736\n",
      "1737\n",
      "1738\n",
      "1739\n",
      "1740\n",
      "1741\n",
      "1742\n",
      "1743\n",
      "1744\n",
      "1745\n",
      "1746\n",
      "1747\n",
      "1748\n",
      "1749\n",
      "1750\n",
      "1751\n",
      "1752\n",
      "1753\n",
      "1754\n",
      "1755\n",
      "1756\n",
      "1757\n",
      "1758\n",
      "1759\n",
      "1760\n",
      "1761\n",
      "1762\n",
      "1763\n",
      "1764\n",
      "1765\n",
      "1766\n",
      "1767\n",
      "1768\n",
      "1769\n",
      "1770\n",
      "1771\n",
      "1772\n",
      "1773\n",
      "1774\n",
      "1775\n",
      "1776\n",
      "1777\n",
      "1778\n",
      "1779\n",
      "1780\n",
      "1781\n",
      "1782\n",
      "1783\n",
      "1784\n",
      "1785\n",
      "1786\n",
      "1787\n",
      "1788\n",
      "1789\n",
      "1790\n",
      "1791\n",
      "1792\n",
      "1793\n",
      "1794\n",
      "1795\n",
      "1796\n",
      "1797\n",
      "1798\n",
      "1799\n",
      "1800\n",
      "1801\n",
      "1802\n",
      "1803\n",
      "1804\n",
      "1805\n",
      "1806\n",
      "1807\n",
      "1808\n",
      "1809\n",
      "1810\n",
      "1811\n",
      "1812\n",
      "1813\n",
      "1814\n",
      "1815\n",
      "1816\n",
      "1817\n",
      "1818\n",
      "1819\n",
      "1820\n",
      "1821\n",
      "1822\n",
      "1823\n",
      "1824\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x175f8169a20>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# make history video\n",
    "\n",
    "\n",
    "tmpDir = os.path.join(figDir, tmpFolder)\n",
    "ctr2 = 0 \n",
    "\n",
    "fig, axs = plt.subplots(1,1,figsize=np.array([30, 10])/2)\n",
    "\n",
    "for dictLen in np.arange(0, len(historyDict[\"mean_squared_error\"])):\n",
    "    if dictLen > 0:    \n",
    "        axs.plot([dictLen -1, dictLen],\n",
    "                 historyDict['mean_squared_error'][dictLen-1:dictLen+1], c= \"C0\")\n",
    "        axs.plot([dictLen -1, dictLen],\n",
    "                 historyDict['val_mean_squared_error'][dictLen-1:dictLen+1], c= \"C1\")\n",
    "    else:    \n",
    "        axs.plot(0,\n",
    "                 historyDict['mean_squared_error'][0],marker='o', markersize=5, c= \"C0\")\n",
    "        axs.plot(0,\n",
    "                 historyDict['val_mean_squared_error'][0],marker='o',markersize=5, c= \"C1\")\n",
    "    axs.set_title('Model MSE = '+ str(format_e(historyDict['val_mean_squared_error'][dictLen])))\n",
    "    axs.set_ylabel('mean squared error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.legend(['train', 'val'], loc='lower left')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "\n",
    "    plt.ylim([0.0001, 0.05])\n",
    "#     fig.savefig(os.path.join(tmpDir, str(dictLen).zfill(4)+ \".png\"), dpi = 120,  pad_inches = 0.5)\n",
    "    #plt.close()\n",
    "    #plt.show()\n",
    "    \n",
    "#     if np.mod(dictLen, 3) == 0:\n",
    "    print(dictLen)\n",
    "    fig.savefig(os.path.join(tmpDir, str(ctr2).zfill(4)+ \".png\"), dpi = 120,  pad_inches = 0.5)\n",
    "    ctr2 += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make into video\n",
    "os.chdir(os.path.join(figDir, tmpFolder))\n",
    "\n",
    "os.system('ffmpeg -start_number 0 -r 60 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y 0000000_HistoryUpdates2.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# crop history video\n",
    "os.system('ffmpeg -i 0000000_HistoryUpdates2.mp4 -filter:v \"crop=iw-150:ih:130:0\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y 0000000_history_cropped.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale video\n",
    "os.system('ffmpeg -i 0000000_history_cropped.mp4 -filter:v scale=\"1400:trunc(ow/a/2)*2\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y  0000000_HistoryUpdates2_scaled.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# scale other video\n",
    "os.system('ffmpeg -i 0000000_WeightUpdates.mp4 -filter:v scale=\"1400:trunc(ow/a/2)*2\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y 0000000_WeightUpdates_scaled.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try ffmpeg vstacking images\n",
    "\n",
    "# make into video\n",
    "os.chdir(os.path.join(figDir, tmpFolder))\n",
    "os.system('ffmpeg -i 0000000_HistoryUpdates2_scaled.mp4 -i 0000000_WeightUpdates_scaled.mp4 -filter_complex vstack=inputs=2 -c:v libx264   -b:v 10000k -pix_fmt yuv420p  -y combinedTraining.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# downsample images\n",
    "os.system('ffmpeg -i combinedTraining.mp4  -filter:v \"fps=30, setpts=0.7*PTS\"  -c:v libx264   -b:v 10000k -pix_fmt yuv420p  -y combinedTraining_small.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# edit crazyflie vid\n",
    "os.chdir(r\"D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019\\crazieFlieVid\")\n",
    "\n",
    "\n",
    "# crop and remove audio and speed up, and trim to start at 19 sec\n",
    "os.system('ffmpeg -i Daniel-Smellicopter-FollowOdor_VideoByAlisonMehravari.MOV -ss 00:00:19 -filter:v \"fps=30, setpts=0.7*PTS, crop=iw:ih-800:0:200\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -an -y CrazyFly_cropped.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# edit crazyflie vid\n",
    "os.chdir(r\"D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019\\crazieFlieVid\")\n",
    "\n",
    "\n",
    "# crop and remove audio and speed up, and trim to start at 19 sec\n",
    "os.system('ffmpeg -i Daniel-Smellicopter-FollowOdor_VideoByAlisonMehravari.MOV -ss 00:00:19 -filter:v \"fps=30, setpts=0.7*PTS, crop=iw:ih-300:0:200\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -an -y CrazyFly_croppedTall.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save hq version of history\n",
    "\n",
    "hpth = r\"D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019\\Opt_rmsprop__Dro_0__Num_400_400_400_16__Wei_0_2019_05_30__19_19_39_history_pruned.pkl\"\n",
    "hist2 = pickle.load(open(hpth, \"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hist2[\"mean_squared_error\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x175f47fdd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1,1,figsize=np.array( [16.5, 7.7])/2)\n",
    "\n",
    "axs.plot(hist2[\"val_mean_squared_error\"], c= \"C1\")\n",
    "axs.plot(hist2[\"mean_squared_error\"], c= \"C0\")\n",
    "\n",
    "\n",
    "axs.set_ylabel('mean squared error')\n",
    "axs.set_xlabel('Epoch')\n",
    "axs.legend(['train', 'validation'], loc='lower left')\n",
    "plt.yscale('log') #logarithmic scale for y axis\n",
    "\n",
    "plt.ylim([0.0001, 0.05])\n",
    "fig.savefig(os.path.join(tmpDir, \"History400.png\"), dpi = 500,  pad_inches = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D:\\\\Dropbox\\\\AcademiaDropbox\\\\CallinStuff\\\\Presentations\\\\eScience_Community_Seminar_2019\\\\smallNetworkTraingingPruning'"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tmpDir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('viridis', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2 + 1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 21])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 7:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"PrunedWts_small\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how good can I get without trimming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot matrices\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "for ii in np.arange(0, len(wts), 2):\n",
    "    plt.matshow(wts[ii], cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot biases\n",
    "\n",
    "for ii in np.arange(1, len(wts), 2):\n",
    "    plt.matshow(wts[ii].reshape(1, -1), cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: save weights and model\n",
    "model.save(os.path.join(savedModels,  modelName + '_pruned_bias.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_pruned_wts_bias.pkl'\n",
    "pickle.dump(wts, open(os.path.join(dataOutput, wtsFile), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(1,5, figsize=(20, 5), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.2)\n",
    "\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 2)):\n",
    "    im = axs[jj].matshow(wts[ii], cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "    \n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"vertical\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(5,1, figsize=(30, 10), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "for jj, ii in enumerate(np.arange(1, len(wts), 2)):\n",
    "    im = axs[jj].matshow(wts[ii].reshape(1, -1), cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    axs[jj].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"horizontal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=(30, 10), facecolor='w', edgecolor='k', )\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.1)\n",
    "\n",
    "\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"horizontal\")\n",
    "plt.savefig(os.path.join(figDir, \"PrunedWeightMatrices.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(dataOutput, wtsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: if whole node is basically 0, then remove the node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(wts[2].reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_network(**modelParams)\n",
    "\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                        verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                        callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if model saved: \n",
    "K.clear_session()\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels, 'my_model_400Units_newData.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wts[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((20,3)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 100)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 100)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(Xtest_scaled, Ytest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (5, 95), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this is the original model\n",
    "inputs = Input(shape=(Xtrain_scaled.shape[1],))\n",
    "x = Dense(400, activation='tanh')(inputs)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(16, activation='tanh')(x)\n",
    "predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics = ['mse'])\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=50, \n",
    "                          verbose=1, mode='auto', min_delta = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "\n",
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (2, 98), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "model.set_weights(wts)\n",
    "\n",
    "\n",
    "# start training\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                    verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                    callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (2.5, 97.5), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "model.set_weights(wts)\n",
    "\n",
    "model.evaluate(Xtest_scaled, Ytest_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history.history['mean_squared_error'])+1),\n",
    "             model_history.history['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "             model_history.history['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE')\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "                   len(model_history.history['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    if saveFig:\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining.png\"), dpi = 120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "plot_model_history(history)\n",
    "print(history.history[\"loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model that was trained for much longer\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels, 'my_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "nzwts = [np.nonzero(wts[ii].reshape(-1))[0] for ii in range(len(wts))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((20,5)) , facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(nzwts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(nzwts[jj].shape))\n",
    "    axs[jj+1].hist(nzwts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(nzwts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((10,10)) , facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n",
    "#fig.savefig(os.path.join(figDir, \"SmallModelResids.png\"), dpi = 120, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim distribution of weights -- cut out middle 20%\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (40, 60), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show new histogram of weights (excluding the 0's)\n",
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array((15, 6)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    \n",
    "    d1 = wts[jj].reshape(-1)\n",
    "    axs[jj].hist(d1[d1!=0], bins = 30, facecolor = '#d6bddb' )\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "\n",
    "    d2 = wts[jj+1]\n",
    "    axs[jj+1].hist(d2[d2!=0], bins = 30, facecolor = '#d6bddb')\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the validation.split is the last X% of the data\n",
    "int(0.3*Xtrain_scaled.shape[0])\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict of hyperparameters\n",
    "\n",
    "\n",
    "# regularization, num layers, num nodes, learning rate, optimizer, activation function, batch size\n",
    "\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Create hyperparameter space\n",
    "NumHiddenLayers = randint(low = 2, high = 20)#[4, 2, 8]\n",
    "numUnits  = [2**4, 2**5, 2**6, 2**7, 2**8, 2**9, 2**10]\n",
    "epochs = [200]\n",
    "batches1 = [2**12, 2**10, 2**8, 2**14] \n",
    "optimizers = ['rmsprop', 'adam']\n",
    "dropout_rate =  uniform(loc = 0, scale = 0.5) #[0.0, 0.2, 0.5]\n",
    "weightRegularization = uniform(loc = 0, scale = 0.001) #[0, 0.0001, 0.001, 0.01]\n",
    "secondToLastUnits = [8, 16, 32, 64]\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(optimizer=optimizers, \n",
    "                        epochs=epochs, \n",
    "                        batch_size=batches1,\n",
    "                        dropout_rate = dropout_rate, \n",
    "                        numUnits = numUnits, \n",
    "                        NumHiddenLayers = NumHiddenLayers, \n",
    "                        weightRegularization = weightRegularization, \n",
    "                        secondToLastUnits = secondToLastUnits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: \n",
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "cutPercent = 49.7\n",
    "for numCuts in range(3):\n",
    "    for numEpocs in range(100):\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                            callbacks = [earlystop])\n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 2):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent, 50 + cutPercent), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
