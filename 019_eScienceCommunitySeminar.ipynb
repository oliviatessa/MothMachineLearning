{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Callin Switzer\n",
    "### 30 May 2019\n",
    "### eScience Community Seminar Prep"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Outline:\n",
    "\n",
    "- Train full network with 400 units\n",
    "- calculate error on test set\n",
    "    - create error plots\n",
    "** show how well moth can follow trajectory\n",
    "\n",
    "\n",
    "Pt2: \n",
    "Pruning: \n",
    "- train smaller network for demonstration (compare MSE to huge network)\n",
    "- prune smaller network for demonstration\n",
    "\n",
    "Prune larger network\n",
    "-show error on pruned network, compared to smaller network\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\calli\\Anaconda3\\envs\\deeplearning\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow successfully installed.\n",
      "The installed version of TensorFlow includes GPU support.\n",
      "3.6.4 |Anaconda custom (64-bit)| (default, Jan 16 2018, 10:22:32) [MSC v.1900 64 bit (AMD64)] \n",
      "\n",
      "last run on 2019-06-03 13:22:36.162287\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import matplotlib.colors as colors\n",
    "from  mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "from matplotlib import cm\n",
    "from matplotlib.colors import ListedColormap, LinearSegmentedColormap\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import time\n",
    "from datetime import datetime\n",
    "import sys\n",
    "import seaborn as sns\n",
    "import scipy.io\n",
    "import subprocess\n",
    "import winsound\n",
    "import pickle\n",
    "import glob\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "import tensorflow as tf\n",
    "print(\"TensorFlow successfully installed.\")\n",
    "if tf.test.is_built_with_cuda():\n",
    "    print(\"The installed version of TensorFlow includes GPU support.\")\n",
    "print(sys.version, \"\\n\")\n",
    "now = datetime.now()\n",
    "print(\"last run on \" + str(now))\n",
    "\n",
    "# define directories\n",
    "baseDir = os.getcwd()\n",
    "dataDir = r'D:\\MothSimulations\\11c-AggressiveManeuver\\Qstore\\hws_am_con'\n",
    "figDir = r'D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019'\n",
    "dataOutput = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\DataOutput'\n",
    "savedModels = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels'\n",
    "randomRawData = r'D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\PythonGeneratedData\\TrainingData'\n",
    "if not os.path.exists(dataOutput):\n",
    "    os.mkdir(dataOutput)\n",
    "if not os.path.exists(savedModels):\n",
    "    os.mkdir(savedModels)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# import\n",
    "from keras.layers import Input, Dense, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras import regularizers\n",
    "from keras.models import load_model\n",
    "\n",
    "# Keras callcacks\n",
    "from keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define some functions\n",
    "\n",
    "def format_e(n):\n",
    "    a = '%E' % n\n",
    "    return a.split('E')[0].rstrip('0').rstrip('.') + 'E' + a.split('E')[1]\n",
    "\n",
    "\n",
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        plt.ylim([0.000001, 0.05])\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned_2.png\"), dpi = 120, bbox_inches='tight')\n",
    "        print(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"))\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make training and test set"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# concatenate all files (only need to do this once)\n",
    "# it takes a few minutes\n",
    "all_files = glob.glob(os.path.join(randomRawData, \"*.csv\"))     \n",
    "df_from_each_file = (pd.read_csv(f) for f in all_files)\n",
    "concatenated_df   = pd.concat(df_from_each_file, ignore_index=True)\n",
    "\n",
    "# check for duplicates\n",
    "concatenated_df.drop_duplicates(inplace=True)\n",
    "concatenated_df.shape\n",
    "\n",
    "print(concatenated_df.shape)\n",
    "concatenated_df.tail()\n",
    "\n",
    "# save to hdf5\n",
    "concatenated_df.to_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "trainDF = pd.read_hdf(os.path.join(dataOutput, \"concatenatedRandomICs.h5\"), key = \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: check for repeats!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# double check for repeats!\n",
    "np.sum(trainDF.iloc[:, [16,17,18]].duplicated()) # 0 means no repeats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9900510, 19)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x0</th>\n",
       "      <th>xf</th>\n",
       "      <th>xd0</th>\n",
       "      <th>xdf</th>\n",
       "      <th>y0</th>\n",
       "      <th>yf</th>\n",
       "      <th>yd0</th>\n",
       "      <th>ydf</th>\n",
       "      <th>theta0</th>\n",
       "      <th>thetaf</th>\n",
       "      <th>thetad0</th>\n",
       "      <th>thetadf</th>\n",
       "      <th>phi0</th>\n",
       "      <th>phif</th>\n",
       "      <th>phid0</th>\n",
       "      <th>phidf</th>\n",
       "      <th>F</th>\n",
       "      <th>alpha</th>\n",
       "      <th>tau0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>23.367432</td>\n",
       "      <td>1240.975696</td>\n",
       "      <td>1047.460389</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.222497</td>\n",
       "      <td>-321.289498</td>\n",
       "      <td>-38.377027</td>\n",
       "      <td>4.539917</td>\n",
       "      <td>6.334514</td>\n",
       "      <td>5.761704</td>\n",
       "      <td>166.050842</td>\n",
       "      <td>2.909070</td>\n",
       "      <td>4.628560</td>\n",
       "      <td>10.607821</td>\n",
       "      <td>162.092739</td>\n",
       "      <td>29718.210402</td>\n",
       "      <td>3.057406</td>\n",
       "      <td>53852.149654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-20.768748</td>\n",
       "      <td>-1149.257088</td>\n",
       "      <td>-1075.409015</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.106142</td>\n",
       "      <td>365.093207</td>\n",
       "      <td>697.828947</td>\n",
       "      <td>3.243816</td>\n",
       "      <td>4.921125</td>\n",
       "      <td>16.957561</td>\n",
       "      <td>146.364185</td>\n",
       "      <td>3.308109</td>\n",
       "      <td>4.891662</td>\n",
       "      <td>22.615302</td>\n",
       "      <td>141.667777</td>\n",
       "      <td>28169.483755</td>\n",
       "      <td>3.504285</td>\n",
       "      <td>66579.923810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-25.280989</td>\n",
       "      <td>-1496.313673</td>\n",
       "      <td>-1133.713595</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.318522</td>\n",
       "      <td>244.869357</td>\n",
       "      <td>748.985152</td>\n",
       "      <td>5.436117</td>\n",
       "      <td>-0.270820</td>\n",
       "      <td>7.760703</td>\n",
       "      <td>-563.122968</td>\n",
       "      <td>5.548527</td>\n",
       "      <td>-0.137526</td>\n",
       "      <td>0.328348</td>\n",
       "      <td>-561.725041</td>\n",
       "      <td>42042.954099</td>\n",
       "      <td>1.460073</td>\n",
       "      <td>-13638.356558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.931729</td>\n",
       "      <td>-560.948725</td>\n",
       "      <td>-26.956023</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.748787</td>\n",
       "      <td>86.858301</td>\n",
       "      <td>45.961219</td>\n",
       "      <td>4.004344</td>\n",
       "      <td>4.826500</td>\n",
       "      <td>-0.067853</td>\n",
       "      <td>72.504068</td>\n",
       "      <td>0.510978</td>\n",
       "      <td>1.423037</td>\n",
       "      <td>24.197259</td>\n",
       "      <td>77.007517</td>\n",
       "      <td>32817.596791</td>\n",
       "      <td>1.943183</td>\n",
       "      <td>-59677.690610</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.280447</td>\n",
       "      <td>-214.455052</td>\n",
       "      <td>-539.671502</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.707153</td>\n",
       "      <td>225.808462</td>\n",
       "      <td>488.013492</td>\n",
       "      <td>6.129205</td>\n",
       "      <td>4.399997</td>\n",
       "      <td>-16.195650</td>\n",
       "      <td>-177.812751</td>\n",
       "      <td>1.609007</td>\n",
       "      <td>-0.231868</td>\n",
       "      <td>9.118306</td>\n",
       "      <td>-183.140660</td>\n",
       "      <td>35120.738164</td>\n",
       "      <td>3.267484</td>\n",
       "      <td>77836.665059</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    x0         xf          xd0          xdf   y0         yf         yd0  \\\n",
       "0  0.0  23.367432  1240.975696  1047.460389  0.0  -2.222497 -321.289498   \n",
       "1  0.0 -20.768748 -1149.257088 -1075.409015  0.0  11.106142  365.093207   \n",
       "2  0.0 -25.280989 -1496.313673 -1133.713595  0.0   4.318522  244.869357   \n",
       "3  0.0  -5.931729  -560.948725   -26.956023  0.0   0.748787   86.858301   \n",
       "4  0.0  -9.280447  -214.455052  -539.671502  0.0   6.707153  225.808462   \n",
       "\n",
       "          ydf    theta0    thetaf    thetad0     thetadf      phi0      phif  \\\n",
       "0  -38.377027  4.539917  6.334514   5.761704  166.050842  2.909070  4.628560   \n",
       "1  697.828947  3.243816  4.921125  16.957561  146.364185  3.308109  4.891662   \n",
       "2  748.985152  5.436117 -0.270820   7.760703 -563.122968  5.548527 -0.137526   \n",
       "3   45.961219  4.004344  4.826500  -0.067853   72.504068  0.510978  1.423037   \n",
       "4  488.013492  6.129205  4.399997 -16.195650 -177.812751  1.609007 -0.231868   \n",
       "\n",
       "       phid0       phidf             F     alpha          tau0  \n",
       "0  10.607821  162.092739  29718.210402  3.057406  53852.149654  \n",
       "1  22.615302  141.667777  28169.483755  3.504285  66579.923810  \n",
       "2   0.328348 -561.725041  42042.954099  1.460073 -13638.356558  \n",
       "3  24.197259   77.007517  32817.596791  1.943183 -59677.690610  \n",
       "4   9.118306 -183.140660  35120.738164  3.267484  77836.665059  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(trainDF.shape)\n",
    "trainDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to be consistent with other code\n",
    "trainDF.rename(columns={\"x0\" : \"x_0\", \"y0\" : \"y_0\", \"phi0\" : \"phi_0\", \"theta0\" : \"theta_0\", \n",
    "                        \"xf\" : \"x_99\", \"yf\" : \"y_99\", \"phif\" : \"phi_99\", \"thetaf\" : \"theta_99\", \n",
    "                        \"xd0\" : \"x_dot_0\", \"yd0\" : \"y_dot_0\", \"phid0\" : \"phi_dot_0\", \"thetad0\": \"theta_dot_0\", \n",
    "                        \"xdf\" : \"x_dot_99\", \"ydf\": \"y_dot_99\", \"phidf\": \"phi_dot_99\", \"thetadf\": \"theta_dot_99\", \n",
    "                        \"tau0\" : \"tau\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert to fx and fy\n",
    "trainDF[\"Fx\"] = trainDF.F * np.cos(trainDF.alpha)\n",
    "trainDF[\"Fy\"] = trainDF.F * np.sin(trainDF.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phi_0</th>\n",
       "      <th>theta_0</th>\n",
       "      <th>x_99</th>\n",
       "      <th>y_99</th>\n",
       "      <th>phi_99</th>\n",
       "      <th>theta_99</th>\n",
       "      <th>x_dot_0</th>\n",
       "      <th>y_dot_0</th>\n",
       "      <th>phi_dot_0</th>\n",
       "      <th>theta_dot_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.909070</td>\n",
       "      <td>4.539917</td>\n",
       "      <td>23.367432</td>\n",
       "      <td>-2.222497</td>\n",
       "      <td>4.628560</td>\n",
       "      <td>6.334514</td>\n",
       "      <td>1240.975696</td>\n",
       "      <td>-321.289498</td>\n",
       "      <td>10.607821</td>\n",
       "      <td>5.761704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.308109</td>\n",
       "      <td>3.243816</td>\n",
       "      <td>-20.768748</td>\n",
       "      <td>11.106142</td>\n",
       "      <td>4.891662</td>\n",
       "      <td>4.921125</td>\n",
       "      <td>-1149.257088</td>\n",
       "      <td>365.093207</td>\n",
       "      <td>22.615302</td>\n",
       "      <td>16.957561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.548527</td>\n",
       "      <td>5.436117</td>\n",
       "      <td>-25.280989</td>\n",
       "      <td>4.318522</td>\n",
       "      <td>-0.137526</td>\n",
       "      <td>-0.270820</td>\n",
       "      <td>-1496.313673</td>\n",
       "      <td>244.869357</td>\n",
       "      <td>0.328348</td>\n",
       "      <td>7.760703</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.510978</td>\n",
       "      <td>4.004344</td>\n",
       "      <td>-5.931729</td>\n",
       "      <td>0.748787</td>\n",
       "      <td>1.423037</td>\n",
       "      <td>4.826500</td>\n",
       "      <td>-560.948725</td>\n",
       "      <td>86.858301</td>\n",
       "      <td>24.197259</td>\n",
       "      <td>-0.067853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.609007</td>\n",
       "      <td>6.129205</td>\n",
       "      <td>-9.280447</td>\n",
       "      <td>6.707153</td>\n",
       "      <td>-0.231868</td>\n",
       "      <td>4.399997</td>\n",
       "      <td>-214.455052</td>\n",
       "      <td>225.808462</td>\n",
       "      <td>9.118306</td>\n",
       "      <td>-16.195650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phi_0   theta_0       x_99       y_99    phi_99  theta_99      x_dot_0  \\\n",
       "0  2.909070  4.539917  23.367432  -2.222497  4.628560  6.334514  1240.975696   \n",
       "1  3.308109  3.243816 -20.768748  11.106142  4.891662  4.921125 -1149.257088   \n",
       "2  5.548527  5.436117 -25.280989   4.318522 -0.137526 -0.270820 -1496.313673   \n",
       "3  0.510978  4.004344  -5.931729   0.748787  1.423037  4.826500  -560.948725   \n",
       "4  1.609007  6.129205  -9.280447   6.707153 -0.231868  4.399997  -214.455052   \n",
       "\n",
       "      y_dot_0  phi_dot_0  theta_dot_0  \n",
       "0 -321.289498  10.607821     5.761704  \n",
       "1  365.093207  22.615302    16.957561  \n",
       "2  244.869357   0.328348     7.760703  \n",
       "3   86.858301  24.197259    -0.067853  \n",
       "4  225.808462   9.118306   -16.195650  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fx</th>\n",
       "      <th>Fy</th>\n",
       "      <th>tau</th>\n",
       "      <th>x_dot_99</th>\n",
       "      <th>y_dot_99</th>\n",
       "      <th>phi_dot_99</th>\n",
       "      <th>theta_dot_99</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-29612.961122</td>\n",
       "      <td>2498.912376</td>\n",
       "      <td>53852.149654</td>\n",
       "      <td>1047.460389</td>\n",
       "      <td>-38.377027</td>\n",
       "      <td>162.092739</td>\n",
       "      <td>166.050842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-26336.915345</td>\n",
       "      <td>-9994.333651</td>\n",
       "      <td>66579.923810</td>\n",
       "      <td>-1075.409015</td>\n",
       "      <td>697.828947</td>\n",
       "      <td>141.667777</td>\n",
       "      <td>146.364185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4645.636361</td>\n",
       "      <td>41785.500502</td>\n",
       "      <td>-13638.356558</td>\n",
       "      <td>-1133.713595</td>\n",
       "      <td>748.985152</td>\n",
       "      <td>-561.725041</td>\n",
       "      <td>-563.122968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-11940.326951</td>\n",
       "      <td>30568.337400</td>\n",
       "      <td>-59677.690610</td>\n",
       "      <td>-26.956023</td>\n",
       "      <td>45.961219</td>\n",
       "      <td>77.007517</td>\n",
       "      <td>72.504068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-34842.795622</td>\n",
       "      <td>-4409.744037</td>\n",
       "      <td>77836.665059</td>\n",
       "      <td>-539.671502</td>\n",
       "      <td>488.013492</td>\n",
       "      <td>-183.140660</td>\n",
       "      <td>-177.812751</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Fx            Fy           tau     x_dot_99    y_dot_99  \\\n",
       "0 -29612.961122   2498.912376  53852.149654  1047.460389  -38.377027   \n",
       "1 -26336.915345  -9994.333651  66579.923810 -1075.409015  697.828947   \n",
       "2   4645.636361  41785.500502 -13638.356558 -1133.713595  748.985152   \n",
       "3 -11940.326951  30568.337400 -59677.690610   -26.956023   45.961219   \n",
       "4 -34842.795622  -4409.744037  77836.665059  -539.671502  488.013492   \n",
       "\n",
       "   phi_dot_99  theta_dot_99  \n",
       "0  162.092739    166.050842  \n",
       "1  141.667777    146.364185  \n",
       "2 -561.725041   -563.122968  \n",
       "3   77.007517     72.504068  \n",
       "4 -183.140660   -177.812751  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test train split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, Y, test_size=0.2, random_state = 123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scale data \n",
    "scalerX = MinMaxScaler([-0.5, 0.5])  \n",
    "scalerY = MinMaxScaler([-0.5, 0.5])  \n",
    "\n",
    "# Don't cheat - fit only on training data\n",
    "scalerX.fit(Xtrain)  \n",
    "scalerY.fit(Ytrain) \n",
    "\n",
    "Xtrain_scaled = scalerX.transform(Xtrain)  \n",
    "Ytrain_scaled = scalerY.transform(Ytrain)  \n",
    "\n",
    "# apply same transformation to test data\n",
    "Xtest_scaled = scalerX.transform(Xtest)\n",
    "Ytest_scaled = scalerY.transform(Ytest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>phi_0</th>\n",
       "      <th>theta_0</th>\n",
       "      <th>x_99</th>\n",
       "      <th>y_99</th>\n",
       "      <th>phi_99</th>\n",
       "      <th>theta_99</th>\n",
       "      <th>x_dot_0</th>\n",
       "      <th>y_dot_0</th>\n",
       "      <th>phi_dot_0</th>\n",
       "      <th>theta_dot_0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.479611</td>\n",
       "      <td>0.002266</td>\n",
       "      <td>-0.318639</td>\n",
       "      <td>-0.229442</td>\n",
       "      <td>-0.094704</td>\n",
       "      <td>0.071486</td>\n",
       "      <td>-0.491811</td>\n",
       "      <td>-0.220474</td>\n",
       "      <td>0.168732</td>\n",
       "      <td>0.450440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.453551</td>\n",
       "      <td>0.264615</td>\n",
       "      <td>0.295886</td>\n",
       "      <td>0.197180</td>\n",
       "      <td>-0.188053</td>\n",
       "      <td>0.054898</td>\n",
       "      <td>0.469097</td>\n",
       "      <td>0.195148</td>\n",
       "      <td>0.353807</td>\n",
       "      <td>-0.446865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.102133</td>\n",
       "      <td>-0.139825</td>\n",
       "      <td>0.314624</td>\n",
       "      <td>0.345313</td>\n",
       "      <td>-0.234415</td>\n",
       "      <td>-0.252743</td>\n",
       "      <td>0.486725</td>\n",
       "      <td>0.399421</td>\n",
       "      <td>0.036643</td>\n",
       "      <td>-0.265189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.025410</td>\n",
       "      <td>0.473391</td>\n",
       "      <td>-0.026110</td>\n",
       "      <td>0.073530</td>\n",
       "      <td>0.050494</td>\n",
       "      <td>0.209861</td>\n",
       "      <td>-0.032577</td>\n",
       "      <td>-0.026313</td>\n",
       "      <td>-0.037384</td>\n",
       "      <td>-0.004011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.492691</td>\n",
       "      <td>-0.269698</td>\n",
       "      <td>-0.131405</td>\n",
       "      <td>0.348033</td>\n",
       "      <td>0.118454</td>\n",
       "      <td>-0.135028</td>\n",
       "      <td>-0.191459</td>\n",
       "      <td>0.408163</td>\n",
       "      <td>-0.416592</td>\n",
       "      <td>-0.057925</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      phi_0   theta_0      x_99      y_99    phi_99  theta_99   x_dot_0  \\\n",
       "0 -0.479611  0.002266 -0.318639 -0.229442 -0.094704  0.071486 -0.491811   \n",
       "1 -0.453551  0.264615  0.295886  0.197180 -0.188053  0.054898  0.469097   \n",
       "2 -0.102133 -0.139825  0.314624  0.345313 -0.234415 -0.252743  0.486725   \n",
       "3 -0.025410  0.473391 -0.026110  0.073530  0.050494  0.209861 -0.032577   \n",
       "4  0.492691 -0.269698 -0.131405  0.348033  0.118454 -0.135028 -0.191459   \n",
       "\n",
       "    y_dot_0  phi_dot_0  theta_dot_0  \n",
       "0 -0.220474   0.168732     0.450440  \n",
       "1  0.195148   0.353807    -0.446865  \n",
       "2  0.399421   0.036643    -0.265189  \n",
       "3 -0.026313  -0.037384    -0.004011  \n",
       "4  0.408163  -0.416592    -0.057925  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Xtrain_scaled, columns = X.columns).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save scalers, to be used on test set\n",
    "scalerfileX = 'scalerX.pkl'\n",
    "pickle.dump(scalerX, open(os.path.join(dataOutput, scalerfileX), 'wb'))\n",
    "\n",
    "scalerfileY = 'scalerY.pkl'\n",
    "pickle.dump(scalerY, open(os.path.join(dataOutput, scalerfileY), 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "#model.get_config()\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=150, \n",
    "                          verbose=1, mode='auto', min_delta = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: start with small network and then build up\n",
    "# refref: start with large network and prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create network\n",
    "def create_network(optimizer = 'rmsprop', \n",
    "                    numUnits = [32, 32, 32, 32], \n",
    "                    weightRegularization = 0.0, \n",
    "                    dropout_rate=0.1):\n",
    "    \n",
    "    '''\n",
    "    Create a feed forward network.  Assumes Xtrain & Ytrain have been created and scaled\n",
    "    \n",
    "    Params: \n",
    "    optimizer (str): choice of optimizer\n",
    "    numUnits (list): number of units in each hidden\n",
    "    weightRegularization (float): between 0 and 1\n",
    "    dropout_rate (float): between 0 and 1\n",
    "    \n",
    "    '''\n",
    "    K.clear_session()\n",
    "    inputs = Input(shape=(Xtrain_scaled.shape[1],))    \n",
    "    \n",
    "    # add layers\n",
    "    for ii in np.arange(0, len(numUnits)):\n",
    "        if ii >= 1: \n",
    "            x = Dense(numUnits[ii], activation='tanh', \n",
    "                      kernel_regularizer=regularizers.l1(weightRegularization))(x)\n",
    "\n",
    "        else: \n",
    "            x = Dense(numUnits[ii], activation='tanh')(inputs)\n",
    "\n",
    "\n",
    "        # add dropout\n",
    "        if dropout_rate > 0: \n",
    "            x = Dropout(dropout_rate)(x)\n",
    "    \n",
    "    predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "    # create model\n",
    "    model = Model(inputs=inputs, outputs=predictions)\n",
    "    model.compile(loss=\"mean_squared_error\", optimizer = optimizer, metrics = ['mse'])\n",
    "\n",
    "    return(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load pre-trained model\n",
    "\n",
    "# model = load_model(r\"D:\\Dropbox\\AcademiaDropbox\\mothMachineLearning_dataAndFigs\\savedModels\\Opt_rmsprop__Dro_0.0__Num_400_400_400_16__Wei_0.0.h5\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelParams = {\"optimizer\": \"rmsprop\", \n",
    "              \"dropout_rate\" : 0, \n",
    "               \"numUnits\": [400, 400, 400, 16],\n",
    "               \"weightRegularization\": 0\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "model = create_network(**modelParams)\n",
    "\n",
    "modelName = ''.join('{}_{}__'.format(key[0:3].capitalize(), val) for  key, val in modelParams.items()).replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \"_\")[0:-2]+ \"_\" + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\")\n",
    "print(modelName)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show random weight matrices\n",
    "# show images for matrices\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2-5:256//2+5, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 200, 400])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 413])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"RandomWeightMatrices\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "historyDict = {\"mean_squared_error\": [], \n",
    "               \"val_mean_squared_error\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=15, \n",
    "                          verbose=1, mode='auto', min_delta = 0.000001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # fit model without regularization\n",
    "stt = time.time()\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 1000, verbose = 2, \n",
    "                        batch_size=2**14, callbacks = [earlystop], validation_split = 0.3)\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)\n",
    "endd = time.time() - stt\n",
    "print(endd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "historyDict[\"mean_squared_error\"].extend(history.history[\"mean_squared_error\"][0:])\n",
    "historyDict[\"val_mean_squared_error\"].extend(history.history[\"val_mean_squared_error\"][0:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: save history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        plt.ylim([0.0001, 0.05])\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_NOTpruned_2.png\"), dpi = 120, bbox_inches='tight')\n",
    "        print(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"))\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "    \n",
    "plot_model_history_fromDict(historyDict, saveFig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "# if I need to remake, use this\n",
    "# wtsPath = \"D:\\Dropbox\\AcademiaDropbox\\CallinStuff\\Presentations\\eScience_Community_Seminar_2019\\Opt_rmsprop__Dro_0__Num_400_400_400_16__Wei_0_2019_05_30__11_59_54_wts.pkl\"\n",
    "# wts =  pickle.load(open(wtsPath, 'rb'))\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2 + 1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 200, 400])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 413])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"TrainedWeightMatrices\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# refref: plot predictions on test set and make figures.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "# apply same transformation to test data\n",
    "# Xtest_scaled = scalerX.transform(Xtest)\n",
    "# Ytest_scaled = scalerY.transform(Ytest)\n",
    "\n",
    "\n",
    "Ytest_pred = model.predict(Xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]\n",
    "\n",
    "\n",
    "# make data frames\n",
    "XtestDF = pd.DataFrame(scalerX.inverse_transform(Xtest_scaled), columns = X.columns)\n",
    "YtestDF = pd.DataFrame(scalerY.inverse_transform(Ytest_scaled), columns = Y.columns)\n",
    "YpredDF = pd.DataFrame(scalerY.inverse_transform(Ytest_pred), columns = Y.columns+ \"_pred\")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df_c = pd.concat([YtestDF.reset_index(drop=True), YpredDF], axis=1)\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_c = df_c[0:100000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array([30, 10]) / 1.3, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.2, wspace=0.7)\n",
    "#fig.suptitle('Predicted vs. acutal ', fontsize=14, fontweight='bold')\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "ylabs = [r\"g*cm/$s^2$\", r\"g*cm/$s^2$\", r\"g*$cm^2$/$s^2$\", \"cm/s\", \"cm/s\", \"rad/s\", \"rad/s\"]\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(df_c.shape[1] //2):\n",
    "    try:\n",
    "        axs[ii].hexbin(y = df_c.iloc[:,ii],x = df_c.iloc[:,ii + 7], gridsize = 50, cmap = cmap)\n",
    "        #axs[ii].set_xlabel(\"Predicted Value\\n(unscaled)\")\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\\n\" + ylabs[ii])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[ii])\n",
    "        axs[ii].set_title(df_c.columns[ii])\n",
    "        axs[ii].plot(df_c.iloc[:,ii], df_c.iloc[:,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "        \n",
    "        # annotate with R^2\n",
    "        axs[ii].text(np.max(df_c.iloc[:,ii])*0.1, np.min(df_c.iloc[:,ii])*0.9, r'$r^2$ =' + str(np.round((r2_score(df_c.iloc[:,ii ],  df_c.iloc[:,ii+7])), 3)))\n",
    "        axs[ii].set_xlim([-np.max(np.abs(df_c.iloc[:,ii+7])), np.max(np.abs(df_c.iloc[:,ii+7]))])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# # residual plots x = predicted, y = actual - predicted\n",
    "for jj in range(df_c.shape[1] //2):\n",
    "    \n",
    "    ii = jj + 7\n",
    "    try:\n",
    "        axs[ii].hexbin(x = df_c.iloc[:,jj],\n",
    "                     y = df_c.iloc[:,jj ] - df_c.iloc[:,jj+7], gridsize = (35, 50), cmap = cmap)\n",
    "        axs[ii].set_xlabel(\"Predicted Value\")\n",
    "\n",
    "        if(jj == 0):\n",
    "            axs[ii].set_ylabel(\"Actual - Predicted\\n\" + ylabs[jj])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[jj])\n",
    "        \n",
    "        axs[ii].hlines(y = 0, xmin = np.min( df_c.iloc[:,jj+7]), \n",
    "                       xmax = np.max( df_c.iloc[:,jj+7]), linestyle =  \"--\", linewidth = 1)\n",
    "        axs[ii].set_ylim([-np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7])), np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7]))])\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "fig.savefig(os.path.join(figDir, \"PredVActual_\" + modelName + \".png\"), dpi = 500, bbox_inches='tight')\n",
    "plt.show()\n",
    "# plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#(y_true, y_pred, sample_weight=None, multioutput=uniform_average)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save model\n",
    "model.save(os.path.join(figDir,  modelName + '_notPruned.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_wts.pkl'\n",
    "pickle.dump(wts, open(os.path.join(figDir, wtsFile), 'wb'))\n",
    "\n",
    "# save history\n",
    "histName = modelName + '_history.pkl'\n",
    "pickle.dump(historyDict, open(os.path.join(figDir, histName), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for jj in range(7):\n",
    "    print (r2_score(df_c.iloc[:,jj ],  df_c.iloc[:,jj+7]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## START NEW ITEM: train and trim weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train and trim weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read in data\n",
    "#wts =  pickle.load(open(os.path.join(dataOutput, wtsFile), 'rb'))\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    print(wts[ii].shape)\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # start training\n",
    "# historyDict = {\"mean_squared_error\": [], \n",
    "#                \"val_mean_squared_error\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start pruning\n",
    "modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numCuts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: \n",
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "def prune_percent_updater(x):\n",
    "    logit = np.exp(x*8) / (np.exp(x*8) + 1)\n",
    "    return((logit - 0.5)*2*50)\n",
    "\n",
    "\n",
    "# cuts a smaller portion as the percent gets closer to 100%\n",
    "cutPercent = prune_percent_updater(np.linspace(0, 1, 26))\n",
    "\n",
    "while True:   \n",
    "   \n",
    "    for numEpocs in range(100):\n",
    "        \n",
    "        MSE_tmp = []\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                            callbacks = [earlystop])\n",
    "        \n",
    "        # refref: earlystop doesn't do anything here\n",
    "        \n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "        \n",
    "        # local MSE\n",
    "        MSE_tmp.append(history.history[\"mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 1):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent[numCuts], 50 + cutPercent[numCuts]), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        \n",
    "        # check the change in mean squared error, and if it's not changing much, then cut out more data\n",
    "        # calculate slope of loss, based on previous 5 data points\n",
    "        if numEpocs > 5:\n",
    "            inputData = historyDict[\"mean_squared_error\"][-5:]\n",
    "\n",
    "            m = np.shape(inputData)\n",
    "            X = np.matrix([np.ones(m), np.arange(0, len(inputData))]).T\n",
    "            y = np.matrix(np.log(inputData)).T\n",
    "\n",
    "            # Solve for projection matrix\n",
    "            intercept, slope = np.array(np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)).reshape(-1,)\n",
    "            print(\"change in log loss:\", slope)\n",
    "    \n",
    "            # break if slope has stopped changing or if the overall min has been surpassed\n",
    "            # in the first training, it will automatically prune after 5 epochs, because the min will be passed\n",
    "            if (np.abs(slope) < 0.0001) or (history.history[\"mean_squared_error\"][0] < np.min(historyDict[\"mean_squared_error\"][:-1])): \n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                model.save(os.path.join(figDir,  modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'))\n",
    "                break\n",
    "                       \n",
    "                    \n",
    "    ## refref: may want to save weights before each pruning, so I can go back, if I need to\n",
    "    ## refref: should I be pruning the biases too?\n",
    "    \n",
    "    ## keep running tally of min mse, and if we can't get back to the min, then break\n",
    "#     print(\"Min MSE for this prune \", np.min(MSE_tmp), \"______overall Min MSE \", np.min(historyDict[\"mean_squared_error\"]))\n",
    "#     if np.min(MSE_tmp) > np.min(historyDict[\"mean_squared_error\"]):\n",
    "#         print(\"no more gain by pruning:  STOPPING Pruning\")\n",
    "#         break\n",
    "    \n",
    "    numCuts += 1\n",
    "    if numCuts >= len(cutPercent):\n",
    "        break\n",
    "\n",
    "        \n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(numCuts)\n",
    "(50 - cutPercent[numCuts]) * 2 # percent of original network size that is used the pruned version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  save model\n",
    "model.save(os.path.join(figDir,  modelName + '_Pruned.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_wts_pruned.pkl'\n",
    "pickle.dump(wts, open(os.path.join(figDir, wtsFile), 'wb'))\n",
    "\n",
    "# save history\n",
    "histName = modelName + '_history_pruned.pkl'\n",
    "pickle.dump(historyDict, open(os.path.join(figDir, histName), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# numCuts = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history_fromDict(model_history_dictionary, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history_dictionary['mean_squared_error'])+1),\n",
    "             model_history_dictionary['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "             model_history_dictionary['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(model_history_dictionary['val_mean_squared_error'][-1])) + \"\\n\" +  str(nzwts) + \" non-zero weights\")\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history_dictionary['val_mean_squared_error'])+1),\n",
    "                   len(model_history_dictionary['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "    if saveFig:\n",
    "        plt.ylim([0.0001, 0.05])\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining_\" + modelName + \"_pruned.png\"), dpi = 120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "\n",
    "\n",
    "# print sizes of each weight matrix\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "    \n",
    "plot_model_history_fromDict(historyDict, saveFig = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "str(dictLen).zfill(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video of training\n",
    "tmpDir = os.path.join(figDir, \"tmpImgs\")\n",
    "if not os.path.exists(tmpDir):\n",
    "    os.mkdir(tmpDir)\n",
    "fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "#for dictLen in np.arange(1, len(historyDict[\"mean_squared_error\"])):\n",
    "for dictLen in range(300):\n",
    "\n",
    "    # save images\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(historyDict['mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "             historyDict['mean_squared_error'][dictLen-1:dictLen])\n",
    "    axs.plot(range(1,len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "             historyDict['val_mean_squared_error'][dictLen-1:dictLen])\n",
    "    axs.set_title('Model MSE = '+ str(format_e(historyDict['val_mean_squared_error'][dictLen])))\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "#     axs.set_xticks(np.arange(1,len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "#                    len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])//10)\n",
    "    axs.legend(['train', 'val'], loc='lower left')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "\n",
    "    plt.ylim([0.0001, 0.05])\n",
    "    fig.savefig(os.path.join(tmpDir, str(dictLen).zfill(4)+ \".png\"), dpi = 120,  pad_inches = 0.5)\n",
    "    #plt.close()\n",
    "    \n",
    "    if np.mod(dictLen, 100) == 0:\n",
    "        print(dictLen)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make video of training\n",
    "tmpDir = os.path.join(figDir, \"tmpImgs\")\n",
    "if not os.path.exists(tmpDir):\n",
    "    os.mkdir(tmpDir)\n",
    "fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "for dictLen in np.arange(1, len(historyDict[\"mean_squared_error\"])):\n",
    "#for dictLen in np.arange(1, 100):\n",
    "\n",
    "    # save images\n",
    "    \n",
    "    # summarize history for accuracy\n",
    "    axs.plot([dictLen -1, dictLen],\n",
    "             historyDict['mean_squared_error'][dictLen-1:dictLen+1], c= \"C0\")\n",
    "    axs.plot([dictLen -1, dictLen],\n",
    "             historyDict['val_mean_squared_error'][dictLen-1:dictLen+1], c= \"C1\")\n",
    "    axs.set_title('Model MSE = '+ str(format_e(historyDict['val_mean_squared_error'][dictLen])))\n",
    "    axs.set_ylabel('mean squared error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "#     axs.set_xticks(np.arange(1,len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])+1),\n",
    "#                    len(historyDict['val_mean_squared_error'][dictLen-1:dictLen])//10)\n",
    "    axs.legend(['train', 'val'], loc='lower left')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "\n",
    "    plt.ylim([0.0001, 0.05])\n",
    "    fig.savefig(os.path.join(tmpDir, str(dictLen).zfill(4)+ \".png\"), dpi = 120,  pad_inches = 0.5)\n",
    "    #plt.close()\n",
    "    #plt.show()\n",
    "    \n",
    "    if np.mod(dictLen, 100) == 0:\n",
    "        print(dictLen)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make into video\n",
    "os.chdir(tmpDir)\n",
    "\n",
    "os.system('ffmpeg -start_number 0   -r 50 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264 -b:v 10000k  -pix_fmt yuv420p -y  0000000_output_epochs.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ytest_pred = model.predict(Xtest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make data frames\n",
    "# make dataset\n",
    "X = trainDF.loc[:, [ \"phi_0\", \"theta_0\", \n",
    "                    \"x_99\", \"y_99\", \"phi_99\", \"theta_99\", \n",
    "                   \"x_dot_0\", \"y_dot_0\", \"phi_dot_0\", \"theta_dot_0\"]]\n",
    "\n",
    "Y = trainDF.loc[:, [\"Fx\", \"Fy\", \"tau\", \"x_dot_99\", \"y_dot_99\", \n",
    "                    \"phi_dot_99\", \"theta_dot_99\"] ]\n",
    "\n",
    "XtestDF = pd.DataFrame(scalerX.inverse_transform(Xtest_scaled), columns = X.columns)\n",
    "YtestDF = pd.DataFrame(scalerY.inverse_transform(Ytest_scaled), columns = Y.columns)\n",
    "YpredDF = pd.DataFrame(scalerY.inverse_transform(Ytest_pred), columns = Y.columns+ \"_pred\")\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)\n",
    "\n",
    "df_c = pd.concat([YtestDF.reset_index(drop=True), YpredDF], axis=1)\n",
    "df_c.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(historyDict[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_c = df_c.iloc[0:10000,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make plots\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array([30, 10]) / 1.3, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.2, wspace=0.7)\n",
    "#fig.suptitle('Predicted vs. acutal ', fontsize=14, fontweight='bold')\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "ylabs = [r\"g*cm/$s^2$\", r\"g*cm/$s^2$\", r\"g*$cm^2$/$s^2$\", \"cm/s\", \"cm/s\", \"rad/s\", \"rad/s\"]\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(df_c.shape[1] //2):\n",
    "    try:\n",
    "        axs[ii].hexbin(y = df_c.iloc[:,ii],x = df_c.iloc[:,ii + 7], gridsize = 50, cmap = cmap)\n",
    "        #axs[ii].set_xlabel(\"Predicted Value\\n(unscaled)\")\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\\n\" + ylabs[ii])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[ii])\n",
    "        axs[ii].set_title(df_c.columns[ii])\n",
    "        axs[ii].plot(df_c.iloc[:,ii], df_c.iloc[:,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "        \n",
    "        # annotate with R^2\n",
    "        axs[ii].text(np.max(df_c.iloc[:,ii])*0.1, np.min(df_c.iloc[:,ii])*0.9, r'$r^2$ =' + str(np.round((r2_score(df_c.iloc[:,ii ],  df_c.iloc[:,ii+7])), 3)))\n",
    "        axs[ii].set_xlim([-np.max(np.abs(df_c.iloc[:,ii+7])), np.max(np.abs(df_c.iloc[:,ii+7]))])\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# # residual plots x = predicted, y = actual - predicted\n",
    "for jj in range(df_c.shape[1] //2):\n",
    "    \n",
    "    ii = jj + 7\n",
    "    try:\n",
    "        axs[ii].hexbin(x = df_c.iloc[:,jj],\n",
    "                     y = df_c.iloc[:,jj ] - df_c.iloc[:,jj+7], gridsize = (35, 50), cmap = cmap)\n",
    "        axs[ii].set_xlabel(\"Predicted Value\")\n",
    "\n",
    "        if(jj == 0):\n",
    "            axs[ii].set_ylabel(\"Actual - Predicted\\n\" + ylabs[jj])\n",
    "        else:\n",
    "            axs[ii].set_ylabel(ylabs[jj])\n",
    "        \n",
    "        axs[ii].hlines(y = 0, xmin = np.min( df_c.iloc[:,jj+7]), \n",
    "                       xmax = np.max( df_c.iloc[:,jj+7]), linestyle =  \"--\", linewidth = 1)\n",
    "        axs[ii].set_ylim([-np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7])), np.max(np.abs(df_c.iloc[:,jj ] - df_c.iloc[:,jj+7]))])\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "\n",
    "fig.savefig(os.path.join(figDir, \"PredVActual_\" + str(len(historyDict[\"mean_squared_error\"])) +  modelName + \".png\"), dpi = 500, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2+1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.7, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('PRGn', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 200, 400])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 413])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 9:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 413])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[8], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"Pruned_WeightMatrices\" + str(len(historyDict[\"mean_squared_error\"]))  + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show example small network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Opt_rmsprop__Dro_0__Num_20_20_16__Wei_0_2019_06_03__14_43_22\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 20)                220       \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 20)                420       \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 7)                 119       \n",
      "=================================================================\n",
      "Total params: 1,095\n",
      "Trainable params: 1,095\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "modelParams = {\"optimizer\": \"rmsprop\", \n",
    "              \"dropout_rate\" : 0, \n",
    "               \"numUnits\": [20, 20, 16],\n",
    "               \"weightRegularization\": 0\n",
    "              }\n",
    "\n",
    "\n",
    "\n",
    "model = create_network(**modelParams)\n",
    "\n",
    "modelName = ''.join('{}_{}__'.format(key[0:3].capitalize(), val) for  key, val in modelParams.items()).replace(\"[\", \"\").replace(\"]\", \"\").replace(\", \", \"_\")[0:-2]+ \"_\" + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\")\n",
    "print(modelName)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saveWeightImages(model, ctr):\n",
    "    \n",
    "    wts = model.get_weights().copy()\n",
    "    for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "\n",
    "        if len(wts[ii].shape) < 2: \n",
    "            wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "        else:\n",
    "            wtsTmp = wts[ii].copy()\n",
    "\n",
    "        im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                                  vmin=-3.0, vmax=3.0))\n",
    "\n",
    "\n",
    "        if np.mod(ii+1, 2) == 0:\n",
    "            axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 1])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "\n",
    "\n",
    "\n",
    "        if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].axes.set_ylim([-1, 21])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "            #axs[jj].axis('off')\n",
    "\n",
    "\n",
    "        if ii == 7:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "            #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([0])\n",
    "            axs[jj].axes.set_xlim([-1, 21])\n",
    "\n",
    "        if ii == 0:\n",
    "            axs[jj].spines['top'].set_visible(False)\n",
    "            axs[jj].spines['right'].set_visible(False)\n",
    "            axs[jj].spines['bottom'].set_visible(False)\n",
    "            axs[jj].spines['left'].set_visible(False)\n",
    "            axs[jj].get_xaxis().set_ticks([])\n",
    "\n",
    "            axs[jj].get_yaxis().set_ticks([])\n",
    "            axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "    cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "    cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "\n",
    "\n",
    "    plt.savefig(os.path.join(figDir, tmpFolder, str(ctr).zfill(4) + \"_\" + modelName  + \".png\"), dpi = 120, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17589de8dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "PRGn = cm.get_cmap('PRGn', 256)\n",
    "newcolors = PRGn(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2 + 1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "tmpFolder = \"smallNetworkTraingingPruning\"\n",
    "\n",
    "if not os.path.exists(os.path.join(figDir, tmpFolder)):\n",
    "    os.mkdir(os.path.join(figDir, tmpFolder))\n",
    "saveWeightImages(model, 0)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20)\n",
      "(20,)\n",
      "(20, 20)\n",
      "(20,)\n",
      "(20, 16)\n",
      "(16,)\n",
      "(16, 7)\n",
      "(7,)\n",
      "1095 total weights\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "historyDict = {\"mean_squared_error\": [], \n",
    "               \"val_mean_squared_error\": []}\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    print(wts[ii].shape)\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "ctr = 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n",
      " - 5s - loss: 0.0247 - mean_squared_error: 0.0247 - val_loss: 0.0221 - val_mean_squared_error: 0.0221\n",
      "Train on 5544285 samples, validate on 2376123 samples\n",
      "Epoch 1/1\n"
     ]
    }
   ],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "for foo in np.arange(1, 1000):\n",
    "    \n",
    "    # # fit model without regularization, and save history and weights at each timestep\n",
    "    history = model.fit(Xtrain_scaled, Ytrain_scaled, epochs = 1, verbose = 2, \n",
    "                            batch_size=2**14, validation_split = 0.3)\n",
    "\n",
    "\n",
    "    # save history\n",
    "    historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "    historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "    \n",
    "    wts = model.get_weights().copy()\n",
    "    \n",
    "    \n",
    "    #  save model\n",
    "    model.save(os.path.join(figDir,tmpFolder,  modelName + '_notPruned.h5'))\n",
    "\n",
    "    # save weights\n",
    "    wts = model.get_weights().copy()\n",
    "\n",
    "    wtsFile = str(ctr).zfill(4) + modelName + '_wts.pkl'\n",
    "    pickle.dump(wts, open(os.path.join(figDir, tmpFolder, wtsFile), 'wb'))\n",
    "\n",
    "    # save history\n",
    "    histName = modelName + '_history.pkl'\n",
    "    pickle.dump(historyDict, open(os.path.join(figDir,tmpFolder, histName), 'wb'))\n",
    "\n",
    "    if np.mod(foo, 3) == 0:\n",
    "        saveWeightImages(model, ctr)\n",
    "        ctr += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make movie:\n",
    "\n",
    "# make into video\n",
    "os.chdir(os.path.join(figDir, tmpFolder))\n",
    "\n",
    "os.system('ffmpeg -start_number 0 -r 10 -i %04d_Opt_rmsprop__Dro_0__Num_20_20_16__Wei_0_2019_06_03__13_54_40.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y 0000000_WeightUpdates.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(historyDict[\"mean_squared_error\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tmpDir = os.path.join(figDir, tmpFolder)\n",
    "ctr2 = 0 \n",
    "\n",
    "fig, axs = plt.subplots(1,1,figsize=np.array([30, 10])/2)\n",
    "\n",
    "for dictLen in np.arange(0, len(historyDict[\"mean_squared_error\"])):\n",
    "    if dictLen > 0:    \n",
    "        axs.plot([dictLen -1, dictLen],\n",
    "                 historyDict['mean_squared_error'][dictLen-1:dictLen+1], c= \"C0\")\n",
    "        axs.plot([dictLen -1, dictLen],\n",
    "                 historyDict['val_mean_squared_error'][dictLen-1:dictLen+1], c= \"C1\")\n",
    "    else:    \n",
    "        axs.plot(0,\n",
    "                 historyDict['mean_squared_error'][0],marker='o', markersize=5, c= \"C0\")\n",
    "        axs.plot(0,\n",
    "                 historyDict['val_mean_squared_error'][0],marker='o',markersize=5, c= \"C1\")\n",
    "    axs.set_title('Model MSE = '+ str(format_e(historyDict['val_mean_squared_error'][dictLen])))\n",
    "    axs.set_ylabel('mean squared error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.legend(['train', 'val'], loc='lower left')\n",
    "    plt.yscale('log') #logarithmic scale for y axis\n",
    "\n",
    "    plt.ylim([0.0001, 0.05])\n",
    "#     fig.savefig(os.path.join(tmpDir, str(dictLen).zfill(4)+ \".png\"), dpi = 120,  pad_inches = 0.5)\n",
    "    #plt.close()\n",
    "    #plt.show()\n",
    "    \n",
    "    if np.mod(dictLen, 3) == 0:\n",
    "        print(dictLen)\n",
    "        fig.savefig(os.path.join(tmpDir, str(ctr2).zfill(4)+ \".png\"), dpi = 120,  pad_inches = 0.5)\n",
    "        ctr2 += 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make into video\n",
    "os.chdir(os.path.join(figDir, tmpFolder))\n",
    "\n",
    "os.system('ffmpeg -start_number 0 -r 10 -i %04d.png -vf \"scale=trunc(iw/2)*2:trunc(ih/2)*2\" -c:v libx264   -b:v 10000k -pix_fmt yuv420p -y 0000000_HistoryUpdates.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x17274617c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "saveWeightImages(model, 0)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Hi\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 20)\n",
      "(20,)\n",
      "(20, 20)\n",
      "(20,)\n",
      "(20, 16)\n",
      "(16,)\n",
      "(16, 7)\n",
      "(7,)\n",
      "1095 total weights\n"
     ]
    }
   ],
   "source": [
    "wts = model.get_weights().copy()\n",
    "wtLengths = []\n",
    "for ii in range(len(wts)):\n",
    "    print(wts[ii].shape)\n",
    "    wtLengths.append(np.prod(wts[ii].shape))\n",
    "\n",
    "print(np.sum(wtLengths), \"total weights\")\n",
    "\n",
    "numCuts = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# start training\n",
    "historyDict = {\"mean_squared_error\": [], \n",
    "               \"val_mean_squared_error\": []}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: \n",
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "def prune_percent_updater(x):\n",
    "    logit = np.exp(x*8) / (np.exp(x*8) + 1)\n",
    "    return((logit - 0.5)*2*50)\n",
    "\n",
    "\n",
    "# cuts a smaller portion as the percent gets closer to 100%\n",
    "cutPercent = prune_percent_updater(np.linspace(0, 1, 26))\n",
    "\n",
    "ctr = 0\n",
    "\n",
    "while True:   \n",
    "    \n",
    "    saveWeightImages(model, ctr)\n",
    "    \n",
    "    ctr += 1\n",
    "    \n",
    "    for numEpocs in range(100):\n",
    "        \n",
    "        MSE_tmp = []\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                            callbacks = [earlystop])\n",
    "        \n",
    "        # refref: earlystop doesn't do anything here\n",
    "        \n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "        \n",
    "        # local MSE\n",
    "        MSE_tmp.append(history.history[\"mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 1):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent[numCuts], 50 + cutPercent[numCuts]), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        \n",
    "        # check the change in mean squared error, and if it's not changing much, then cut out more data\n",
    "        # calculate slope of loss, based on previous 5 data points\n",
    "        if numEpocs > 5:\n",
    "            inputData = historyDict[\"mean_squared_error\"][-5:]\n",
    "\n",
    "            m = np.shape(inputData)\n",
    "            X = np.matrix([np.ones(m), np.arange(0, len(inputData))]).T\n",
    "            y = np.matrix(np.log(inputData)).T\n",
    "\n",
    "            # Solve for projection matrix\n",
    "            intercept, slope = np.array(np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)).reshape(-1,)\n",
    "            print(\"change in log loss:\", slope)\n",
    "    \n",
    "            # break if slope has stopped changing or if the overall min has been surpassed\n",
    "            # in the first training, it will automatically prune after 5 epochs, because the min will be passed\n",
    "            if (np.abs(slope) < 0.0001) or (history.history[\"mean_squared_error\"][0] < np.min(historyDict[\"mean_squared_error\"][:-1])): \n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                print(\"************************************************ PRUNING ********************************************************\")\n",
    "                model.save(os.path.join(figDir,  modelName + str(datetime.now())[0:-7].replace(\"-\", \"_\").replace(\" \", \"__\").replace(\":\", \"_\") + '_Pruned.h5'))\n",
    "                break\n",
    "                       \n",
    "                    \n",
    "    ## refref: may want to save weights before each pruning, so I can go back, if I need to\n",
    "    ## refref: should I be pruning the biases too?\n",
    "    \n",
    "    ## keep running tally of min mse, and if we can't get back to the min, then break\n",
    "#     print(\"Min MSE for this prune \", np.min(MSE_tmp), \"______overall Min MSE \", np.min(historyDict[\"mean_squared_error\"]))\n",
    "#     if np.min(MSE_tmp) > np.min(historyDict[\"mean_squared_error\"]):\n",
    "#         print(\"no more gain by pruning:  STOPPING Pruning\")\n",
    "#         break\n",
    "    \n",
    "    numCuts += 1\n",
    "    if numCuts >= len(cutPercent):\n",
    "        break\n",
    "\n",
    "        \n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,4, figsize=np.array([30, 10])/2, facecolor='w', edgecolor='k', sharex = \"none\", sharey = \"none\")\n",
    "fig.subplots_adjust(hspace = -0.4, wspace=0.1, bottom = -0.1 )\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "\n",
    "viridis = cm.get_cmap('viridis', 256)\n",
    "newcolors = viridis(np.linspace(0, 1, 256))\n",
    "white = np.array([0.8, 0.8, 0.8, 1])\n",
    "newcolors[256//2:256//2 + 1, :] = white\n",
    "newcmp = ListedColormap(newcolors)\n",
    "\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "\n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = newcmp, norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 1])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        axs[jj].get_xaxis().set_ticks([0, 10])\n",
    "        \n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].tick_params(top = False, labelbottom = True, labeltop = False)\n",
    "        \n",
    "\n",
    "    \n",
    "    if (np.mod(jj, 2) == 0) and (jj != 0):\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "            \n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].axes.set_ylim([-1, 21])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        #axs[jj].axis('off')\n",
    "        \n",
    "        \n",
    "    if ii == 7:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([0])\n",
    "        axs[jj].axes.set_xlim([-1, 21])\n",
    "        \n",
    "    if ii == 0:\n",
    "        axs[jj].spines['top'].set_visible(False)\n",
    "        axs[jj].spines['right'].set_visible(False)\n",
    "        axs[jj].spines['bottom'].set_visible(False)\n",
    "        axs[jj].spines['left'].set_visible(False)\n",
    "        axs[jj].get_xaxis().set_ticks([])\n",
    "        #axs[jj].get_yaxis().set_ticks([])\n",
    "\n",
    "\n",
    "        #axs[jj].axes.get_yaxis().set_visible(False)\n",
    "        axs[jj].get_yaxis().set_ticks([])\n",
    "        axs[jj].set_title(str(wtsTmp.shape[0]) + \"x\" + str(wtsTmp.shape[1]) + \" matrix\", loc = \"left\")\n",
    "\n",
    "\n",
    "        #axs[jj].axes.set_ylim([-1, 32])\n",
    "\n",
    "    \n",
    "    #axs[jj].axis('off')\n",
    "\n",
    "cbaxes = inset_axes(axs[6], width=\"5%\", height=\"75%\", loc= \"center\") \n",
    "cbar = fig.colorbar(im, cax=cbaxes, orientation=\"vertical\", ticks = [-10, -1, 0, 1, 10])    \n",
    "    \n",
    "#fig.colorbar(im, orientation=\"horizontal\", pad=0.2)\n",
    "\n",
    "\n",
    "\n",
    "plt.savefig(os.path.join(figDir, \"PrunedWts_small\" + modelName + \".png\"), dpi = 500, bbox_inches = 'tight', pad_inches = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how good can I get without trimming\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot matrices\n",
    "\n",
    "wts = model.get_weights().copy()\n",
    "for ii in np.arange(0, len(wts), 2):\n",
    "    plt.matshow(wts[ii], cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot biases\n",
    "\n",
    "for ii in np.arange(1, len(wts), 2):\n",
    "    plt.matshow(wts[ii].reshape(1, -1), cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    plt.colorbar()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: save weights and model\n",
    "model.save(os.path.join(savedModels,  modelName + '_pruned_bias.h5'))\n",
    "\n",
    "# save weights\n",
    "wts = model.get_weights().copy()\n",
    "\n",
    "wtsFile = modelName + '_pruned_wts_bias.pkl'\n",
    "pickle.dump(wts, open(os.path.join(dataOutput, wtsFile), 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(1,5, figsize=(20, 5), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.2)\n",
    "\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 2)):\n",
    "    im = axs[jj].matshow(wts[ii], cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    \n",
    "    \n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"vertical\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(5,1, figsize=(30, 10), facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "\n",
    "\n",
    "axs = axs.ravel()\n",
    "\n",
    "for jj, ii in enumerate(np.arange(1, len(wts), 2)):\n",
    "    im = axs[jj].matshow(wts[ii].reshape(1, -1), cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    axs[jj].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"horizontal\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=(30, 10), facecolor='w', edgecolor='k', )\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.1)\n",
    "\n",
    "\n",
    "axs = axs.ravel(\"F\")\n",
    "\n",
    "for jj, ii in enumerate(np.arange(0, len(wts), 1)):\n",
    "    \n",
    "    \n",
    "    \n",
    "    if len(wts[ii].shape) < 2: \n",
    "        wtsTmp = wts[ii].reshape(1,-1).copy()\n",
    "    else:\n",
    "        wtsTmp = wts[ii].copy()\n",
    "    \n",
    "    im = axs[jj].matshow(wtsTmp, cmap = \"PRGn\", norm=colors.SymLogNorm(linthresh=0.01, linscale=0.01,\n",
    "                                              vmin=-3.0, vmax=3.0))\n",
    "    if np.mod(ii+1, 2) == 0:\n",
    "        axs[jj].axes.get_yaxis().set_visible(False)\n",
    "\n",
    "plt.colorbar(im,ax=axs[jj], orientation = \"horizontal\")\n",
    "plt.savefig(os.path.join(figDir, \"PrunedWeightMatrices.png\"))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.path.join(dataOutput, wtsFile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: if whole node is basically 0, then remove the node. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.std(wts[2].reshape(-1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_network(**modelParams)\n",
    "\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                        verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                        callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check to see if model saved: \n",
    "K.clear_session()\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels, 'my_model_400Units_newData.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(wts[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((20,3)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 100)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 100)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(model.get_weights())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(Xtest_scaled, Ytest_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (5, 95), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "K.clear_session()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# this is the original model\n",
    "inputs = Input(shape=(Xtrain_scaled.shape[1],))\n",
    "x = Dense(400, activation='tanh')(inputs)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(400, activation='tanh')(x)\n",
    "x = Dense(16, activation='tanh')(x)\n",
    "predictions = Dense(Ytrain_scaled.shape[1], activation='linear')(x)\n",
    "\n",
    "# create model\n",
    "model = Model(inputs=inputs, outputs=predictions)\n",
    "model.compile(loss=\"mse\", optimizer=\"adam\", metrics = ['mse'])\n",
    "\n",
    "earlystop = EarlyStopping(monitor='val_mean_squared_error', patience=50, \n",
    "                          verbose=1, mode='auto', min_delta = 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "\n",
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (2, 98), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "model.set_weights(wts)\n",
    "\n",
    "\n",
    "# start training\n",
    "history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                    verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                    callbacks = [earlystop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "\n",
    "# trim weights\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (2.5, 97.5), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "print(nzwts)\n",
    "model.set_weights(wts)\n",
    "\n",
    "model.evaluate(Xtest_scaled, Ytest_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_model_history(model_history, saveFig = False):\n",
    "    fig, axs = plt.subplots(1,1,figsize=(10,5))\n",
    "    # summarize history for accuracy\n",
    "    axs.plot(range(1,len(model_history.history['mean_squared_error'])+1),\n",
    "             model_history.history['mean_squared_error'])\n",
    "    axs.plot(range(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "             model_history.history['val_mean_squared_error'])\n",
    "    axs.set_title('Model MSE')\n",
    "    axs.set_ylabel('mean_squared_error')\n",
    "    axs.set_xlabel('Epoch')\n",
    "    axs.set_xticks(np.arange(1,len(model_history.history['val_mean_squared_error'])+1),\n",
    "                   len(model_history.history['val_mean_squared_error'])/10)\n",
    "    axs.legend(['train', 'val'], loc='best')\n",
    "    if saveFig:\n",
    "        fig.savefig(os.path.join(figDir, \"ModelTraining.png\"), dpi = 120, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "plot_model_history(history)\n",
    "print(history.history[\"loss\"][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load model that was trained for much longer\n",
    "from keras.models import load_model\n",
    "model = load_model(os.path.join(savedModels, 'my_model.h5'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get nonzero weights\n",
    "wts = model.get_weights().copy()\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.05*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wts = model.get_weights().copy()\n",
    "nzwts = [np.nonzero(wts[ii].reshape(-1))[0] for ii in range(len(wts))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((20,5)) , facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(nzwts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(nzwts[jj].shape))\n",
    "    axs[jj+1].hist(nzwts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(nzwts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,8, figsize=np.array((10,10)) , facecolor='w', edgecolor='k')\n",
    "#fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    axs[jj].hist(wts[jj].reshape(-1), bins = 30)\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "    axs[jj+1].hist(wts[jj+1], bins = 30)\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n",
    "#fig.savefig(os.path.join(figDir, \"SmallModelResids.png\"), dpi = 120, bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trim distribution of weights -- cut out middle 20%\n",
    "for ii in np.arange(0, 7):\n",
    "    qants = np.percentile(np.reshape(wts[ii], -1), q = (40, 60), )\n",
    "    wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "    \n",
    "# calculate number of nonzero weights\n",
    "nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "nzwts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show new histogram of weights (excluding the 0's)\n",
    "# show weights histograms\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,5, figsize=np.array((15, 6)) , facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.3, wspace=0.3)\n",
    "axs = axs.ravel(order = \"F\")\n",
    "\n",
    "for ii in range(int(len(wts) / 2)):  \n",
    "    jj= int(2*ii)\n",
    "    \n",
    "    d1 = wts[jj].reshape(-1)\n",
    "    axs[jj].hist(d1[d1!=0], bins = 30, facecolor = '#d6bddb' )\n",
    "    axs[jj].set_xlabel(\"Layer \" + str(int(jj/2)) + \" weights\" + \", shape = \" + str(wts[jj].shape))\n",
    "\n",
    "    d2 = wts[jj+1]\n",
    "    axs[jj+1].hist(d2[d2!=0], bins = 30, facecolor = '#d6bddb')\n",
    "    axs[jj+1].set_xlabel(\"Layer \" + str(int(jj/2)) + \" biases\" + \", shape = \" + str(wts[jj+1].shape))\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the validation.split is the last X% of the data\n",
    "int(0.3*Xtrain_scaled.shape[0])\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set new weights and calculate new loss\n",
    "model.set_weights(wts)\n",
    "\n",
    "ValLoss = model.evaluate(Xtrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :], \n",
    "                         Ytrain_scaled[-int(0.3*Xtrain_scaled.shape[0]):, :])\n",
    "print(ValLoss[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict on test set\n",
    "nnpreds = model.predict(Xtest_scaled[ :])\n",
    "\n",
    "# rescale\n",
    "nnpreds_unscaled = scalerY.inverse_transform(nnpreds)\n",
    "\n",
    "# show residuals\n",
    "# combine residual and regular plots\n",
    "plt.close(\"all\")\n",
    "fig, axs = plt.subplots(2,7, figsize=np.array((30, 8)) / 1.7, facecolor='w', edgecolor='k')\n",
    "fig.subplots_adjust(hspace = 0.1, wspace=0.5)\n",
    "axs = axs.ravel()\n",
    "\n",
    "# replace lightest colors with white\n",
    "import matplotlib.colors\n",
    "cmap = plt.cm.magma_r\n",
    "cmaplist = np.array([cmap(i) for i in range(cmap.N)])\n",
    "cmaplist[:,0:3] = np.divide(cmaplist[:, 0:3], 1.1)\n",
    "cmaplist[0] = (1,1,1,0.5)\n",
    "cmap = matplotlib.colors.LinearSegmentedColormap.from_list('mcm',cmaplist, cmap.N)\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    \n",
    "    try:\n",
    "        axs[ii].hexbin(y = Ytest.iloc[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[ii].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[ii].ticklabel_format(style='sci',  axis='y', scilimits=(3,4))\n",
    "        axs[ii].axes.xaxis.set_ticklabels([])\n",
    "        if(ii == 0):\n",
    "            axs[ii].set_ylabel(\"Actual Value\")\n",
    "        axs[ii].set_title(nms2[ii])\n",
    "        axs[ii].plot(Ytest.iloc[0:1000,ii], Ytest.iloc[0:1000,ii], 'grey', linewidth = 1, linestyle  = \"--\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "for ii in range(len(Y.columns)):\n",
    "    jj = ii + len(Y.columns)\n",
    "    \n",
    "    try:\n",
    "        axs[jj].hexbin(y = Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii],x = nnpreds_unscaled[:,ii], gridsize = 150, cmap = cmap)\n",
    "        axs[jj].set_xlabel(\"Predicted Value\")\n",
    "        axs[jj].xaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        axs[jj].yaxis.set_major_formatter(ScalarFormatter(useMathText=True))\n",
    "        mmin = np.min(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        mmax = np.max(Ytest.iloc[:,ii] - nnpreds_unscaled[:,ii])\n",
    "        \n",
    "        upper = np.max([np.abs(mmin), np.abs(mmax)])\n",
    "        axs[jj].set_ylim(-upper, upper)\n",
    "\n",
    "        if(ii == 0):\n",
    "            axs[jj].set_ylabel(\"Actual - Predicted\")\n",
    "        axs[jj].hlines(y = 0, xmin = np.min(nnpreds_unscaled[:,ii]), \n",
    "                       xmax = np.max(nnpreds_unscaled[:,ii]), linestyle =  \"--\", linewidth = 1)\n",
    "    except:\n",
    "        pass\n",
    "plt.tight_layout()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dict of hyperparameters\n",
    "\n",
    "\n",
    "# regularization, num layers, num nodes, learning rate, optimizer, activation function, batch size\n",
    "\n",
    "from scipy.stats import randint\n",
    "from scipy.stats import uniform\n",
    "\n",
    "# Create hyperparameter space\n",
    "NumHiddenLayers = randint(low = 2, high = 20)#[4, 2, 8]\n",
    "numUnits  = [2**4, 2**5, 2**6, 2**7, 2**8, 2**9, 2**10]\n",
    "epochs = [200]\n",
    "batches1 = [2**12, 2**10, 2**8, 2**14] \n",
    "optimizers = ['rmsprop', 'adam']\n",
    "dropout_rate =  uniform(loc = 0, scale = 0.5) #[0.0, 0.2, 0.5]\n",
    "weightRegularization = uniform(loc = 0, scale = 0.001) #[0, 0.0001, 0.001, 0.01]\n",
    "secondToLastUnits = [8, 16, 32, 64]\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(optimizer=optimizers, \n",
    "                        epochs=epochs, \n",
    "                        batch_size=batches1,\n",
    "                        dropout_rate = dropout_rate, \n",
    "                        numUnits = numUnits, \n",
    "                        NumHiddenLayers = NumHiddenLayers, \n",
    "                        weightRegularization = weightRegularization, \n",
    "                        secondToLastUnits = secondToLastUnits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# refref: \n",
    "# train until I have very good results\n",
    "# then prune, and retrain until results are close\n",
    "# change pruning rate as data get closer to 100% removed\n",
    "cutPercent = 49.7\n",
    "for numCuts in range(3):\n",
    "    for numEpocs in range(100):\n",
    "\n",
    "        history = model.fit(Xtrain_scaled, Ytrain_scaled, validation_split = 0.3, \n",
    "                            verbose = 2, batch_size=2**14, epochs = 1, \n",
    "                            callbacks = [earlystop])\n",
    "        # save history\n",
    "        historyDict[\"mean_squared_error\"].append(history.history[\"mean_squared_error\"][0])\n",
    "        historyDict[\"val_mean_squared_error\"].append(history.history[\"val_mean_squared_error\"][0])\n",
    "\n",
    "        # set weights that are close to 0 all the way back to 0, and then retrain for one epoch\n",
    "        # get nonzero weights\n",
    "        wts = model.get_weights().copy()\n",
    "\n",
    "        # set weights close to 0 to 0 (but ignore biases)\n",
    "        for ii in np.arange(0, len(wts), 2):\n",
    "            qants = np.percentile(np.reshape(wts[ii], -1), q = (50 - cutPercent, 50 + cutPercent), )\n",
    "            wts[ii][(wts[ii] > qants[0]) & (wts[ii] < qants[1])] = 0\n",
    "\n",
    "        # print nonzero weights\n",
    "        # calculate number of nonzero weights\n",
    "        nzwts = np.sum([np.nonzero(wts[ii].reshape(-1))[0].shape[0] for ii in range(len(wts))])\n",
    "        print(nzwts, \"of\", np.sum(wtLengths), \"weights retained\")\n",
    "\n",
    "        # set new weights and calculate new loss\n",
    "        model.set_weights(wts)\n",
    "        #cutPercent += 0.2\n",
    "winsound.PlaySound(\"*\", winsound.SND_ALIAS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deeplearning",
   "language": "python",
   "name": "deeplearning"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
